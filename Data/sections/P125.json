{
  "title": "DISCOSENSE: Commonsense Reasoning with\nDiscourse Connectives",
  "abstract": "We present DISCOSENSE, a benchmark for commonsense reasoning via un-\nderstanding a wide variety of discourse connectives. We generate compelling\ndistractors in DISCOSENSE using Conditional Adversarial Filtering, an extension\nof Adversarial Filtering that employs conditional generation. We show that state\nof-the-art pre-trained language models struggle to perform well on DISCOSENSE,\nwhich makes this dataset ideal for evaluating next generation commonsense rea-\nsoning systems.",
  "introduction": "This paper addresses the critical need for challenging benchmarks that can reliably target the limita-\ntions of current pre-trained language models (LMs) in commonsense reasoning. State-of-the-art LMs\nhave achieved or even surpassed human performance on numerous commonsense downstream tasks.\nNevertheless, these LMs are still very far from being able to perform commonsense reasoning as well\nas humans. Hence, the fact that they have begun to ace existing benchmarks implies that time is ripe\nto design a new challenging benchmark that can reliably target their limitations.\n\nMotivated by this observation, we present DISCOSENSE, a benchmark for performing commonsense\nreasoning through understanding a wide variety of discourse connectives. Figure 1 shows an example\ntaken from DISCOSENSE. As can be seen, an example is composed of a context (e.g., \u201cOur waitress\nwas very nice, but she kept on forgetting my stuff.\u201d) and a discourse connective (e.g., \u201cFor example\u201d),\nand the goal is to choose the most plausible ending out of four options. If we ignore the discourse\nconnective, then all four options may\n\nOur waitress was very nice, but she kept on forgetting my stuff. For example\n\na) When I ordered the garlic shrimp, she remembered to add my requested garlic butter.\n\nb) She took forever to bring me my beer and fries.\n\nc) When I told her I wanted to use the free breakfast that was available she was not pleased.\n\nd) For some customers, this is fine.\n\nFigure 1: Example on commonsense reasoning with discourse connectives. The correct (i.e., most\nplausible) option is boldfaced.\n\nseem plausible because we do not know what the writer\u2019s intent is. Once we consider both the context\nand the discourse connective, then it is clear that only option b) is plausible. The reason is that \u201cFor\nexample\u201d signals an EXEMPLIFICATION relation between its arguments, and what follows the\ndiscourse connective is expected to be an example of the waitress keeping on forgetting the writer\u2019s\nstuff. Using commonsense knowledge, we know that (1) \u201cmy beer and fries\u201d is an example of \u201cmy\nstuff\u201d, and (2) her taking forever to bring the writer stuff implies she kept on forgetting his/her stuff.\n\nWhat if we replace \u201cFor example\u201d with \u201cHowever\u201d in the example? Since \u201cHowever\u201d signals a\nCONTRAST relation, options a) and d) both seem viable. Specifically, option a) describes a situation\nin which she did not forget the writer\u2019s stuff. While option d), unlike option a), does not describe\n\n\fany example that signals a contrast, one may infer a contrast between option d) and the context:\nbeing forgetful is fine for some customers. Nevertheless, option a) is arguably more plausible than\noption d) and should be chosen. The reason is that for d) to be sensible, one needs to assume that her\nforgetting the writer\u2019s stuff implies that she is in general forgetful. Without this assumption, it may\nbe strange for other customers to have an opinion on her forgetting the writer\u2019s stuff. In general, the\nmost plausible option is the option that makes the smallest number of assumptions, and/or is the most\ncoherent given the context and the discourse connective. Considering the commonsense knowledge\nand the reasoning involved, it should not be difficult to see that this task is challenging.\n\nOur contributions are four-fold. First, we create DISCOSENSE, a new dataset aimed at testing\nLMs\u2019 commonsense reasoning capabilities through discourse connectives. Second, we employ a\ncontrolled text generation based adversarial filtering approach to generate compelling negatives.\nThird, we establish baseline results on DISCOSENSE with numerous state-of-the-art discriminator\nmodels and show that they struggle to perform well on DISCOSENSE, which makes our dataset\nan ideal benchmark for next-generation commonsense reasoning systems. Finally, we show the\nefficacy of using DISCOSENSE as a transfer learning resource through sequential fine-tuning of\nLMs on DISCOSENSE followed by HELLASWAG and achieve near state-of-the-art results on the\nHELLASWAG test set. To stimulate work on this task, we make our code and data publicly available.",
  "related_work": "In this section, we discuss related work, focusing our discussion on the differences between DIS-\nCOSENSE and existing commonsense reasoning benchmarks. In addition, we present an overview of\nAdversarial Filtering, which will facilitate the introduction of the Conditional Adversarial Filtering\nmechanism we propose in Section 3.\n\nCommonsense reasoning benchmarks. SWAG and HELLASWAG are arguably the most prominent\ncommonsense reasoning benchmarks. In SWAG, given a partial description along with four candidate\nendings, the task is to predict the most plausible ending. The synthetic options (a.k.a. distractors)\nare generated through a process called Adversarial Filtering (AF) (see below). HELLASWAG is an\nextension of SWAG that seeks to eliminate artifacts in the generated endings. Unlike SWAG and\nHELLASWAG, DISCOSENSE requires that the discourse connective be taken into account in the\nreasoning process, thus increasing the number of inference steps and potentially the task complexity.\nIn addition, while the examples in SWAG and HELLASWAG come primarily from ActivityNet (a\nbenchmark focused on dense captioning of temporal events),\n\nDISCOSENSE features a more diverse set of examples coming from varied domains that may only\nbe solved with rich background knowledge.\n\nThere are benchmarks that aim to test different kinds of commonsense reasoning abilities, although\nnone of them focuses on reasoning over discourse connectives. SocialIQA, for instance, focuses on\nsocial and emotional commonsense reasoning. ABDUCTIVE NLI focuses on abductive reasoning.\nWINOGRANDE contains Winograd schema-inspired problems, which are essentially hard pronoun\nresolution problems requiring world knowledge. PIQA examines physical commonsense reasoning.\nMCTACO and TIMEDIAL focus on temporal reasoning in comprehension and dialogue formats.\n\nMore closely related to DISCOSENSE are commonsense reasoning benchmarks that involve reason-\ning with a particular kind of relations. COPA (Choice of Plausible Alternatives) focuses exclusively\non reasoning with CAUSAL relations and involves choosing the more plausible ending out of two\n(rather than four) options. P-MCQA focuses exclusively on reasoning with PRECONDITION rela-\ntions: given a commonsense fact, select the precondition that make the fact possible (enabling) or\nimpossible (disabling) out of four options. NLI, which aims to evaluate defensible inference, focuses\nexclusively on reasoning with the STRENGTHEN/WEAKEN relations: given a premise-claim pair\nwhere the premise supports the claim, generate a sentence that either strengthens or weakens the\nsupport. WINOVENTI, which is composed of Winogradstyle schemas, focuses exclusively on\nreasoning with ENTAILMENT relations: given two sentences with an entailment relation, such as\n\u201dPete says the pear is delicious. The pear is \u201d, the goal is to fill in the blank with one of two choices\n(e.g., \u201dedible\u201d, \u201dinedible\u201d). There are two key differences between these datasets and DISCOSENSE.\nFirst, rather than focusing on a particular type of relation, DISCOSENSE encompasses 37 discourse\nconnectives signaling different discourse relation types. Second, DISCOSENSE involves reasoning\n\n2\n\n\fDataset\n\nModel Human\n\nSWAG\nNLI\nHellaswag\nCosmosQA\nPIQA\nSocialIQa\nMC-TACO\nWinoGrande\nProtoQA\nVCR\n\n91.71\n91.18\n93.85\n91.79\n90.13\n83.15\n80.87\n86.64\n54.15\n63.15\n\n88\n92.9\n95.6\n94\n94.9\n88.1\n75.8\n94\n74.03\n85\n\nTable 1: Status of how competitive current common-sense reasoning benchmarks are for state-of-the-\nart pre-trained language models.\n\nFigure 1: Components of Adversarial Filtering.\n\nwith discourse connectives, which is more complicated than reasoning with discourse relations.\nSpecifically, as some connectives are sense-ambiguous\n\n(e.g., the connective \u201csince\u201d may serve as a temporal or causal connective), a LM will likely need to\n(implicitly) perform sense disambiguation in order to perform well on DISCOSENSE.\n\nThere are datasets and knowledge bases where the semantic/discourse/commonsense relations are\nexplicitly annotated and which can provide data sources from which commonsense reasoning bench-\nmarks can be derived. Examples include (1) the Penn Discourse TreeBank, where two sentences or\ntext segments are annotated with their discourse relation type, if any; (2) COREQUISITE, which\nis used to provide the commonsense facts and the human-generated preconditions in the P-MCQA\ndataset mentioned above; (3) SNLI, where each premise-hypothesis pair is annotated as ENTAIL-\nMENT, CONTRADICTION, or NEUTRAL; (4) ATOMIC20, which is a commonsense knowledge\ngraph where the nodes correspond to propositions and the edges correspond to social/physical\ncommonsense relations; and (5) SOCIAL-CHEM-101, which is a collection of statements about\ncommonsense social judgments made given everyday situations.\n\nOne of the motivations behind the creation of DISCOSENSE is that state-of-the-art LMs have man-\naged to achieve or even surpass human performance on various commonsense reasoning benchmarks.\nTable 1 shows the best accuracies achieved by existing LMs on 10 widely used commonsense rea-\nsoning benchmarks and the corresponding human performance levels. As can be seen, existing LMs\nhave managed to achieve an accuracy of more than 80\n\nAdversarial filtering (AF). Originally proposed by, AF aims to create examples that would be difficult\nfor models to solve, specifically by replacing the easy options in correctlysolved examples with\ndifficult ones. As shown in Figure 2, AF has three components: data (i.e., examples with multiple\noptions, one of which is correct), a discriminator LM (a classifier that is used to solve each example)\nand a generator LM (a model that generates new options for an example). In each AF iteration, the\ndiscriminator LM is trained on the training set and used to solve each example in the test set. If a test\nexample is incorrectly solved (i.e., the discriminator LM chooses the wrong option), the example\nis deemed sufficiently difficult and no change is made to it. On the other hand, if a test example\nis correctly solved, then AF seeks to increase its difficulty by replacing the easiest option (i.e., the\ngenerated option that the discriminator LM classifies with the highest confidence) with a new option\ngenerated by the generator LM. Training a new discriminator LM in each AF iteration ensures that\nthe dataset is not just adversarial for one LM but a class of LMs, as training different instances of\nthe same type of LMs results in models that have differently learned linguistic representations. This\nprocess is repeated on all correctly classified examples in the test set until the performance on the test\nset converges.\n\n3\n\n\fData Source\n\nDISCOSENSE Train DISCOSENSE Test\n\nDISCOVERY Train\nDISCOVERY Validation\nDISCOFUSE train\n\nBottom 7%\n\nTop 54k w/ DC\n\n100%\n\nTable 2: Data sources for DISCOSENSE and its composition before human verification. DC refers to\nthose samples in DISCOFUSE that are concerned with the discourse connective phenomenon.\n\nData\n\nGenerator LM\n\nDISCOVERY Train\nDISCOVERY Test\n\nlast 93%\n100%\n\nTable 3: Data used to train the generator LMs in Conditional Adversarial Filtering.\n\n3 DISCOSENSE\n\n3.1 Task Description\n\nDISCOSENSE aims to measure the commonsense inference abilities of computational models\nthrough the use of discourse connectives. The correct endings can be obtained after understanding\nthe purpose of the given discourse connectives. Given a context c <s, d>, which is composed of a\ncontextual sentence s and a discourse connective d as well as a set of four options O = o1, o2, o3, o4,\nthe task is to predict the most plausible ending oi belongs to O.\n\n3.2 Dataset Creation\n\nTo assemble DISCOSENSE, we focus on source datasets that contain two sentences connected through\na discourse connective. Specifically, we use two peer reviewed academic datasets, DISCOVERY\nand DISCOFUSE. In DISCOVERY, each sentence is composed of two sentences connected via\na discourse connective for the purpose of learning joint sentence representations with discourse\nconnectives. DISCOFUSE, on the other hand, is assembled for the task of sentence fusion (i.e.,\njoining several independent sentences into a single coherent sentence). We only consider those\nexamples where a discourse connective is needed for sentence fusion, and include in DISCOSENSE\nthe fused sentences in the Wikipedia split of DISCOFUSE. Since these datasets contain sentences from\nCommon Crawl and Wikipedia articles, DISCOSENSE is diverse in the topics it covers. Importantly,\nsince by construction the discourse connective is crucial in solving the underlying tasks (i.e., sentence\nrepresentation learning and sentence fusion), the crucial role played by the discourse connectives\nin these sentences makes them suitable for our use case. Details of how the DISCOVERY and\nDISCOFUSE sentences are used to create DISCOSENSE are shown in Tables 2 and 3.\n\n3.3 Generating Options\n\nNext, we describe how we generate challenging options for DISCOSENSE using an improved version\nof AF that we call Conditional Adversarial Filtering (CAF). CAF follows the AF procedure in Figure\n2, only differing from AF in terms of (1) the generator LM (Section 3.3.1), (2) the discriminator LM\n(Section 3.3.2), and (3) how the generator LMs are used to generate options (Section 3.3.3).\n\n3.3.1 Conditional Generator LM\n\nPre-training does not explicitly teach how important a particular token or text span is in contributing\nto the semantics of a sentence. Hence, to be able to generate sentences that are coherent with not\nonly the context but also the discourse connective, we propose to use Controllable Text Generation,\nwhich aims to provide a more granular control over how generation happens to match a particular\nattribute. In the context of Transformer-based LMs, there are two lines of research on controllable\ntext generation. One examines how to steer generation by fine-tuning an extra set of parameters while\nkeeping the base (unconditionally trained) model fixed while the other involves conditionally training\na generative model on a control variable to generate text w.r.t. a prompt prefix. We adopt the latter\n\n4\n\n\fapproach, extending CTRL to explicitly steer generation w.r.t. discourse relations by using discourse\nconnectives as control codes, as described below.\n\nTraining. The input to CTRL is as follows:\n\ninput: <d> <contexts> label: <endings>\n\nwhere d is a discourse connective. Specifically, each input context for CTRL is prepended with a\nconnective, and the training task for CTRL is to learn the conditional distribution p(e|d, context)\nover possible endings e. The predicted ending is then compared with the human generated ending to\ncompute loss. Since the original CTRL model is pre-trained with control codes suitable for openended\ntext generation, we fine-tune CTRL on the portion of DISCOVERY shown in Table 3 using all the\n174 connectives present in the selected splits. Comparing Tables 2 and 3, we can see that the data\nthe generator LM is fine-tuned on is not part of DISCOSENSE. Doing so ensures that the endings\ngenerated by the generator LM are different from the ground truth (i.e., the human written endings).\n\nDecoding. We use Nucleus sampling for generating options for the training set with the value of p set\nto 0.7, which means the\n\nweights of the tail of the probability distribution are ignored (i.e., tokens with a cumulative probability\nmass of less than 0.3 are left out). Additionally, we use a length penalty of 0.8 to restrict the length of\nthe generations to match the average length of the ground truth to avoid the induction of length bias.\n\nEfficacy of conditional generation. Recall that we propose the use of conditional generation, specifi-\ncally the use of discourse connectives as control codes, in our generator LM because of our hypothesis\nthat the resulting LM would generate options that are more compliant with the purpose of the dis-\ncourse connective. To test this hypothesis, we compare the text generation capability of CTRL\nwith that of GPT2-XL, a model that is trained unconditionally and has nearly the same number of\nparameters (1.6B) as CTRL, under the same evaluation setting. Specifically, both LMs are fine-tuned\non the same data (see Table 3) using the same machine (a 2x Quadro RTX 8000 with a batch size\nof 24). The only difference between them lies in the format of the training examples: in CTRL\nthe discourse connective is used as the control code and therefore precedes the context, whereas in\nGPT2XL, the discourse connective follows the context.\n\nThe two LMs are then independently applied to generate exactly one option for each example in the\nDISCOVERY validation set. CTRL achieves a much lower perplexity than GPT2-XL (2.39 vs. 2.53),\nwhich suggests that conditional training improves the quality of the generated sentences.\n\n3.3.2 Discriminator LM\n\nWe use ROBERTA-LARGE as the discriminator LM, which takes the context, the discourse connec-\ntive, and the four endings as input and predicts the most plausible ending. This LM is trained on the\nrandomly shuffled training split of DISCOSENSE and applied to the DISCOSENSE test set to get\nthe confidence scores associated with its predictions.\n\n3.3.3 Generating Options\n\nNext, we describe how we generate options for the examples in DISCOSENSE. Recall that each\nexample contains one of 174 discourse connectives. Rather than generating options for examples that\ncontain any of these 174 connectives, we select 37 discourse connectives and generate options only\nfor examples that contain one of them. The connectives that are discarded are primarily those that\nimpose few constraints on the endings to be gen-\n\nerated given the context according to preliminary experiments. For instance, the connective \u201cand\u201d\nis discarded because numerous endings are equally plausible. Similarly for connectives that signal\na temporal relation (e.g., \u201cbefore\u201d, \u201cafter\u201d): they also tend to allow numerous equally plausible\nendings, as can be seen in examples such as \u201cJohn went to eat lunch after [ending]\u201d. The 37\nconnectives that we end up choosing are shown in Table 4. These connectives are less likely to yield\noptions that look equally plausible to human annotators and which are indicative of different kinds\nof discourse relations, such as EXEMPLIFICATION (e.g., \u201cfor instance\u201d), CONCESSION (e.g.,\n\u201calthough\u201d), COMPARISON (e.g., \u201cin contrast\u201d), and CAUSAL (e.g., \u201cas a result\u201d). 94k examples in\nDISCOSENSE contain one of the 37 connectives.\n\n5\n\n\falthough\nbecause of this\nbecause of that\nbut\nconsequently\nconversely\nfor example\nfor instance\nhence\nhowever\nin contrast\n\nin other words\nin sum\ninterestingly\ninstead\nlikewise\nnevertheless\nnonetheless\non the contrary\non the other hand\notherwise\noverall\n\nparticularly\nspecifically\nsubsequently\nthereafter\nthereby\ntherefore\nthough\nthus\nyet\n\nTable 4: Discourse connectives present in DISCOSENSE.\n\nContext Answer\ntuples\n\nDiscoSense\ntrain\ntest\ntotal\nStatistics\ncontext\nanswers (all)\nanswers (correct)\nanswers (incorrect)\ncontext\nanswers (all)\nanswers (correct)\nanswers (incorrect)\nTable 5: Data statistics for DISCOSENSE.\n\n9299\n3757\n13056\nTrain / Test\n22.08 / 22.51\n18.62 / 18.92\n16.94 / 18.18\n18.51 / 18.5\n32577 / 16858\n43992 / 27406\n26836 / 15078\n41158 / 25900\n\nAverage\n\ntokens\n\nUnique\ntokens\n\nTo generate the options for these 94k sentences, we begin by training 20 generator LMs on a\nrandomly shuffled order of the generators\u2019 training data (see Table 3) and then inserting them into a\ncircular queue. Although the underlying data is the same, random shuffling ensures that the learned\nrepresentations of these 20 models are different. Since each example needs to have 3 synthetic\noptions, we use the first 3 generator LMs from the circular queue to generate the initial options for\neach example. After that, we begin CAF. In each CAF iteration, we (1) train the discriminator LM\n(see Section 3.3.2) on the DISCOSENSE training set for 4 epochs and use it to filter out the options\ndeemed as easiest by the discriminator LM; and (2) use the next generator LM in the circular queue\nto generate the options for the examples whose easiest option is removed by the discriminator LM. In\nother words, a different discriminator LM is used in each CAF iteration, and a generator LM in the\n\ncircular queue is used once every 20 CAF iterations. CAF is run separately for the DISCOSENSE\ntraining and test sets. After running CAF for approximately 150 iterations, the average accuracy of a\ndiscriminator LM decreased from 86\u201390\n\n3.3.4 Other Implementation Details\n\nFor the models we use in CAF, we obtain the pre-trained weights and the implementations from\nHugging Face Transformers. These models are trained using the AdamW optimizer with a learning\nrate of 2e-5. The training of each generator LM is performed on a 2x Quadro RTX 8000 with a batch\nsize of 24 and typically lasts for 3 days. The training of a discriminator LM is performed on a RTX\n3090 with a batch size of 16 and typically lasts for 5\u20136 hours.\n\n3.4 Human Verification\n\nNext, we perform human verification of the examples for which we have generated options. The\nverification proceeds in two steps. In Step 1, we ask three human verifiers to independently identify\nthe correct option for each example, removing an example if at least one person fails to identify the\ncorrect option. We repeat this process until the number of examples that survive this verification\n\n6\n\n\fModel\n\nAccuracy / std\n\nRandom Guess\nBERT-BASE (110M)\nBERT-LARGE (336M)\nROBERTA-BASE (125M)\nROBERTA-LARGE (355M)\nALBERT-XXLARGE-V2 (223M)\nLONGFORMER BASE (435M)\nXLNET LARGE (340M)\nFUNNEL-TRANSFORMER-XL (468M)\nELECTRA-LARGE\nHuman Performance\n\n25.0\n32.86 / 0.45\n34.25 / 1.04\n34.11 / 0.45\n34 / 0.2\n50.91 / 1.44\n35.29 / 0.77\n36.71 / 0.77\n35.22 / 1.94\n65.87 / 2.26\n95.40 / 0.20\n\nTable 6: Accuracies (best results obtained among 8 epochs when averaged over 5 runs with random\nseeds) of the LMs on the DISCOSENSE test set.\n\nreaches 13,056. In Step 2, we ask three human verifiers not involved in Step 1 to independently\nidentify the correct option for each of the 13,056 examples verified in Step 1. We compute for\neach verifier the accuracy of choosing the correct option and use the average accuracy as the human\nperformance on DISCOSENSE. Appendix A contains the details on how the human verifiers are\nrecruited and the annotation instructions we present to them.\n\n3.5 Dataset Statistics\n\nStatistics on DISCOSENSE are shown in Table 5, in which we report the average number of tokens\nin (1) the context, (2) the ground truth and (3) the generated endings. The number of unique tokens\nprovides a rough characterization of the richness of the vocabulary. In addition, we report the\ndistribution of the examples over the discourse connectives in DISCOSENSE in Figure 3.\n\n4 Evaluation\n\n4.1 Baseline Systems\n\nOur baselines are composed of prominent LMs with different kinds of Transformer architectures. First,\nwe consider models that are pre-trained in a BERT-like fashion and share architectural similarities,\nincluding the base and large variants of BERT and ROBERTA, as well as ALBERT-XXLARGE-V2.\nAs an extension, we select LONGFORMER BASE, which is pre-trained in the same manner as\nROBERTA but has a sparse attention matrix. From the autoregressive/decoder based networks,\nwe experiment with XLNET LARGE, which maximizes the learning of bidirectional contexts and\nGPT2-XL. For\n\nmodels trained with a different pre-training objective, we experiment with ELECTRA-LARGE and\nFUNNEL-TRANSFORMER-XL, the latter of which is pre-trained in a similar manner as ELECTRA-\nLARGE.\n\nWe obtain the implementations of these LMs from Hugging Face Transformers. We fine-tune them on\nthe DISCOSENSE training set using a 4way cross-entropy loss in the same way as the discriminator\nLMs in CAF are trained (see Section 3.3.4) and evaluate them on the test set.\n\n4.2 Results and Discussion\n\nResults on the test set, which are expressed in terms of accuracy, are shown in Table 6. A few points\ndeserve mention.\n\nFirst, all baselines perform better than random guess (row 1). This implies that while CAF is used to\nremove easy options, there may still be artifacts in the data that could be exploited by the LMs.\n\nSecond, models sharing a similar pre-training objective as that of BERT, such as ROBERTA and\nLONGFORMER, are among the worst baselines. A similar trend is observed with XLNET. Although\n\n7\n\n\fALBERT has the Masked Token Prediction task in its pre-training objective, its architectural differ-\nences (i.e., larger hidden states and parameter sharing) and its Sentence Order Prediction objective\nseem to help it learn inter-sentence coherency properties better than its BERT counterparts.\n\nThird, pre-training appears to play a predominant role in our task. While the BERT family of models\nare trained with the masked-LM objective, the pre-training objective of ELECTRA (the best baseline)\nis designed to determine if a token in a human-written sentence has been replaced by a generator. We\nspeculate that ELECTRA\u2019s superior\n\nperformance can be attributed to the fact that its pretrained knowledge of discriminating between syn-\nthetic and human generated tokens transfers well to the task of discriminating between synthetically\ngenerated sentences and human written sentences in DISCOSENSE. Nevertheless, the fact that it\nonly achieves an accuracy of 65.87\n\nFinally, we report human performance in the last row of Table 6. Details of how these numbers are\nobtained are discussed in Section 3.4. As can be seen, the accuracy achieved by the best baseline,\nELECTRA, lags behind that of humans by nearly 30\n\n4.3 Quantitative Error Analysis\n\nWe perform a quantitative error analysis of our best-performing model, ELECTRA. Specifically,\nwe compute for each discourse connective the percentage of examples in the DISCOSENSE test\nset that are misclassified by ELECTRA, with the goal of gaining a better understanding of the\ndiscourse connectives that are perceived as easy as well as those that are perceived as difficult as far\nas commonsense reasoning is concerned.\n\nResults are shown in Figure 4. As we can see,\n\nthe misclassification rates are highest for those discourse connectives that express contrast (e.g.,\n\u201cotherwise\u201d, \u201chowever\u201d, \u201cbut\u201d, \u201calthough\u201d). A plausible explanation for this result is that it is often\nhard to anticipate what a human would have in mind if they are trying to indicate the opposite of what\nthey mean to say. On the other hand, the model finds it easy to predict sentences where the discourse\nconnective signals compliance and exemplification (e.g., \u201csimilarly\u201d, \u201clikewise\u201d, \u201chence\u201d, \u201cbecause\nof that\u201d, \u201cfor example\u201d).\n\n4.4 Qualitative Error Analysis\n\nTo better understand the mistakes made by ELECTRA, we manually inspected 100 randomly selected\nexamples that are misclassified and identified four major reasons why they are misclassified.\n\nLess plausible endings. This category contributes to 21 perentt of the errors where the model\nchooses a less plausible ending. Choosing a less plausible option could be associated with a partial\nunderstanding of the context or unwarranted assumptions. In Example 1 of Figure 5, the model makes\nthe assumption that whatever is applicable to grass is also applicable to trees. However, the option it\nends up picking is non-factual in nature because of the phrase \u201c7000 years ago\u201d.\n\nAbstract associations. 14 percent of the errors are made due to the formation of abstract associations\nbetween concepts. The model seems to rely on certain spans of context for classification rather than\nunderstand the semantics in its entirety. In Example 2 of Figure 5, the model seems to wrongly\nassociate \u201cenergy dense nutrients\u201d with \u201cobesity\u201d and fails to understand that the context is discussing\nthe correlation between nutrient deficit diet and people belonging to lower income groups.\n\nComplex Context Understanding. 23\n\nAlthough the grasses were only a moment old, they appeared as if they were months old. Likewise\n\na) Similar phenomena occurred with the ancient trees around the earth 7,000 years ago.\n\nb) The dinosaurs were not billions of years old.\n\nc) Several seeds were found encased within stems that are several months old, but they seemed quite\nfresh and alive. d) The trees, although only a day old when they sprouted forth, were nevertheless\nlike trees years old as they were fully grown.\n\n8\n\n\fLow income people are less likely to consume a healthy diet than wealthier people, and energy\ndense nutrients poor diets are preferentially consumed by persons of lower socioeconomic status.\nConsequently\n\na) Nutrients associated with these diets may be potentially contributing to obesity and diabetes.\n\nb) Metabolic syndrome is primarily related to obesity. c) Their health is at greater risk from diet\nrelated illness. d) A great number of persons suffering from obesity related diseases receive inadequate\nnutritional care.\n\nIt weighs on a mind, all this but\n\na) You have to live it if you want to know whats on it. b) All that means in practice.\n\nc) It does make me want to back up and ask even bigger questions. d) In a kind of perverse way, I\ndon\u2019t really feel sad.\n\nFigure 5: Examples misclassified by ELECTRA (misclassified options in pink; ground truths in\ngreen).\n\nmake a person do, in this case, \u201cask bigger questions\u201d.\n\nLack of understanding of the discourse connective. In many cases it is difficult to pinpoint the reason\nwhy an example is misclassified. Hence, if a misclassified example is not covered by any of the first\nthree categories, we attribute the mistake to a lack of understanding of the discourse connective. This\ncategory contributes to 42\n\n4.5 Role of Context and Discourse connective\n\nTo better understand the role played by the context and the discourse connective in a LM\u2019s reasoning\nprocess, we conduct two ablation experiments. In the first experiment, we remove the discourse\nconnective, so only the context and the endings are available to the LMs. In the second experiment,\nwe strip the context and the discourse connective, exposing only the endings to the LMs.\n\nResults of these experiments are shown in the C+E column and the E column of Table 7 respectively.\nFor comparison purposes,\n\n9",
  "methodology": "",
  "experiments": "",
  "results": "",
  "conclusion": ""
}
{
  "title": "A Comprehensive Multimodal Dataset for\nClimate-Conscious Prediction of Crop Yields",
  "abstract": "Accurate forecasting of crop yields is crucial for maintaining food security and promoting sustainable agricultural\nmethods. While AI has shown significant promise in various scientific domains, the creation of deep learning\nmodels for crop yield prediction has been constrained by the absence of an expansive, publicly accessible,\nmultimodal dataset that encompasses adequate information. To address this limitation, we introduce CropNet, the\nfirst terabyte-scale, publicly available, multimodal dataset designed for climate-aware crop yield predictions across\nthe contiguous United States at the county level. The CropNet dataset integrates three types of data: Sentinel-2\nImagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset, covering over 2200 U.S. counties over six\nyears (2017-2022). This dataset is designed to help researchers develop versatile deep learning models for accurate\nand timely county-level crop yield predictions, considering both short-term weather variations during the growing\nseason and long-term climate change impacts. Additionally, we offer the CropNet package, which includes three\ntypes of APIs to facilitate data downloading for specific times and regions of interest and to support the flexible\ndevelopment of deep learning models for precise crop yield predictions. Extensive experiments using various deep\nlearning solutions on the CropNet dataset confirm its general applicability and effectiveness in climate-conscious\ncrop yield predictions. The CropNet dataset is officially released on Hugging Face Datasets, and the CropNet\npackage is available on the Python Package Index (PyPI).",
  "introduction": "The accurate estimation of crop yields is vital for proactive agricultural planning, timely adjustments to management policies,\ninformed financial decision-making, and ensuring national food security. Recent progress in deep neural networks (DNNs) has\nled to remarkable performance in various fields. Building on these advancements, numerous studies have utilized spatial-temporal\nDNNs to enhance the timeliness and accuracy of crop yield predictions. However, these studies often rely on individually curated\nand limited datasets, resulting in somewhat moderate prediction accuracy. There is a pressing need for new, extensive, and deep\nlearning-ready datasets specifically designed for widespread use in crop yield forecasting.\n\nRecent studies have introduced open and large-scale datasets based on satellite imagery or meteorological parameters, which are\nadaptable to agricultural tasks like crop type classification. However, these datasets have two primary limitations that prevent their\ndirect application to general crop yield predictions. First, they lack the essential ground-truth crop yield data, making them unsuitable\nfor predicting crop yields. Second, they offer only a single data modality, either satellite images or meteorological parameters.\nAccurate crop yield predictions often require the simultaneous monitoring of crop growth and the capture of meteorological variations\nthat affect yields, necessitating multiple data modalities. To date, the creation of a large-scale, multimodal dataset specifically for\ncounty-level crop yield predictions remains an unresolved challenge.\n\nIn this research, we aim to develop such a dataset, named CropNet, which is the first terabyte-sized, publicly accessible dataset with\nmultiple modalities, specifically designed for county-level crop yield predictions across the United States (U.S.) continent. The\nCropNet dataset comprises three data modalities: Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset,\ncovering 2291 U.S. counties from 2017 to 2022. Specifically, the Sentinel-2 Imagery from the Sentinel-2 mission provides two\ntypes of satellite images, agriculture imagery (AG) and normalized difference vegetation index (NDVI), for detailed monitoring of\ncrop growth. The WRF-HRRR Computed Dataset, derived from the WRF-HRRR model, offers daily and monthly meteorological\nparameters, accounting for short-term weather variations and long-term climate change, respectively. The USDA Crop Dataset,\nsourced from the USDA Quick Statistic website, contains annual crop yield information for four major crops (corn, cotton, soybean,\nand winter wheat) grown in the contiguous U.S., serving as the ground-truth label for crop yield prediction tasks.\n\n2 Data Sources\n\nThe CropNet dataset is constructed from three distinct data sources, as detailed below:\n\n\fSentinel-2 Mission: Launched in 2015, the Sentinel-2 mission is a crucial Earth observation initiative. It offers multi-spectral\nsatellite images with 13 spectral bands and a high revisit frequency of 5 days. These images are valuable for various applications,\nincluding climate change monitoring and agricultural oversight.\n\nWRF-HRRR Model: The High-Resolution Rapid Refresh (HRRR) is a forecast modeling system based on the Weather Research &\nForecasting Model (WRF). It provides hourly forecasts of weather parameters for the entire United States continent with a spatial\nresolution of 3 km. We use the HRRR assimilated results archived at the University of Utah, which include several parameters\nrelevant to crop growth, such as temperature, precipitation, wind speed, relative humidity, and radiation, starting from July 2016.\n\nUSDA: The United States Department of Agriculture (USDA) offers annual crop information for major crops cultivated in the U.S.\nat the county level, including corn, cotton, soybeans, and wheat. The statistical data, dating back to 1850, includes planted areas,\nharvested areas, production, and yield for each crop type.\n\n3 Our CropNet Dataset\n\n3.1 Motivation\n\nLarge-scale, multimodal data that include satellite images, numerical meteorological weather data, and crop yield statistics are\nessential for monitoring crop growth and correlating weather variations with crop yields. These data are crucial for making timely\nand precise crop yield predictions at the county level. Currently, there is no such open and extensive dataset available for county-level\ncrop yield prediction. In this benchmark article, we introduce CropNet, an open and large-scale dataset with multiple modalities,\nincluding visual satellite images, numerical meteorological parameters, and crop yield statistics across the U.S. continent. It is\nimportant to note that not all U.S. counties are suitable for crop planting; therefore, our dataset includes data from 2291 out of 3143\ncounties. This multimodal dataset is invaluable for researchers and practitioners to design and test various deep learning models for\ncrop yield predictions, considering both short-term growing season weather variations and long-term climate change impacts on\ncrop yields.\n\n3.2 Overview of Our CropNet Dataset\n\nThe CropNet dataset consists of three data modalities: Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA Crop\nDataset, spanning from 2017 to 2022 across 2291 U.S. counties. Given that crop planting is highly dependent on geography, the\ndataset includes the number of counties for each crop type in the USDA Crop Dataset. The four major crops included are corn,\ncotton, soybeans, and winter wheat, with satellite imagery and meteorological data covering all 2291 counties. An overview of the\nCropNet dataset is provided in Table 1. The total size of the dataset is 2362.6 GB, with 2326.7 GB of visual data for Sentinel-2\nImagery, 35.5 GB of numerical data for the WRF-HRRR Computed Dataset, and 2.3 MB of numerical data for the USDA Crop\nDataset. Sentinel-2 Imagery contains two types of satellite images (AG and NDVI), both with a spatial resolution of approximately\n40 meters (covering an area of 9x9 km with 224x224 pixels) and a revisit frequency of 14 days. The WRF-HRRR Computed Dataset\nprovides daily or monthly meteorological parameters gridded at a spatial resolution of 9 km in one-day or one-month intervals. The\nUSDA Dataset offers county-level crop information for four types of crops, with a temporal resolution of one year.\n\nDataset\n\nSEVIR\nDENETHOR\nPASTIS\nWorldStrat\nRainNet\nENS-10\n\nTable 1: Dataset comparison\n\nSize (GB) Data Modality\n\n970\n254\n29\n107\n360\n3072\n\nSatellite Imagery\nSatellite Imagery\nSatellite Imagery\nSatellite Imagery\nSatellite Imagery\nMeteorological Parameters\nSatellite Imagery\nMeteorological Parameters\nCrop Information\n\nOur CropNet Dataset\n\n2362\n\n3.3 Data Collection and Preparation\n\nSentinel-2 Imagery: We acquire satellite images from the Sentinel-2 mission using the Sentinel Hub Processing API at a processing\nlevel of Sentinel-2 L1C. We set a maximum cloud coverage of 20%, with three spectral bands (B02, B08, and B11) for AG images\nand two bands (B04 and B08) for NDVI images. Satellite images are obtained every 14 days instead of the original 5 days to avoid a\nlarge number of duplicate images. Each county is partitioned into multiple grids with a resolution of 9x9 km, each corresponding to\none satellite image. The downloaded satellite images for one U.S. state, spanning one season, are stored in one Hierarchical Data\nFormat (HDF5) file. The HDF5 file format is chosen for its ability to save disk space, store data in multidimensional arrays, and\nstore descriptive information for the satellite images.\n\n2\n\n\fWRF-HRRR Computed Dataset: The WRF-HRRR Computed Dataset is derived from the WRF-HRRR model, which produces\nhourly GRID files containing meteorological parameters across the contiguous U.S. at a spatial resolution of 3x3 km. Our CropNet\ndataset includes nine crop growth-relevant meteorological parameters: averaged temperature, precipitation, relative humidity, wind\ngust, wind speed, downward shortwave radiation flux, maximal temperature, minimal temperature, and vapor pressure deficit (VPD).\nVPD is calculated using the formula:\n\nTC = TK \u2212 273.15,\n\nesat =\n\n610.7 \u00d7 10(7.5\u00d7TC )/(237.3+TC )\n1000\n\n,\n\neair = esat \u00d7\n\nRH\n100\nV P D = esat \u2212 eair.\n\n,\n\n(1)\n\nWe align the resolution of the WRF-HRRR Computed Dataset with that of Sentinel-2 Imagery by using the latitude and longitude of\nthe centric point in the 9x9 km grid to find the nearest 3x3 km grid in the WRF-HRRR model. Meteorological parameters from the\n3x3 km grid and its surrounding eight grids represent a region gridded at 9x9 km. Daily meteorological parameters are computed\nfrom hourly data, and monthly parameters are derived from daily data. These parameters are stored in Comma Separated Values\n(CSV) files, which also include the FIPS code, latitude, and longitude of each grid.\n\nUSDA Crop Dataset: Data from the USDA Crop Dataset is retrieved from the USDA Quick Statistic website using a newly developed\nweb crawler. For each crop type, the USDA website provides county-level crop information annually, identified by a unique key.\nOur web crawler retrieves this key by specifying the crop type and year, then uses the key to obtain the corresponding crop data. The\ndownloaded data is stored in a CSV file, which includes additional information such as FIPS code, state name, and county name. The\ndata format is unified to store production and yield information in separate columns for easy access by Python libraries like pandas.\n\nOur CropNet dataset targets county-level crop yield predictions across the contiguous U.S. continent. We use the FIPS code to fetch\ndata for each county, including HDF5 files for Sentinel-2 Imagery, CSV files for daily and monthly meteorological parameters, and a\nCSV file for the USDA Crop Dataset. Configurations are stored in a JSON file for enhanced accessibility.\n\n4 Experiments and Results\n\nWe evaluated the general applicability of our CropNet dataset to various deep learning solutions through three scenarios of climate\nchange-aware crop yield predictions: Crop Yield Predictions, One-Year Ahead Predictions, and Self-Supervised Pre-training.\n\n4.1 Experimental Settings\n\nApproaches: We employed ConvLSTM, CNN-RNN, GNN-RNN, and MMST-ViT models for crop yield predictions. Additionally,\nwe considered two self-supervised learning (SSL) techniques: MAE and MM-SSL within the MMST-ViT, representing unimodal\nand multimodal SSL techniques, respectively. These methods were adapted to fit the CropNet data in our experiments.\n\nMetrics: We used Root Mean Square Error (RMSE), R-squared (R2), and Pearson Correlation Coefficient (Corr) to assess the\neffectiveness of the CropNet dataset. Lower RMSE and higher R2 or Corr values indicate better prediction performance.\n\n4.2 Performance Evaluation for 2022 Crop Yield Predictions\n\nExperiments were conducted on the CropNet dataset for 2022 crop yield predictions using satellite images, daily weather conditions\nduring growing seasons, and monthly meteorological conditions from 2017 to 2021. The models used were ConvLSTM, CNN-RNN,\nGNN-RNN, and MMST-ViT. Table 2 presents the overall performance results for each crop. All models achieved excellent prediction\nperformance with our CropNet data. For instance, ConvLSTM, CNN-RNN, GNN-RNN, and MMST-ViT showed low RMSE\nvalues for soybean yield predictions. These results validate that our CropNet dataset is well-suited for LSTM-based, CNN-based,\nGNN-based, and ViT-based models, demonstrating its general applicability. MMST-ViT achieved the best performance across all\nscenarios, with the lowest RMSE values and highest R2 and Corr values for predicting corn, cotton, soybeans, and winter wheat\nyields. This superior performance is attributed to MMST-ViT\u2019s novel attention mechanisms, which capture the effects of both\ngrowing season weather variations and climate change on crop growth. This experiment demonstrates that our CropNet dataset\ncan provide timely and precise crop yield predictions, which are essential for making informed economic decisions and optimizing\nagricultural resource allocation.\n\n4.3 Performance of One-Year Ahead Predictions\n\nPredicting crop yields well in advance of the planting season is crucial for farmers to make early crop planting and management\nplans. We used the CropNet dataset one year before the planting season to predict the next year\u2019s crop yields. The experimental\nresults for 2022 crop yield predictions using 2021 growing season data show that all models maintain decent prediction performance.\nFor example, ConvLSTM, CNN-RNN, GNN-RNN, and MMST-ViT achieved average RMSE values of 6.2, 5.4, 5.3, and 4.7,\n\n3\n\n\fTable 2: Overall performance for 2022 crop yield predictions, where the yield of cotton is measured in pounds per acre (LB/AC) and\nthose of the rest are measured in bushels per acre (BU/AC).\n\nMethod\n\nCorn\n\nCotton\n\nSoybeans\n\nWinter Wheat\n\nRMSE (\u2193) R2 (\u2191) Corr (\u2191) RMSE (\u2193) R2 (\u2191) Corr (\u2191) RMSE (\u2193) R2 (\u2191) Corr (\u2191) RMSE (\u2193) R2 (\u2191) Corr (\u2191)\n\nConvLSTM\nCNN-RNN\nGNN-RNN\nMMST-ViT\n\n19.2\n14.3\n14.1\n13.2\n\n0.795\n0.867\n0.871\n0.890\n\n0.892\n0.923\n0.917\n0.943\n\n56.7\n54.5\n55.1\n50.9\n\n0.834\n0.826\n0.813\n0.848\n\n0.913\n0.899\n0.881\n0.921\n\n5.3\n4.1\n4.1\n3.9\n\n0.801\n0.853\n0.868\n0.879\n\n0.895\n0.915\n0.929\n0.937\n\n6.0\n5.6\n5.3\n4.8\n\n0.798\n0.823\n0.845\n0.864\n\n0.893\n0.906\n0.912\n0.929\n\nrespectively, for soybean predictions. MMST-ViT consistently achieved excellent Corr values, averaging 0.922 for corn, 0.890 for\ncotton, 0.926 for soybeans, and 0.904 for winter wheat predictions. These results are only slightly inferior to those for regular 2022\ncrop yield predictions, which can be attributed to MMST-ViT\u2019s ability to capture the indirect influence of 2021\u2019s weather conditions\non the subsequent year\u2019s crop growth through the use of long-term weather parameters. This further underscores how our CropNet\ndataset enhances climate change-aware crop yield predictions.\n\n4.4\n\nImproving the Generalization Capabilities of DNNs\n\nSelf-supervised learning (SSL) techniques have significantly advanced the generalization capabilities of deep neural networks\n(DNNs), especially in vision transformers (ViTs). Our CropNet dataset, with over 2 TB of data, benefits both deep learning and\nagricultural communities by providing large-scale visual satellite imagery and numerical meteorological data for pre-training\nDNNs. To demonstrate the applications of our CropNet dataset to self-supervised pre-training, we used MMST-ViT for crop yield\npredictions under three scenarios: MMST-ViT without SSL (w/o SSL), MMST-ViT with SSL in MAE (MAE), and MMST-ViT with\nthe multi-modal SSL technique (MM-SSL). The performance results for four crop types under three metrics (RMSE, R2, and Corr)\nshow that without SSL, MMST-ViT exhibits limitations in generalization capabilities, resulting in suboptimal crop yield prediction\nperformance. Pre-training MMST-ViT with MAE\u2019s SSL technique improves performance compared to the w/o SSL scenario, with\ndecreased RMSE values for corn, cotton, soybeans, and winter wheat predictions. This confirms that our CropNet dataset can\nimprove the generalization capabilities of vision models. Furthermore, MMST-ViT with the multi-modal SSL technique achieved\nthe best performance results under all scenarios, significantly decreasing RMSE values for predicting corn, cotton, soybeans, and\nwinter wheat. The effectiveness of the multi-modal SSL technique may stem from its ability to integrate visual satellite imagery\nwith numerical meteorological data in the CropNet dataset, enhancing the generalization capabilities of the MMST-ViT model by\nimproving its ability to discern the influence of weather conditions on crop growth patterns during pre-training.\n\n4.5 Significance of Each Modality of Our CropNet Dataset\n\nTo demonstrate the necessity and significance of each modality in our CropNet dataset, we examined five scenarios. First, we\ndropped the temporal satellite images (w/o temporal images) by randomly selecting only one day\u2019s imagery data. Second, we\ndiscarded the high-resolution satellite images (w/o high-resolution images) by using only one satellite image to capture the whole\ncounty\u2019s agricultural information. Third, we ignored the effects of weather variations on crop yields by dropping all meteorological\ndata (w/o WRF-HRRR data). Similarly, w/o short-term data and w/o long-term data represent masking out the daily and monthly\nmeteorological parameters, respectively. We also included prediction results using all modalities of the CropNet dataset (All) for\nperformance comparison. Note that the USDA Crop Dataset provides the label for crop yield predictions, so no ablation study is\nrequired for this modality.\n\nTable 3 presents the experimental results under the MMST-ViT model. Discarding the temporal satellite images (w/o temporal\nimages) significantly degrades performance, increasing RMSE values and lowering Corr values for corn and soybean yield predictions.\nThis is because a sequence of satellite images spanning the whole growing season is essential for tracking crop growth. The w/o\nhigh-resolution images scenario achieved the worst prediction performance, with the highest RMSE values and lowest Corr values\nfor corn and soybean yield predictions. This is because high-resolution satellite images are critical for precise agricultural tracking.\nDropping meteorological parameters (w/o WRF-HRRR data) prevents MMST-ViT from capturing meteorological effects on crop\nyields, leading to increased RMSE values and decreased Corr values for corn and soybean yield predictions. Discarding either\ndaily weather parameters (w/o short-term data) or monthly meteorological parameters (w/o long-term data) also lowers crop yield\nprediction performance, as the former is necessary for capturing growing season weather variations, while the latter is essential\nfor monitoring long-term climate change effects. Therefore, each modality in our CropNet dataset is important and necessary for\naccurate crop yield predictions, especially for crops sensitive to growing season weather variations and climate change.\n\n4\n\n\fTable 3: Ablation studies for different modalities of the CropNet dataset, with five scenarios considered and the last row presenting\nthe results by using all modalities\n\nModality\n\nScenario\n\nCorn\n\nSoybeans\n\nRMSE (\u2193) R2 (\u2191) Corr (\u2191) RMSE (\u2193) R2 (\u2191) Corr (\u2191)\n\nSentinel-2 Imagery\n\nw/o temporal images\nw/o high-resolution images\n\nWRF-HRRR\nComputed Dataset\n\nw/o WRF-HRRR data\nw/o short-term data\nw/o long-term data\n\nAll\n\n\u2014\n\n22.1\n27.9\n\n20.6\n18.6\n15.3\n\n13.2\n\n0.758\n0.656\n\n0.758\n0.796\n0.854\n\n0.890\n\n0.870\n0.810\n\n0.871\n0.892\n0.924\n\n0.943\n\n5.72\n7.80\n\n5.78\n5.04\n4.72\n\n3.91\n\n0.773\n0.631\n\n0.764\n0.816\n0.825\n\n0.879\n\n0.879\n0.794\n\n0.874\n0.903\n0.908\n\n0.937\n\n5 The CropNet Package\n\nIn addition to the CropNet dataset, we release the CropNet package, which includes three types of APIs available on the Python\nPackage Index (PyPI). These APIs are designed to help researchers develop DNNs for multi-modal climate change-aware crop yield\npredictions.\n\nDataDownloader: This API enables researchers to download CropNet data for specific times and regions of interest on the fly. For\ninstance, given the time and region (e.g., the FIPS code for a U.S. county), the DataDownloader API can be used to download the\nup-to-date CropNet data.\n\nDataRetriever: This API allows researchers to conveniently obtain CropNet data stored locally (e.g., after downloading the curated\ndataset) for specific times and regions of interest. The requested data is presented in a user-friendly format.\n\nDataLoader: This API assists researchers in developing DNNs for crop yield predictions. It allows for the flexible merging of\nmultiple modalities of CropNet data and exposes them through a DataLoader object after performing necessary data preprocessing.",
  "related_work": "",
  "methodology": "",
  "experiments": "",
  "results": "",
  "conclusion": "This work introduces the CropNet dataset, an open, large-scale, and multi-modal dataset specifically designed for county-level\ncrop yield predictions across the contiguous United States. The CropNet dataset comprises three modalities of data: Sentinel-2\nImagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset, containing high-resolution satellite images, daily and monthly\nmeteorological conditions, and crop yield information, aligned both spatially and temporally. This dataset is ready for use in\ndeep learning, agriculture, and meteorology, facilitating the development of new solutions and models for crop yield predictions,\nconsidering both growing season weather variations and climate change impacts on crop growth. Extensive experimental results\nconfirm the general applicability of our CropNet dataset to various deep learning models for both timely and one-year ahead crop\nyield predictions. Additionally, the application of our dataset to self-supervised pre-training scenarios demonstrates its utility in\nimproving the generalization capabilities of DNNs. Alongside the dataset, we have developed the CropNet package, which enables\nresearchers to construct CropNet data on the fly for specific times and regions of interest and to flexibly build deep learning models\nfor climate change-aware crop yield predictions. While the initial goal of creating the CropNet dataset and package was to enhance\ncrop yield prediction accuracy, we believe its future applicability is broad and warrants further exploration, benefiting the deep\nlearning, agriculture, and meteorology communities in pursuing more interesting, critical, and pertinent applications.\n\nAcknowledgments\n\nThe views and opinions expressed in this paper are those of the authors and do not necessarily reflect the views of the funding\nagencies.\n\n5"
}
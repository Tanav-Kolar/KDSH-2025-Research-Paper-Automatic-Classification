{
  "title": "A Convolutional LSTM Network Approach for\nIdentifying Diseases in Medical Volumetric Images\nwith Limited Annotations",
  "abstract": "This paper presents a methodology for identifying disease characteristics from\nmedical imaging data using 3D volumes, which have weak annotations. This\napproach converts 3D volumes into sequences of 2D images. We show the efficacy\nof our method when detecting emphysema using low-dose CT images taken from\nlung cancer screenings. Our method uses convolutional long short-term memory\n(LSTM) to sequentially \"scan\" through an imaging volume to detect diseases within\nspecific areas. This structure enables effective learning by using just volumetric\nimages and binary disease labels, facilitating training with a large dataset of 6,631\nunannotated image volumes from 4,486 patients. When evaluated on a testing\nset of 2,163 volumes from 2,163 patients, our model detected emphysema with\nan area under the receiver operating characteristic curve (AUC) of 0.83. This\nmethod outperformed both 2D convolutional neural networks (CNN) using dif-\nferent multiple-instance learning techniques (AUC=0.69-0.76) and a 3D CNN\n(AUC=.77).",
  "introduction": "This paper addresses the critical challenge of developing deep learning-based computer-aided diag-\nnosis (CAD) systems in radiology, which is often limited by the need for large, annotated medical\nimage datasets. It is particularly difficult to acquire manual annotations from radiologists, which\nis required to train deep models, especially for 3D imaging techniques like computed tomography\n(CT). As a result, it is frequently unfeasible to use a model trained using a large, labeled dataset. The\ndetection of emphysema, a disease associated with shortness of breath and an elevated risk of cancer,\nis one such area. Emphysema is frequently observed as ruptured air sacs within a small portion of\nthe lung volume. The wide range of manifestations in CT scans makes training a model to detect\nemphysema using solely volumetric imaging data and binary diagnostic labels difficult.\n\nA common strategy to enable learning without precise labels is multiple instance learning (MIL). In\nMIL, sets of samples are organized into labeled bags, with a positive label indicating the existence\nof positive samples within the bag. Prior research has effectively used a MIL framework to identify\nemphysema and other lung disorders on CT scans. It has been demonstrated that MIL, when used\nwith a handcrafted feature-based classifier to analyze a number of 2D patches from the lung, can\nidentify emphysema and other lung diseases. More recently, researchers reported positive results in\ngrading emphysema by summarizing the results of a convolutional neural network (CNN) across a\nset of 2D patches using a proportional method similar to MIL.\n\nA drawback of MIL-based techniques is their failure to maintain inter-sample relationships. For in-\nstance, MIL does not retain the spatial relationship between samples collected from an image, despite\nbeing successful in summarizing data from a number of samples. Furthermore, the effectiveness\nof MIL depends on the pooling strategy used to summarize predictions across the bag, a variable\nthat can greatly affect the instances in which a model succeeds or fails. For example, a maximum\npooling-based approach considers only the single sample with the strongest correlation to disease,\n\n.\n\n\fdisregarding any data from the bag\u2019s other samples. On the other hand, a mean pooling of predictions\nwithin a bag may fail to detect a disease present in only a small number of samples.\n\nRecurrent neural networks, such as long short-term memory (LSTM), are highly adept at identifying\ncorrelations between connected samples, such as in pattern recognition across time series data.\nConvolutional long short term memory (Conv-LSTM) expands this capability to spatial data by\napplying convolutional operations to an LSTM. Conv-LSTM has been highly successful in identifying\nchanges in image patterns over time, including applications like video classification and gesture\nrecognition. Instead of utilizing Conv-LSTM to identify spatiotemporal patterns from time series\nimage data, we suggest using it to \"scan\" through an imaging volume for the presence of disease\nwithout the need for expert annotations of the diseased regions. Our framework allows for the\nidentification of emphysema-related image patterns on and between slices as it processes the image\nvolume, unlike an MIL-based technique. The network stores emphysema-related image patterns\nthrough several bidirectional passes through a volume and produces a final set of characteristics that\ndescribe the full volume without the requirement for a possibly reductive bag pooling operation.\nOur method can make effective use of readily available, but weak, image labels (such as a binary\ndiagnosis of emphysema as positive or negative) for abnormality identification inside image volumes.",
  "related_work": "",
  "methodology": "2.1 Dataset and Processing\n\nA total of 8,794 non-contrast CT volumes from 6,648 unique participants in the National Lung\nScreening Trial (NLST) were used. We classified 3,807 CT volumes from 2,789 participants who\nwere diagnosed with emphysema during the three years of the study as positive samples, and 4,987 CT\nvolumes from 3,859 participants who were not diagnosed with emphysema in any of the three years\nas negative samples. 75% of these scans, with a balanced distribution of emphysema-positive and\nemphysema-negative patients, were utilized for model training. 4,197 volumes from 3,166 patients\nwere used to directly learn model parameters, while 2,434 volumes from 1,319 patients were used\nto fine-tune hyper-parameters and assess performance in order to select the best-performing model.\nThe remaining 2,163 volumes (578 emphysema positive, 1,585 emphysema negative), each from a\nunique patient, were held out for independent testing. Volumes were resized to 128x128x35, which\ncorresponds to an average slice spacing of 9 mm.\n\n2.2 Convolutional Long Short Term Memory (LSTM)\n\nThe architecture includes four units, each consisting of convolution operations applied to each slice\nindividually and a conv-LSTM to process the volume slice by slice. Two 3x3 convolutional layers\nwith batch normalization are followed by max-pooling. The output of the convolutional layers for\neach slice is then processed sequentially by the conv-LSTM layer in either forward or reverse order.\nThis outputs a set of features collected through convolutional operations using both the current slice\nand previous slices within the volume. All layers within a unit have the same number of filters\nand process the volume in either ascending or descending order. The four convolutional units have\nthe following dimensionality and directionality: Ascending 1: 32 filters, Descending 1: 32 filters,\nAscending 2: 64 filters, Descending 2: 64 filters. The final Conv-LSTM layer produces a single set of\nfeatures that summarizes the network\u2019s results after processing the full imaging volume multiple times.\nFinally, a fully-connected layer with sigmoid activation calculates the probability of emphysema. The\nnetwork, as illustrated in Figure 1, contains a total of 901,000 parameters. All models were trained\nfor 50 epochs or until validation set performance stopped improving.\n\n2.3 Comparison Experiments\n\nMultiple Instance Learning: We developed an MIL-based network in which each slice of the CT\nvolume was treated as a sample from a bag. We implemented a solely convolutional network design\nsimilar to the one shown in Figure 1, but with more single-slice convolutional layers instead of\nconv-LSTM layers, to achieve this. Various methods for summarizing predictions across the entire\nvolume into a single bag probability were investigated. The following methods can be used to\ncompute the overall probability, P, for a bag containing N samples with an individual probability of\nemphysema, pi, i 1, ..., N:\n\n2\n\n\f1. Max Pooling: P = max(pi)\n(cid:80)N\n2. Mean Pooling: P = 1\ni=1 pi\nN\n3. Product Pooling: P = 1 \u2212 (cid:81)N\n\ni=1(1 \u2212 pi)\n\n3D CNN: Conv-LSTM was also compared to a 3D CNN with a similar structure to the 2D CNN used\nwith MIL, with the exception of a single dense layer and no pooling action on the final convolutional\nlayer. The number of kernels for each comparison model was raised to make its number of parameters\nroughly comparable to that of our Conv-LSTM framework and ensure a fair comparison (Table 1).",
  "experiments": "",
  "results": "Convolutional-LSTM demonstrated high accuracy in the detection of emphysema when trained\nusing only weakly annotated imaging volumes, achieving an AUC of 0.82. It outperformed a CNN\nwith MIL, regardless of the pooling strategy (Max pooling: AUC=0.69, Mean Pooling: AUC=0.70,\nProduct pooling: AUC=0.76). At the optimal operating point corresponding to the Youden Index, our\nmodel achieved a sensitivity of 0.77 and a specificity of 0.74. The results for all evaluated models in\nthe testing set are shown in Table 1.\n\nModel\nF1\n\nMIL - Max Pooling\n0.63\nMIL - Mean Pooling\n0.66\nMIL - Product Pooling\n0.69\n3D CNN\n0.69\nConv-LSTM\n0.75\n\nKernels\n\n# Parameters AUC Sensitivity\n\nSpecificity\n\n64\n\n64\n\n64\n\n36\n\n32\n\n1,011,393\n\n0.69\n\n1,011,393\n\n0.70\n\n1,011,393\n\n0.76\n\n958,213\n\n901,793\n\n0.77\n\n0.83\n\n0.59\n\n0.76\n\n0.61\n\n0.61\n\n0.77\n\n0.68\n\n0.57\n\n0.79\n\n0.80\n\n0.74\n\nTable 1: Emphysema detection results in the testing set (2,219 CT volumes) and model size.\n\nOur method eliminates the need for manual processing or time-consuming annotation of imaging\ndata. Our framework makes it possible to train for disease detection using simple binary diagnostic\nlabels, even when the disease is confined to a small area of the image. As a result, our network\ncan be trained easily using information that can be gathered automatically by mining radiology\nreports. This significantly increases the amount of volumetric imaging data that can be used for\nthis kind of application and enables easy retraining and fine-tuning of an algorithm when used in a\ndifferent hospital. This strategy can be used in other disease/abnormality detection problems outside\nof emphysema when the amount of volumetric imaging data accessible is greater than the capacity of\nradiologists to offer manually drawn ground truth, but when labels may be readily retrieved from\nradiology reports.\n\n3",
  "conclusion": ""
}
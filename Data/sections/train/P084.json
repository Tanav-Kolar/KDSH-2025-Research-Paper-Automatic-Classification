{
  "title": "An Empirical Study of the \"Hard-Won Lesson\": Two\nDecades of Research Insights",
  "abstract": "This research investigates the congruence between research in major computer\nvision conferences and the tenets of the \"hard-won lesson\" articulated by Rich\nSutton. Utilizing large language models (LLMs), we scrutinize twenty years of\nabstracts and titles from these conferences to evaluate the field\u2019s acceptance of these\ncore concepts. Our approach employs cutting-edge natural language processing\nmethodologies to methodically chart the progression of research paradigms within\ncomputer vision. The findings indicate notable patterns in the implementation of\ngeneralized learning algorithms and the exploitation of enhanced computational\ncapabilities. We analyze the ramifications of these discoveries for the prospective\ntrajectory of computer vision research and its conceivable influence on the broader\ndevelopment of artificial intelligence. This investigation contributes to the persistent\ndiscourse regarding the most efficacious methods for propelling machine learning\nand computer vision forward, furnishing perspectives that could steer forthcoming\nresearch orientations and techniques in these domains.",
  "introduction": "Rich Sutton\u2019s seminal paper, \"The Hard-Won Lesson,\" posits that the most substantial progress in\nartificial intelligence (AI) has resulted from concentrating on broad methods that utilize computation,\nas opposed to human-derived representations and knowledge. This concept has been notably appar-\nent in Computer Vision (CV), a domain that has observed a discernible transition from manually\nengineered features to deep learning frameworks.\n\nIn this article, we explore the degree to which the abstracts from a prominent machine learning (ML)\nconference align with the principles of the \"hard-won lesson\" across two decades. Our analysis\nencompasses a randomized selection of 200 papers annually, addressing these research questions:\n\n\u2022 How has the emphasis on generalized methodologies and computational approaches devel-\n\noped in major computer vision conference abstracts over the last 20 years?\n\n\u2022 What discernible patterns can be observed regarding the embrace of deep learning method-\n\nologies and the departure from manually constructed features?\n\n\u2022 To what degree do the abstracts mirror the primary observations of Sutton\u2019s \"hard-won\n\nlesson,\" and how has this correlation altered over time?\n\n\u2022 Does a substantial correlation exist between a paper\u2019s alignment with the \"hard-won lesson\"\n\nprinciples and its influence, as gauged by its citation count?\n\nTo tackle these inquiries, we utilize large language models (LLMs), themselves a clear demonstration\nof the principles delineated in the \"hard-won lesson,\" to scrutinize the abstracts. This assessment\nhinges on five metrics assigned by the LLMs, offering a thorough evaluation of the congruence\nbetween the abstracts and the \"hard-won lesson.\"\n\nOur study provides valuable perspectives on the general trajectory of the ML community and uncovers\nintriguing patterns in the embrace of Sutton\u2019s principles. By employing LLMs to analyze a substantial\n\n.\n\n\fcorpus of research literature, we introduce an innovative method for comprehending the learning and\nprogression of a scientific field. This technique enables us to detect patterns and trends that might\nelude conventional research approaches, thereby delivering a more holistic understanding of the\ncurrent state of ML research and its alignment with the principles demonstrated to be most effective\nin driving AI advancements.\n\nThe prospective influence of our conclusions on forthcoming CV research directions is considerable.\nBy pinpointing trends in the adoption of generalized methods and deep learning techniques, we can\ncontribute to the advancement of foundational CV models at the cutting edge. These insights enhance\nour comprehension of the present state of ML research and illuminate potential avenues for further\ninvestigation and expansion in the field.\n\n2 Background\n\n2.1 The Hard-Won Lesson\n\nThe realm of artificial intelligence (AI) has experienced a fundamental change, eloquently expressed\nin Rich Sutton\u2019s influential essay \"The Hard-Won Lesson.\" Sutton\u2019s central idea underscores the\nimportance of generalized methods that utilize computational capability over human-engineered\nrepresentations and domain-specific expertise. This viewpoint resonates with Leo Breiman\u2019s earlier\nwork, which, twenty years prior, outlined the distinction between statistical and algorithmic methods\nin his paper \"Statistical Modeling: The Two Cultures.\" Breiman\u2019s insights, along with subsequent\ncontributions, have significantly influenced our comprehension of data-oriented approaches in AI.\n\n2.2 Evolution of Computer Vision\n\nThe discipline of Computer Vision (CV) serves as a prime illustration of the concepts articulated in\nSutton\u2019s \"hard-won lesson.\" Historically dependent on manually designed features such as SIFT, HOG,\nand Haar cascades for object recognition and image categorization, CV experienced a transformation\nwith the introduction of deep learning, particularly Convolutional Neural Networks (CNNs). This shift\nfacilitated the automated acquisition of hierarchical features directly from unprocessed image data,\nthereby bypassing the necessity for manual feature creation and markedly enhancing performance\nacross a range of CV applications.\n\nThe emergence of foundational models further aligned CV with Sutton\u2019s principles. Models like\nCLIP, ALIGN, and Florence demonstrate remarkable adaptability across diverse tasks with minimal\nfine-tuning, leveraging extensive multi-modal datasets to learn rich, transferable representations.\n\nThis progression from conventional feature engineering to deep learning and foundational models\nin CV highlights the significance of employing computational resources and extensive datasets to\nachieve enhanced performance and generalization.\n\n2.3 Large Language Models in Academic Evaluation\n\nThe incorporation of Large Language Models (LLMs) into the assessment of scholarly texts has\nbecome a notable area of focus. LLMs, like GPT-4, have shown impressive abilities in swiftly handling\nand examining vast quantities of data, making them appropriate for numerous uses, including the\nevaluation of academic papers.\n\nBeyond their analytical abilities, LLMs have been shown to possess a degree of human-like judgment\nin assessing the quality of text. The G-EVAL framework, which employs LLMs to evaluate the\nquality of natural language generation outputs, demonstrates that LLMs can closely align with human\nevaluators in certain contexts. However, deploying LLMs in academic evaluation is not without its\nchallenges. LLMs can exhibit biases similar to those found in human judgments, which may affect\nthe fairness and accuracy of their evaluations.\n\nThe function of LLMs in responding to inquiries and formulating hypotheses also deserves considera-\ntion. Their capacity to furnish comprehensive answers to intricate queries has been utilized in diverse\neducational environments, enhancing learning experiences and facilitating knowledge acquisition. In\nthe context of academic research, LLMs can aid in generating hypotheses and guiding exploratory\nstudies, contributing to the advancement of knowledge in various fields.\n\n2\n\n\fDespite the promising applications of LLMs in academic evaluation and research, it is crucial to\nestablish ethical guidelines and best practices for their use.\n\n3 Methodology and Evaluation\n\n3.1 LLM Evaluation of Titles and Abstracts\n\nWe utilize three large language models to assess the titles and abstracts of papers: GPT-4o-2024-05-\n13, gpt-4o-mini-2024-07-18, and claude-3-5-sonnet-20240620. The following details are extracted\nfrom online sources and stored in a database for each paper: Year of Publication (2005-2024), Title,\nAuthors, and Abstract. Additionally, the citation count for each paper is obtained from the Semantic\nScholar API on July 20th, 2024, and recorded alongside the other metadata.\n\nEach LLM is assigned the task of providing a Likert score ranging from 0 to 10, indicating the degree\nto which a paper corresponds with the principles outlined in Sutton\u2019s \"hard-won lesson.\" We employ\nthe Chain-of-Thought Prompting method in conjunction with the Magentic library to interact with\nthe models and accumulate their feedback in a structured manner for subsequent analysis.\n\nWe establish five dimensions for alignment with the \"hard-won lesson\":\n\n1. **Learning Over Engineering:** How much does the idea prioritize using computation through\ndata-driven learning and statistical methods over human-engineered knowledge and domain expertise?\n2. **Search over Heuristics:** To what extent does the idea emphasize leveraging computation\nthrough search algorithms and optimization techniques instead of relying on human-designed heuris-\ntics? 3. **Scalability with Computation:** How much is the idea based on methods that can\ncontinuously scale and improve performance as computational resources increase? 4. **Generality\nover Specificity:** How much does the approach emphasize general, flexible methods that learn from\ndata rather than building complex models of the world through manual engineering? 5. **Favoring\nFundamental Principles:** To what extent does the approach adhere to fundamental principles of\ncomputation and information theory rather than emulating human cognition?\n\nThe prompts were crafted to encapsulate the core of each \"hard-won lesson\" dimension in a succinct\nand impartial manner. To standardize the ratings, we furnish examples for the 0, 5, and 10 points on\neach dimension, elucidating the standards and guaranteeing uniform evaluations.\n\nGiven the large number of publications, our research concentrates on a representative random sample\nof 200 papers from each year. We define the overall alignment score for each paper as the sum of\nscores across the five dimensions.\n\n3.2\n\nInter-rater Reliability Measures\n\n**Intraclass Correlation Coefficient (ICC):** We employ ICC to measure the level of agreement\namong the models\u2019 evaluations. ICC is especially fitting for evaluating reliability when numerous\nraters assess an identical set of items. Specifically, we utilize the two-way random effects model\n(ICC(2,k)) to consider both rater and subject influences.\n\n**Krippendorff\u2019s Alpha:** In addition to ICC, we compute Krippendorff\u2019s Alpha, a flexible reliability\ncoefficient capable of managing diverse data types (nominal, ordinal, interval, ratio) and resilient to\nmissing data. This metric offers an supplementary viewpoint on inter-rater agreement, particularly\nbeneficial when addressing potential variations in rating scales or absent evaluations.\n\n3.3 Regression Analysis\n\nTo examine the connection between alignment scores and a paper\u2019s impact, we conduct a regression\nanalysis, using citation count as an indicator of influence. To manage the publication year and address\npotential temporal effects, we incorporate yearly stratification into our regression model. This method\nenables us to isolate the influence of alignment while accounting for the differing citation patterns\nacross various publication years.\n\nTo tackle the typically right-skewed distribution of citation counts, we employ a logarithmic transfor-\nmation on the data. This transformation achieves several objectives in our analysis: it diminishes\nskewness, yielding a more symmetrical distribution that more closely resembles normality; it stabi-\n\n3\n\n\flizes variance across the data range, reducing the heteroscedasticity often seen in citation count data\nwhere variance tends to rise with the mean; and it linearizes potentially multiplicative relationships,\nconverting them into additive ones.",
  "related_work": "",
  "methodology": "",
  "experiments": "",
  "results": "4.1\n\nInter-rater Reliability\n\nThe models show consistently strong agreement on all dimensions except \"Favoring Fundamental\nPrinciples,\" as indicated by ICC values above 0.5 and Krippendorff\u2019s alpha scores exceeding 0.4 on\nthe remaining dimensions. The dimension \"Learning Over Engineering\" exhibits the highest ICC and\nKrippendorff\u2019s alpha scores.\n\nAlthough perfect agreement is not achieved, the inter-reliability measures fall within or above\ncommon thresholds for \"good\" reliability, validating the use of AI models for prompt-based research\npaper evaluation.\n\n4.2 Regression Analysis\n\nTable 1 presents the regression analysis results for each dimension of \"hard-won lesson\" alignment\nscores against citation impact, stratified by year of publication. The R-squared values range from\n0.027 to 0.306.\n\nIn this regression analysis, a multiplicative effect implies that a one-unit change in the alignment\nscore for a particular dimension leads to a proportional change in the original scale of the citation\ncount.\n\nThe statistical significance of the regression coefficients is denoted using , , and to represent the\n10%, 5%, and 1% significance levels, respectively. Several dimensions, such as \"Scalability\" and\n\"Learning over engineering,\" exhibit statistically significant relationships with citation impact across\nmultiple years.\n\nTable 2 shows the results of regressing citation counts on the overall \"hard-won lesson\" alignment\nscore for each year between 2005 and 2024. The R-squared values are quite low for most years but\nincrease substantially starting in 2015.\n\n4.3 Trends in \"Hard-Won Lesson\" Alignment\n\nThe dimensions of \"Scalability with Computation\" and \"Learning Over Engineering\" show a consis-\ntent upward trend over the years. The period from 2015 to 2020 witnesses a particularly sharp rise in\nthe average scores for these dimensions.",
  "conclusion": "Our study scrutinized the concordance of research with Rich Sutton\u2019s \"hard-won lesson\" over two\ndecades, employing large language models to analyze trends. The results show a steady rise in\nthe adoption of general-purpose learning algorithms and scalability with computational resources,\nindicating a strong adherence to the core principles of the \"hard-won lesson.\" These trends highlight\nthe machine learning community\u2019s inclination towards data-driven and computation-intensive methods\nover manual engineering and domain-specific knowledge.\n\nHowever, the \"Search over Heuristics\" dimension has not shown a similar upward trend, suggesting\nlimited integration of search-based methods in the field. This stagnation contrasts with recent progress\nin inference-time scaling, exemplified by OpenAI\u2019s o1 models, which emphasize the importance of\ntest-time computation in overcoming diminishing returns.\n\nThe shift towards scaling inference time, driven by the development of larger and more complex\nmodels, has the potential to emulate search-like processes. As computational capabilities continue to\nexpand, it is plausible that future research may increasingly incorporate search techniques, thereby\nenhancing alignment with this dimension of the \"hard-won lesson.\"\n\n4\n\n\fTable 1: Regression analysis results for the relationship between \"hard-won lesson\" alignment scores\nand citation impact, stratified by year.\n\nYear\n\nR-squared N\n\nLearning\n\nSearch\n\nScalability Generality\n\nPrinciples\n\n0.027\n0.076\n0.035\n0.078\n0.085\n0.074\n0.076\n0.094\n0.085\n0.119\n0.264\n0.306\n0.313\n0.172\n0.111\n0.120\n0.090\n0.136\n0.123\n0.178\n\n0.139\n2005\n0.388*\n2006\n0.350*\n2007\n0.465***\n2008\n0.104\n2009\n0.218\n2010\n0.318**\n2011\n0.428**\n2012\n0.013\n2013\n0.308*\n2014\n0.417**\n2015\n0.517***\n2016\n0.751***\n2017\n0.418**\n2018\n0.229\n2019\n0.179\n2020\n0.253\n2021\n0.110\n2022\n0.664***\n2023\n0.808***\n2024\n*** indicates significance at the 1% level, ** indicates significance at the 5% level, and * indicates significance at the 10% level.\n\n0.104\n-0.042\n0.117\n0.096\n0.136\n-0.129\n-0.036\n0.077\n-0.112\n-0.085\n-0.145\n-0.300**\n-0.353**\n-0.322*\n-0.439**\n-0.411***\n-0.381***\n-0.137\n-0.009\n0.314\n\n-0.220\n0.016\n-0.087\n-0.009\n-0.073\n0.121\n0.208\n0.195\n0.395***\n0.408***\n0.515***\n0.637***\n0.418***\n0.291*\n0.573**\n0.315\n0.269*\n0.618***\n0.107\n-0.619***\n\n-0.171\n-0.171\n-0.318*\n-0.463***\n-0.631***\n-0.471**\n-0.423**\n-0.517**\n-0.279\n-0.266\n-0.122\n-0.372*\n-0.508**\n-0.436**\n-0.257\n0.010\n-0.265*\n-0.257\n-0.132\n-0.020\n\n0.272\n0.199\n-0.006\n-0.026\n0.378*\n0.016\n-0.284\n-0.110\n-0.119\n-0.348*\n-0.236\n-0.325\n-0.004\n0.156\n-0.099\n0.229\n-0.072\n-0.118\n-0.078\n0.282\n\n199\n200\n200\n200\n199\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n171\n\nIn summary, our findings underscore the enduring significance of the \"hard-won lesson\" in shaping\nthe path of computer vision research. By emphasizing generality and scalability, the field is well-\npositioned to leverage emerging computational advancements. Future work should explore the\nintegration of search methodologies and assess their impact on research impact and innovation within\ncomputer vision, particularly in light of recent breakthroughs in inference-time scaling.\n\n6 Limitations\n\nThis study has several limitations. First, our reliance on large language models (LLMs) for evaluating\nresearch abstracts introduces potential biases inherent to these models. Second, the absence of human\nexpert evaluation as a ground truth is a significant limitation.\n\nFurthermore, our analysis is limited to the information contained in titles and abstracts, which may\nnot capture the full depth and nuance of the methodologies and findings presented in the full papers.\nLastly, while our study spans two decades of proceedings, it does not account for research published\nin other venues or unpublished work that may have influenced the field.\n\nDespite these limitations, we believe our study provides valuable insights into broad trends in\ncomputer vision research and its alignment with the principles of the \"hard-won lesson.\" Future\nwork could address these limitations by incorporating human expert evaluations, analyzing full paper\ncontents, and expanding the scope to include a wider range of publication venues.\n\n7 Ethics Statement\n\nThis study adheres to ethical guidelines. Our use of large language models (LLMs) for analyzing\ntrends in academic literature raises important ethical considerations. We acknowledge that LLMs\nmay introduce biases when used for direct evaluation of academic work. However, our study focuses\nsolely on using LLMs to analyze broad trends rather than to assess individual papers\u2019 quality or merit.\n\nAll data were collected in accordance with applicable privacy and intellectual property laws. No\npersonally identifiable information was collected from human subjects. Our methodology aims to\n\n5\n\n\fTable 2: Regression analysis results for the relationship between overall \"hard-won lesson\" alignment\nscores and citation impact, stratified by year.\n\nYear\n\nR-squared N\n\nF-statistic\n\nProb (F-statistic) Overall Alignment Score\n\n0.007\n0.050\n0.003\n0.010\n0.015\n0.000\n0.000\n0.024\n0.005\n0.030\n0.170\n0.128\n0.133\n0.066\n0.021\n0.040\n0.002\n0.062\n0.063\n0.092\n\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n*** indicates significance at the 1% level, ** indicates significance at the 5% level, and * indicates significance at the 10% level.\n\n0.029 [-0.019, 0.076]\n0.083*** [0.032, 0.134]\n0.019 [-0.031, 0.068]\n0.031 [-0.012, 0.075]\n0.045* [-0.006, 0.097]\n0.005 [-0.049, 0.059]\n-0.000 [-0.051, 0.051]\n0.057** [0.006, 0.109]\n0.022 [-0.023, 0.067]\n0.056** [0.011, 0.101]\n0.141*** [0.097, 0.184]\n0.129*** [0.082, 0.176]\n0.182*** [0.117, 0.248]\n0.098*** [0.047, 0.150]\n0.061** [0.003, 0.119]\n0.079*** [0.025, 0.133]\n-0.017 [-0.068, 0.035]\n0.097*** [0.044, 0.149]\n0.099*** [0.046, 0.153]\n0.127*** [0.066, 0.188]\n\n1.409\n10.335\n0.554\n1.993\n2.998\n0.033\n0.000\n4.898\n0.944\n6.023\n40.618\n29.114\n30.338\n13.996\n4.241\n8.325\n0.407\n13.054\n13.416\n17.040\n\n0.237\n0.002\n0.457\n0.160\n0.085\n0.856\n0.993\n0.028\n0.333\n0.015\n0.000\n0.000\n0.000\n0.000\n0.041\n0.004\n0.524\n0.000\n0.000\n0.000\n\n199\n200\n200\n200\n199\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n171\n\nminimize risks by using multiple models and focusing on aggregate trends rather than individual\nassessments.\n\n6"
}
{
  "title": "Disparate Citation Patterns Between Chinese and\nAmerican Research Communities at a Unified Venue",
  "abstract": "At NeurIPS, there is a tendency for American and Chinese institutions to cite papers\nfrom within their own regions substantially more often than they cite papers from\nthe other region. To measure this divide, we construct a citation graph, compare\nit to European connectivity, and discuss both the causes and consequences of this\nseparation.",
  "introduction": "In recent years, the machine learning research community has been transformed by the rise of\nChinese AI research. China is now consistently the second-largest contributor of publications at\nNeurIPS, following the United States. In 2020, 13.6% of all NeurIPS publications came from Chinese\ninstitutions. The next year, this increased to 17.5%, a relative increase of 28.7%.\n\nDespite China\u2019s position as a leader in AI research, collaborations between Chinese and American\ninstitutions are less common than collaborations between American and Western European institutions.\nAnecdotally, researchers from these regions often form distinct social groups at machine learning\nconferences. This separation is not limited to just social interactions. A prominent professor in an\napplied area of machine learning publicly advised students to avoid talks by Chinese authors, arguing\nthat their presentations would be difficult to understand or of poor quality. Although many non-native\nEnglish speakers find it a challenge to speak in public, avoiding talks by Chinese researchers may\nlimit a conference attendee\u2019s exposure to new topics and ideas.\n\nThis study measures the separation between researchers in China and the United States. We use\nNeurIPS citation data to analyze the impact of work from US-based and China-based institutions,\nand find that Chinese institutions under-cite work from the US and Europe, and that both American\nand European institutions under-cite work from China.\n\n2 Citation Networks\n\n2.1 Methods\n\nTo quantify the divide between the regions, we compiled a citation graph using NeurIPS paper\ncitation data from SemanticScholar and institutional information about authors from AMiner. We\nfirst collected all paper titles from NeurIPS from 2012 to 2021 from the NeurIPS website. Using\nthe Semantic Scholar Academic Graph (S2AG) API, we then mapped paper titles to their Semantic\nScholar paper IDs. For unmatched papers we manually searched, finding all but one in the Semantic\nScholar database. We then used the S2AG API to identify the authors of each paper as well as the\nauthors of papers referenced by these papers.\n\nWe used AMiner to identify institutional information for each author. The 9460 NeurIPS papers have\n135,941 authors in total, of which we found institutions for 83,515 (61%). The 4038 papers lacking\nauthor information were excluded from the dataset. We then automatically identified institutes that\nincluded a country name, along with common cities and regions in China. We augmented these\nautomatic annotations with existing regional matchings and added 364 additional rules. Finally, we\n\n.\n\n\fremoved major multinational corporate labs (e.g., Google, Meta, Microsoft, Tencent, Alibaba, or\nHuawei). Of the remaining 5422 papers, we removed papers that were not from China, the US, or\nEurope, or included collaborators in multiple regions, leaving 1792 papers. Finally, we computed the\naverage number and proportion of citations between papers from each region, shown in Figure 1.\n\n2.2 Results\n\nWe observed the extent to which American and Chinese papers fail to cite each other. While American\npapers constitute 60% of our dataset, they only account for 34% of citations made by Chinese papers.\nAmerican citations of Chinese papers are even more striking: while Chinese papers account for\n34% of our dataset, they are only cited in 9% of American references. This is more profound when\ncomparing these values to American citations of European papers: even though the dataset has\nsix times more Chinese than European papers, American institutions cite Chinese papers less than\nEuropean papers.\n\nWe also observe that each region tends to cite its own papers more often: 21% for China, 41% for\nthe USA, and 14% for Europe. The division between American and Chinese research communities\nis much more pronounced than one would expect based on typical regional preferences. While\nAmerican and European research communities show similar citation behavior, Chinese institutions\ncite American and European papers less than other regions.\n\nUSA China Europe\n\nUSA\nChina\nEurope\n\n41\n34\n15\n\n9\n21\n9\n\n12\n6\n14\n\nTable 1: Proportion of papers from given regions citing other regions or endogenously. Values are in\npercentage.\n\n3 Limitations\n\nThe conclusions we make in this paper are dependent on a few key choices we made during our data\nselection process. First, while we consider institutions in the US as American, many US labs have\nclose ties to China, potentially underestimating the true divide. Some US labs are largely or entirely\nmade up of Chinese international students. Additionally, international students returning to their\nhome country may bring international connections, and we did not measure if their citation patterns\nfocus more on domestic papers or if they continue to cite American work. In addition, our filtering of\nmultinational corporate labs may be incomplete which could also affect our results.\n\nSecond, a number of papers were excluded from our analysis due to missing author information on\nAMiner, which is a Chinese platform. This may have resulted in the number of Chinese papers in the\ndataset being more than what there actually is. We discarded 43\n\n4 Consequences\n\nThough American and Chinese researchers publish in the same venues, they represent two parallel\ncommunities. To some degree, this can be attributed to different research interests due to cultural\nnorms influencing research priorities. For instance, multi-object tracking is an active area of research\nin China, with many large scale benchmarks. However, due to concerns surrounding privacy and\nmisuse, many North American researchers tend to avoid related topics. In general, the US tends to be\nheavily represented at fairness conferences, while representation from China is limited.\n\nNot only research topics are limited by this lack of exchange, but even abstract topics and architectures\nthat are popular in China are often not adopted in other regions. For example, PCANet, a popular\nimage classification architecture has most of its 1200 citations from Chinese or East Asian institutions.\nSimilarly, the Deep Forest model has garnered most of its 600 citations from Chinese researchers.\n\nRecently, the North American and European AI communities have increasingly engaged in conversa-\ntions regarding the ethical considerations of AI and have adopted review systems for ethical concerns\n\n2\n\n\fand required authors to include ethics statements. However, there has been limited engagement\nwith researchers from China regarding these topics, and ethics statements for Chinese-based AI\ninstitutions are similar to western ones. Despite such statements, specific disagreements regarding\nresearch practices still exist. For instance, while Duke University stopped providing the Duke-MTMC\ndataset, due to the ethical issues with the collection process, similar datasets from Chinese institutions\ncontinue to be actively used. This highlights the need for a discussion on the topic of the ethical\ndimensions of AI research between different communities.\n\nThe separation between the research communities has an impact on both researchers and societies as\na whole. It is crucial that the AI community initiates a discussion to overcome this barrier.\n\nAppendix A: Proof of Lemma 3\n\nAppendix B: Sub-Gaussian Covering Numbers for ReLU Networks\n\nC: Table 2\n\n\u2022 Name: name of the attack\n\u2022 Threat Model: the threat model used in the attack\n\n\u2013 \u2018aux\u2018 auxiliary information,\n\u2013 black - black box,\n\u2013 white - white box\n\n\u2022 Baseline: method used to determine the performance of the attack.\n\n\u2013 \u2018A\u2018 - absolute, the proportion of correctly identified data points or some other metric of\n\nattack success\n\n\u2013 \u2018M\u2018 - mathematical privacy metrics (e.g., k-anonymity, DP)\n\u2013 \u2018R\u2018 - random\n\u2013 \u2018C\u2018 - a control baseline which is a subset of the real data that was not used for the\n\ntraining data\n\n\u2013 \u2018SL\u2018 - metrics from supervised learning such as precision and recall\n\u2022 Attack estimator: The method used to estimate the success of an attack\n\n\u2013 \u2018IT\u2018 - information theory\n\u2013 \u2018NN\u2018 - nearest neighbor\n\u2013 \u2018ML\u2018 - machine learning\n\n\u2022 Attack Technique: The technique of the attack.\n\n\u2013 \u2018VRD\u2018 - vulnerable record discovery through searching or sampling\n\u2013 \u2018SM\u2018 - shadow modeling\n\u2013 \u2018MIA\u2018 - membership inference attack\n\n\u2022 Attack type (WP29) attack type based on WP29 specification.\n\n\u2013 \u2018S\u2018 - singling out\n\u2013 \u2018L\u2018 - linkage\n\u2013 \u2018I\u2018 - inference.\n\n3\n\n\fModel\nSymbiotic\n\nGCN\n0.38 \u00b1 0.01\n\n0.38 \u00b1 0.01\n\n0.35 \u00b1 0.01\n\n0.36 \u00b1 0.02\n\n0.03 \u00b1 0.01\n\n0.02 \u00b1 0.0\nGAT\n0.38 \u00b1 0.02\n\n0.3 \u00b1 0.03\n\n0.32 \u00b1 0.02\n\n0.3 \u00b1 0.03\n\n0.2 \u00b1 0.03\n\n0.19 \u00b1 0.02\nAPPNP\n0.47 \u00b1 0.01\n\n0.45 \u00b1 0.02\n\n0.51 \u00b1 0.04\n\n0.54 \u00b1 0.01\n\n0.09 \u00b1 0.01\n\n0.1 \u00b1 0.02\nGPRGNN\n0.33 \u00b1 0.01\n\n0.35 \u00b1 0.01\n\n0.4 \u00b1 0.01\n\n0.4 \u00b1 0.01\n\n0.08 \u00b1 0.02\n\n0.15 \u00b1 0.04\nRGCN\n0.47 \u00b1 0.01\n\n0.52 \u00b1 0.02\n\n0.15 \u00b1 0.03\n\nDataset\n\nClean\n\nEvasion\n\nPoisoning\n\nCiteSeer\n\n0.68 \u00b1 0.01\n\n0.41 \u00b1 0.01\n\n0.4 \u00b1 0.01\n\nCiteSeer-J\n\n0.68 \u00b1 0.01\n\n0.4 \u00b1 0.01\n\n0.4 \u00b1 0.02\n\nCora\n\n0.78 \u00b1 0.01\n\n0.37 \u00b1 0.02\n\n0.46 \u00b1 0.02\n\nCora-J\n\n0.74 \u00b1 0.01\n\n0.36 \u00b1 0.01\n\n0.43 \u00b1 0.02\n\nPubMed\n\n0.78 \u00b1 0.01\n\n0.05 \u00b1 0.01\n\n0.12 \u00b1 0.02\n\nPubMed-J\n\n0.77 \u00b1 0.01\n\n0.04 \u00b1 0.01\n\n0.11 \u00b1 0.01\n\nCiteSeer\n\n0.62 \u00b1 0.02\n\n0.3 \u00b1 0.03\n\n0.41 \u00b1 0.02\n\nCiteSeer-J\n\n0.64 \u00b1 0.01\n\n0.3 \u00b1 0.03\n\n0.41 \u00b1 0.03\n\nCora\n\n0.69 \u00b1 0.02\n\n0.29 \u00b1 0.02\n\n0.48 \u00b1 0.03\n\nCora-J\n\n0.67 \u00b1 0.01\n\n0.28 \u00b1 0.02\n\n0.45 \u00b1 0.02\n\nPubMed\n\n0.73 \u00b1 0.01\n\n0.24 \u00b1 0.02\n\n0.41 \u00b1 0.01\n\nPubMed-J\n\n0.74 \u00b1 0.01\n\n0.27 \u00b1 0.04\n\n0.38 \u00b1 0.04\n\nCiteSeer\n\n0.69 \u00b1 0.01\n\n0.47 \u00b1 0.01\n\n0.56 \u00b1 0.01\n\nCiteSeer-J\n\n0.68 \u00b1 0.01\n\n0.45 \u00b1 0.02\n\n0.52 \u00b1 0.02\n\nCora\n\n0.82 \u00b1 0.02\n\n0.54 \u00b1 0.02\n\n0.64 \u00b1 0.02\n\nCora-J\n\n0.82 \u00b1 0.01\n\n0.57 \u00b1 0.01\n\n0.67 \u00b1 0.01\n\nPubMed\n\n0.79 \u00b1 0.0\n\n0.09 \u00b1 0.02\n\n0.21 \u00b1 0.02\n\nPubMed-J\n\n0.77 \u00b1 0.01\n\n0.1 \u00b1 0.02\n\n0.19 \u00b1 0.03\n\nCiteSeer\n\n0.66 \u00b1 0.01\n\n0.34 \u00b1 0.01\n\n0.44 \u00b1 0.02\n\nCiteSeer-J\n\n0.65 \u00b1 0.01\n\n0.35 \u00b1 0.01\n\n0.44 \u00b1 0.01\n\nCora\n\n0.82 \u00b1 0.01\n\n0.46 \u00b1 0.01\n\n0.53 \u00b1 0.01\n\nCora-J\n\n0.79 \u00b1 0.01\n\n0.42 \u00b1 0.01\n\n0.54 \u00b1 0.01\n\nPubMed\n\n0.78 \u00b1 0.01\n\n0.08 \u00b1 0.02\n\n0.28 \u00b1 0.03\n\nPubMed-J\n\n0.78 \u00b1 0.01\n\n0.16 \u00b1 0.05\n\n0.38 \u00b1 0.04\n\nCiteSeer\n\n0.63 \u00b1 0.01\n\n0.39 \u00b1 0.01\n\n0.59 \u00b1 0.02\n\nCora\n\n0.74 \u00b1 0.02\n\n0.44 \u00b1 0.01\n\n0.74 \u00b1 0.01\n\nPubMed\n\n0.77 \u00b1 0.01\n\n0.43 \u00b1 0.01\n\n0.42 \u00b1 0.04\n\n4\n\n\fTable 2: Perturbed accuracies (\u00b1 standard error) of the joint and sequential attacks under the symbiotic\nthreat model with a 5% global budget. The -J suffix indicates the graph has been pre-processed with\nJaccard purification.\n\nDataset\n\nClean\n\nSequential\n\nJoint\n\nModel\n\nGCN\n\nGAT\n\nAPPNP\n\nCiteSeer\nCiteSeer-J\nCora\nCora-J\nPubMed\nPubMed-J\nCiteSeer\nCiteSeer-J\nCora\nCora-J\nPubMed\nPubMed-J\nCiteSeer\nCiteSeer-J\nCora\nCora-J\nPubMed\nPubMed-J\n\nGPRGNN CiteSeer\n\nCiteSeer-J\nCora\nCora-J\nPubMed\nPubMed-J\nCiteSeer\nCora\nPubMed\n\nRGCN\n\n0.68 \u00b1 0.01\n0.68 \u00b1 0.01\n0.78 \u00b1 0.01\n0.74 \u00b1 0.01\n0.78 \u00b1 0.01\n0.77 \u00b1 0.01\n0.62 \u00b1 0.02\n0.64 \u00b1 0.01\n0.69 \u00b1 0.02\n0.67 \u00b1 0.01\n0.73 \u00b1 0.01\n0.74 \u00b1 0.01\n0.69 \u00b1 0.01\n0.68 \u00b1 0.01\n0.82 \u00b1 0.02\n0.82 \u00b1 0.01\n0.79 \u00b1 0.0\n0.77 \u00b1 0.01\n0.66 \u00b1 0.01\n0.65 \u00b1 0.01\n0.82 \u00b1 0.01\n0.79 \u00b1 0.01\n0.78 \u00b1 0.01\n0.78 \u00b1 0.01\n0.63 \u00b1 0.01\n0.74 \u00b1 0.02\n0.77 \u00b1 0.01\n\n0.41 \u00b1 0.01\n0.4 \u00b1 0.01\n0.37 \u00b1 0.02\n0.36 \u00b1 0.01\n0.05 \u00b1 0.01\n0.04 \u00b1 0.01\n0.3 \u00b1 0.03\n0.3 \u00b1 0.03\n0.29 \u00b1 0.02\n0.28 \u00b1 0.02\n0.24 \u00b1 0.02\n0.27 \u00b1 0.04\n0.47 \u00b1 0.01\n0.45 \u00b1 0.02\n0.54 \u00b1 0.02\n0.57 \u00b1 0.01\n0.09 \u00b1 0.02\n0.1 \u00b1 0.02\n0.34 \u00b1 0.01\n0.35 \u00b1 0.01\n0.41 \u00b1 0.01\n0.42 \u00b1 0.01\n0.08 \u00b1 0.02\n0.16 \u00b1 0.05\n0.47 \u00b1 0.01\n0.56 \u00b1 0.01\n0.28 \u00b1 0.04\n\n0.38 \u00b1 0.01\n0.38 \u00b1 0.01\n0.35 \u00b1 0.01\n0.36 \u00b1 0.02\n0.03 \u00b1 0.01\n0.02 \u00b1 0.0\n0.38 \u00b1 0.02\n0.36 \u00b1 0.02\n0.32 \u00b1 0.02\n0.3 \u00b1 0.03\n0.2 \u00b1 0.03\n0.19 \u00b1 0.02\n0.48 \u00b1 0.01\n0.45 \u00b1 0.02\n0.51 \u00b1 0.04\n0.54 \u00b1 0.01\n0.09 \u00b1 0.01\n0.12 \u00b1 0.02\n0.33 \u00b1 0.01\n0.35 \u00b1 0.01\n0.4 \u00b1 0.01\n0.4 \u00b1 0.01\n0.11 \u00b1 0.03\n0.15 \u00b1 0.04\n0.47 \u00b1 0.01\n0.52 \u00b1 0.02\n0.15 \u00b1 0.03\n\n5",
  "related_work": "",
  "methodology": "",
  "experiments": "",
  "results": "",
  "conclusion": ""
}
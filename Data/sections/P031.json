{
  "title": "Explainable Identification of Hate Speech towards\nIslam using Graph Neural Networks",
  "abstract": "Islamophobic language on online platforms fosters intolerance, making detection\nand elimination crucial for promoting harmony. Traditional hate speech detection\nmodels rely on NLP techniques like tokenization, part-of-speech tagging, and\nencoder-decoder models. However, Graph Neural Networks (GNNs), with their\nability to utilize relationships between data points, offer more effective detection\nand greater explainability. In this work, speeches are represented as nodes and\nconnect them with edges based on their context and similarity to develop the graph.\nA novel paradigm using GNNs to identify and explain hate speech towards Islam is\nintroduced. The model leverages GNNs to understand the context and patterns of\nhate speech by connecting texts via pretrained NLP-generated word embeddings,\nachieving state-of-the-art performance and enhancing detection accuracy while pro-\nviding valuable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.",
  "introduction": "Detecting and eliminating hate speech on social media platforms is of utmost importance for the\npromotion of harmony and tranquility in society. The escalating presence of hate speech specifically\ntargeting Islam or Muslim communities on online discussion platforms is a growing concern. This\nform of hate speech not only fosters an environment of intolerance and hostility but can also have\nsevere psychological impacts on individuals and communities, leading to real-world violence and\ndiscrimination.\n\nTo address this issue, researchers have increasingly turned to advanced technologies; using text-\nprocessing approaches in AI. Natural Language Processing (NLP) techniques are frequently employed\nfor hate speech detection, with some offering severity assessment of hate speech. These methods\nutilize sophisticated algorithms to analyse vast amounts of textual data, identifying patterns and\nfeatures indicative of hate speech. For instance, deep learning models, like recurrent neural networks\n(RNNs), can learn complex representations of text data, enabling them to detect subtle and context-\ndependent instances of hate speech. Modern NLP techniques, on the other hand, can enhance these\nmodels by providing richer linguistic insights. Tokenization, part-of-speech tagging, and named\nentity recognition are just a few NLP techniques that help in breaking down and understanding the\ntext\u2019s structure and meaning. Moreover, the integration of latest NLP model and transformers, like\nBERT and GPT, has significantly improved the ability of models to understand context, sarcasm, and\nimplicit hate speech, which are often challenging to detect. Another interesting approach is to use\nhuman-centric perspectives of AI using some benchmark dataset.\n\nResearchers have tried to employ GNNs in hate speech classification, but still needs more focus\non this area. Despite their potential, GNNs have not been actively employed for the purpose of\ninterpretable identification of hate speech, particularly in Islamic contexts. Islamophobic content\noften exhibits close word choices and hate speakers from the same community, which GNNs can\nleverage to reveal and explain patterns, alongside impressive classification scores.\n\n\fA novel approach employing graph neural networks for the identification and explication of hate\nspeech directed at Islam (XG-HSI) is introduced. The dataset is pre-processed to focus on Islamic\ncontexts, utilize pretrained NLP models for word embeddings, establish connections between texts,\nand employ a series of graph encoders for hate speech target identification, which achieves state-of-\nthe-art performance.\n\n2 Background\n\nGraph Neural Networks (GNNs) are powerful neural networks designed for processing non-Euclidean\ndata organized in complex, interconnected graphs. Using their ability to utilize relations between\ndifferent data points, GNNs have shown tremendous promise in text classification and detection\ntasks. GNNs have the ability to enhance hate speech detection on social media by modeling complex\nrelationships between users and content, capturing contextual information from interactions. They\npropagate information across the network, identifying coordinated and evolving hate speech patterns.\nWe also present a case study in Section 5 to illustrate how incorporating related information enhances\nthe process.\n\nA general bag of words-based approach to create graphs, without LLMs is adopted. By integrating\nwith pretrained NLP models, GNNs leverage contextual word embeddings to better understand the\nsubtleties of hate speech. This combined approach improves the accuracy, context-awareness, and\nadaptability of detection systems, making them more effective in identifying hate speech directed at\nIslam and potentially generalizing to other targeted groups.",
  "related_work": "",
  "methodology": "3.1 Notations\n\nLet a graph G = (V, E, X), where V represents nodes, E denotes edges. We also define N and M as the\nnumbers of nodes and edges, respectively. Each node v is associated with a feature xi \u02d82208 RF , and\nthe node feature matrix for the entire graph is denoted as X \u02d82208 RN \u02d800d7F , where F represents the\nfeature vector length. In our approach, each content denotes a node, contextual similarity between\ntwo nodes is denoted by an edge and word embeddings are node features of the graph. The task\ninvolves a node classification task to detect hate speech and Islamophobic content.\n\n3.2 Data Pre-Processing\n\nInitially, the dataset was filtered to focus on hate speech targeting Islam. Next, pretrained NLP models\nis applied to the text to obtain word embeddings X as node features for all nodes V. Edges E are\ndetermined using cosine similarity between embeddings with a threshold of 0.725. Subsequently,\nGNN is applied for the classification task.\n\n3.3 Graph Encoder\n\nAfter data pre-processing, every data point x \u02d82282 X undergoes a series of transformations to get\noutput p. First, it is processed by a linear layer producing x1 (Equation 1).\n\nx1 = W x + b\n\n(1)\n\nSubsequently, x1 is passed into two initial graph encoders to aggregate neighborhood information,\nfeature extraction, and yield x2, x3 utilizing G and concatenated to x23 (Equation 2,3, 4). Here in\nEquation 2, we aggregate features from a node\u2019s local neighborhood, to learn different characteristics.\nIn Equation 3 and 4, we use a semi-supervised learning on graph-structured data, employing an\nefficient variant of convolutional neural networks that operate directly on graphs.\n\nx2 = W 1x1 + W 2 \u00b7 meanj\u2208N (i)x1\n\nx3 = W 1x1 + \u02c6Ax1\n\n2\n\n(2)\n\n(3)\n\n\fx23 = concat(x2, x3)\n\n(4)\n\nHere, N is the set of neighbouring nodes. Following this, x23 is passed through another graph layer\nemploying attention-based feature extraction, utilizing masked self-attentional layers to implicitly\nassign different weights to nodes in a neighbourhood, producing x4 (Equation 5 and 6).\n\nx4 = \u03b1i,i\u0398x23i +\n\n(cid:88)\n\nj\u2208N (i)\n\n\u03b1i,j\u0398x23j\n\n\u03b1i,j =\n\nexp(LeakyReLU (aT [\u0398x23i||\u0398x23j]))\nk\u2208N (i) exp(LeakyReLU (aT [\u0398x23i||\u0398x23k]))\n\n(cid:80)\n\n(5)\n\n(6)\n\nHere, \u02d803b8 refers to trainable model weights. \u02d803b1 is the attention value, calculated by the equation\nmentioned.\n\nFinally, x4 is passed through a final linear layer to obtain logits pl, which are then subjected to a\nsoftmax operation to derive probabilities p (Equation 7 amd 8).\n\nxc = concat(x1, x4); pl = W xc + b\n\np = sof tmax(pl)\n\n(7)\n\n(8)\n\n3.4 Loss Function\n\nCross Entropy loss is designed to minimize the difference between the predicted probabilities and\ntrue values, as follows:\n\nlce = \u2212\n\nn\n(cid:88)\n\ni=1\n\n3.5 Graph Explanation\n\n(pilog(o(pi)) + (1 \u2212 pi)log(1 \u2212 o(pi)))\n\n(9)\n\nGNNExplainer is used to derive explanations from the graph encoder network for interpreting the\nresults and find underlying relations and causation. It works by taking a trained GNN model and\nits predictions as input, and returns explanations in the form of compact subgraph structures and\nsubsets of influential node features. This model-agnostic approach can explain predictions of any\nGNN-based model on various graph-based machine learning tasks, including node classification,\nlink prediction, and graph classification. GNNExplainer formulates explanations as rich subgraphs\nof the input graph, maximizing mutual information with the GNN\u2019s predictions. It achieves this\nby employing a mean field variational approximation to learn real-valued graph masks that select\nimportant subgraphs and feature masks that highlight crucial node features. Through this process,\nGNNExplainer offers insights into the underlying reasoning of GNN predictions, enhancing model\ninterpretability and facilitating error analysis.",
  "experiments": "4.1 Experimental Setup\n\nDataset. HateXplain, a benchmark hate speech dataset designed for addressing bias and interpretabil-\nity is used. The dataset has hate speech targets labelled. This labelling is used to collect only\nMuslim-focused sentences and created a subset to work on this project. A 6:2:2 train, validation and\ntest split is used.\n\nBaselines. The baseline models are: CNN-GRU, BiRNN, BiRNN-HateXplain, BERT, BERT-\nHateXplain. Mentioned HateXplain-based models are fine-tuned on HateXplain dataset.\n\n3\n\n\fImplementation Details. Hugging Face transformers library is used to get embeddings from pre-\ntrained BERT (bert-base-uncased) and BiRNN. The model is trained for 200 epochs with a learning\nrate of 0.001, using Adam optimizer. The experimental results in Table 1 show that our model achieves\nremarkable performance comparing to benchmarks with explaining occurring phenomenons.We\nutilized a single layer for each type of GNN, with a maximum tokenization length of 512 in the\ntokenizer and length of BERT embeddings (F ) set to 128.\n\n4.2 Experimental Results\n\nTable 1 shows the performance of various models in detecting hate speech, highlighting accuracy and\nMacro F1 metrics. Traditional models like CNN-GRU and BiRNN show lower performance, with\nBiRNN-HateXplain offering slight improvements. BERT-based models perform better, particularly\nBERT-HateXplain. However, our proposed models, XG-HSI-BiRNN and XG-HSI-BERT, signifi-\ncantly outperform all others, with XG-HSI-BERT achieving the highest accuracy (0.741) and Macro\nF1 (0.747). These results demonstrate the superior effectiveness of our dual GNN approach in hate\nspeech detection.\n\nTable 1: Experimental Results (\u02d82191)\n\nModel\n\nAccuracy Macro F1\n\nCNN-GRU\nBiRNN\nBiRNN-HateXplain\nBERT\nBERT-HateXplain\nXG-HSI-BiRNN (Ours)\nXG-HSI-BERT (Ours)\n\n0.628\n0.591\n0.612\n0.692\n0.693\n0.742\n0.751\n\n0.604\n0.578\n0.621\n0.671\n0.681\n0.737\n0.747\n\n5 Graph Explanation Case Study\n\nFor a given post, \"How is all that awesome Muslim diversity going for you native germans? You\nhave allowed this yourselves. If you do not stand and fight against this. You get what you asked for\nwhat you deserve!\", the predicted classification was offensive towards Islam. As per the explainer,\nthe neighbouring and self-tokens helped to classify this as offensive to Muslims are fight, Muslim\ndiversity, brooks, rish, donald, syrian, schultz, typed. The text\u2019s association of \"Muslim diversity\"\nwith potential blame and its confrontational tone in phrases like \"stand and fight against this,\"\ncombined with neighbouring tokens like syrians, brooks, syrians denoted negative sentiment.\n\n6 Discussion\n\nThis study not only addresses the immediate challenge of identifying and explaining hate speech\ndirected at Islam but also recognizes the broader impact of hate speech propagation on online\nplatforms. The proliferation of Islamophobic language fosters intolerance, division, and hostility\nwithin communities, perpetuating harmful stereotypes and prejudices. By leveraging GNNs in our\nXG-HSI framework, we not only detect hate speech but also provide explanations for its occurrence,\nshedding light on the underlying factors driving such behaviour. GNNs excel in capturing complex\nrelationships and patterns within data, enabling them to effectively identify instances of hate speech\nand elucidate the contextual nuances surrounding them. By leveraging the inherent structure of social\nnetworks and textual data, our approach offers a comprehensive understanding of how hate speech\npropagates in online discourse.\n\nIn future research, exploring the integration of multimodal data sources, such as images and videos,\ncould enhance the robustness of hate speech detection models, particularly in detecting nuanced\nforms of Islamophobic content. Additionally, investigating the dynamic nature of online communities\nand incorporating temporal aspects into GNN architectures could provide deeper insights into the\nevolution of hate speech propagation and enable more proactive interventions to counter its spread.\n\n4",
  "results": "",
  "conclusion": "Identifying and addressing Islamophobic hatred on social media is crucial for achieving harmony\nand peace. This research presents a novel method using GNNs to detect hate speech towards Islam.\nEmpirical findings demonstrate that our model achieves exceptional performance, significantly\noutperforming all others, with XG-HSI-BERT achieving the highest accuracy (0.741) and Macro F1\n(0.747). Explainability aspect of this approach is also very promising, as it provides insights into\nboth correlations and causation. This further highlights the potential of GNNs in combating online\nhate speech and fostering a safer, more inclusive online environment.\n\nLimitations\n\nThe limitations include the use of only one dataset, which, while sufficient for this initial exploration,\nshould be expanded upon in future research to validate and extend our findings. Additionally, while\nGraph Neural Networks (GNNs) are known to be computationally intensive, especially with large-\nscale datasets, the relatively limited number of hate speech keywords suggests that GNNs may still\nbe highly effective. Furthermore, more efficient GNN training methods are now available, which\naddress some of the computational challenges in future applications.\n\nEthical Implications\n\nOur work on using GNNs to detect hate speech targeting Islam carries significant ethical responsibili-\nties. We focus on minimizing biases in the model to ensure fair treatment of all groups, emphasizing\nthe need for transparency in how the model arrives at its decisions. By using interpretable GNN\nmethods, we strive to provide clear explanations for the model\u2019s classifications, allowing for greater\naccountability. We also acknowledge the potential risks of misuse and take steps to prevent these,\nadhering to ethical guidelines that respect privacy and avoid unjust censorship.\n\nSocietal Implications\n\nThe societal impact lies in its potential to create a safer online environment by effectively identifying\nand mitigating Islamophobic content. By enhancing the detection accuracy and providing clear\nexplanations for the identified hate speech, our model contributes to fostering more inclusive and\nrespectful online communities. Additionally, our work highlights the importance of combating digital\nhate speech, which can lead to real-world harm. We aim to empower platforms and policymakers\nwith tools that uphold freedom of expression while curbing harmful rhetoric, thus promoting social\nharmony and understanding.\n\nPotential Risks\n\nThe application of our model presents several risks. One major concern is the potential for model\nmisclassification, which could lead to false positives or negatives, impacting users unfairly. Addition-\nally, there is a risk of over-reliance on automated systems, which might not capture nuanced contexts\nand could inadvertently suppress legitimate speech. Annotation errors can also induce bias, but as\nwe used a previously peer-reviewed benchmark dataset, we hope those type of concerns are already\naddressed.\n\nAcknowledgements\n\nSincere gratitude to the Computational Intelligence and Operations Laboratory (CIOL) for all their\nsupport. This work was presented at the Muslims in ML workshop (non-archival) at NeurIPS 2023,\nand thanks for their reviews, support, and the opportunity to present. Appreciation to all the reviewers\nfor their valuable suggestions to improve the work.\n\n5"
}
{
  "title": "Addressing Popularity Bias with Popularity-Conscious Alignment and\nContrastive Learning",
  "abstract": "distribution of items in real-world datasets. This tendency creates a notable difference in accuracy between items\nthat are popular and those that are not. This discrepancy impedes the accurate comprehension of user preferences\nand intensifies the Matthew effect within recommendation systems. To counter popularity bias, current methods\nconcentrate on highlighting less popular items or on differentiating the correlation between item representations\nand their popularity. Despite their effectiveness, current approaches continue to grapple with two significant\nissues: firstly, the extraction of shared supervisory signals from popular items to enhance the representations of\nless popular items, and secondly, the reduction of representation separation caused by popularity bias. In this\nstudy, we present an empirical examination of popularity bias and introduce a method called Popularity-Aware\nAlignment and Contrast (PAAC) to tackle these two problems. Specifically, we utilize the common supervisory\nsignals found in popular item representations and introduce an innovative popularity-aware supervised alignment\nmodule to improve the learning of representations for unpopular items. Furthermore, we propose adjusting the\nweights in the contrastive learning loss to decrease the separation of representations by focusing on popularity.\nWe confirm the efficacy and logic of PAAC in reducing popularity bias through thorough experiments on three\nreal-world datasets.",
  "introduction": "employ collaborative filtering (CF) to assist users in discovering items that may interest them. CF-based techniques primarily\nlearn user preferences and item attributes by matching the representations of users with the items they engage with. Despite their\nachievements, CF-based methods frequently encounter the issue of popularity bias, which leads to considerable disparities in\naccuracy between items that are popular and those that are not. Popularity bias occurs because there are limited supervisory signals\nfor items that are not popular, which results in overfitting during the training phase and decreased effectiveness on the test set. This\nhinders the precise comprehension of user preferences, thereby diminishing the variety of recommendations. Furthermore, popularity\nbias can worsen the Matthew effect, where items that are already popular gain even more popularity because they are recommended\nmore frequently.\n\nTwo significant challenges are presented when mitigating popularity bias in recommendation systems. The first challenge is the\ninadequate representation of unpopular items during training, which results in overfitting and limited generalization ability. The\nsecond challenge, known as representation separation, happens when popular and unpopular items are categorized into distinct\nsemantic spaces, thereby intensifying the bias and diminishing the precision of recommendations.",
  "related_work": "Popularity bias is a prevalent problem in recommender systems, where unpopular items in the training dataset are seldom recom-\nmended. Numerous techniques have been suggested to examine and decrease performance variations between popular and unpopular\nitems. These techniques can be broadly divided into three categories.\n\n\u2022 Re-weighting-based methods aim to increase the training weight or scores for unpopular items, redirecting focus away\nfrom popular items during training or prediction. For instance, IPS adds compensation to unpopular items and adjusts\nthe prediction of the user-item preference matrix, resulting in higher preference scores and improving rankings for\nunpopular items. \u03b1-AdjNorm enhances the focus on unpopular items by controlling the normalization strength during the\nneighborhood aggregation process in GCN-based models.\n\n\u2022 Decorrelation-based methods aim to effectively remove the correlations between item representations (or prediction scores)\nand popularity. For instance, MACR uses counterfactual reasoning to eliminate the direct impact of popularity on item\noutcomes. In contrast, InvCF operates on the principle that item representations remain invariant to changes in popularity\nsemantics, filtering out unstable or outdated popularity characteristics to learn unbiased representations.\n\n\u2022 Contrastive-learning-based methods aim to achieve overall uniformity in item representations using InfoNCE, preserving\nmore inherent characteristics of items to mitigate popularity bias. This approach has been demonstrated as a state-of-the-art\nmethod for alleviating popularity bias. It employs data augmentation techniques such as graph augmentation or feature\naugmentation to generate different views, maximizing positive pair consistency and minimizing negative pair consistency\nto promote more uniform representations. Specifically, Adap-\u03c4 adjusts user/item embeddings to specific values, while\nSimGCL integrates InfoNCE loss to enhance representation uniformity and alleviate popularity bias.\n\n4.2 Representation Learning for CF\n\nRepresentation learning is crucial in recommendation systems, especially in modern collaborative filtering (CF) techniques. It\ncreates personalized embeddings that capture user preferences and item characteristics. The quality of these representations critically\ndetermines a recommender system\u2019s effectiveness by precisely capturing the interplay between user interests and item features.\nRecent studies emphasize two fundamental principles in representation learning: alignment and uniformity. The alignment principle\nensures that embeddings of similar or related items (or users) are closely clustered together, improving the system\u2019s ability to\nrecommend items that align with a user\u2019s interests. This principle is crucial when accurately reflecting user preferences through\ncorresponding item characteristics. Conversely, the uniformity principle ensures a balanced distribution of all embeddings across the\nrepresentation space. This approach prevents the over-concentration of embeddings in specific areas, enhancing recommendation\ndiversity and improving generalization to unseen data.\n\nIn this work, we focus on aligning the representations of popular and unpopular items interacted with by the same user and re-\nweighting uniformity to mitigate representation separation. Our model PAAC uniquely addresses popularity bias by combining group\nalignment and contrastive learning, a first in the field. Unlike previous works that align positive user-item pairs or contrastive pairs,\nPAAC directly aligns popular and unpopular items, leveraging the rich information of popular items to enhance the representations\nof unpopular items and reduce overfitting. Additionally, we introduce targeted re-weighting from a popularity-centric perspective to\nachieve a more balanced representation.",
  "methodology": "method. We utilize the common supervisory signals present in popular item representations to direct the learning of unpopular\nrepresentations, and we present a popularity-aware supervised alignment module. Moreover, we incorporate a re-weighting system\nin the contrastive learning module to deal with representation separation by considering popularity.\n\n2.1 Supervised Alignment Module\n\nDuring the training process, the alignment of representations usually emphasizes users and items that have interacted, often causing\nitems to be closer to interacted users than non-interacted ones in the representation space. However, because unpopular items have\nlimited interactions, they are usually modeled based on a small group of users. This limited focus can result in overfitting, as the\nrepresentations of unpopular items might not fully capture their features.\n\n\fThe disparity in the quantity of supervisory signals is essential for learning representations of both popular and unpopular items.\nSpecifically, popular items gain from a wealth of supervisory signals during the alignment process, which helps in effectively\nlearning their representations. On the other hand, unpopular items, which have a limited number of users providing supervision, are\nmore susceptible to overfitting. This is because there is insufficient representation learning for unpopular items, emphasizing the\neffect of supervisory signal distribution on the quality of representation. Intuitively, items interacted with by the same user have\nsome similar characteristics. In this section, we utilize common supervisory signals in popular item representations and suggest a\npopularity-aware supervised alignment method to improve the representations of unpopular items.\n\nWe initially filter items with similar characteristics based on the user\u2019s interests. For any user, we define the set of items they interact\nwith. We count the frequency of each item appearing in the training dataset as its popularity. Subsequently, we group items based on\ntheir relative popularity. We divide items into two groups: the popular item group and the unpopular item group. The popularity of\neach item in the popular group is higher than that of any item in the unpopular group. This indicates that popular items receive more\nsupervisory information than unpopular items, resulting in poorer recommendation performance for unpopular items.\n\nTo tackle the issue of insufficient representation learning for unpopular items, we utilize the concept that items interacted with by the\nsame user share some similar characteristics. Specifically, we use similar supervisory signals in popular item representations to\nimprove the representations of unpopular items. We align the representations of items to provide more supervisory information to\nunpopular items and improve their representation, as follows:\n\nLSA =\n\n(cid:88)\n\nu\u2208U\n\n1\n|Iu|\n\n(cid:88)\n\n||f (i) \u2212 f (j)||2,\n\n(1)\n\ni\u2208I u\n\npop,j\u2208I u\n\nunpop\n\nwhere f (\u00b7) is a recommendation encoder and hi = f (i). By efficiently using the inherent information in the data, we provide more\nsupervisory signals for unpopular items without introducing additional side information. This module enhances the representation of\nunpopular items, mitigating the overfitting issue.\n\n2.2 Re-weighting Contrast Module\n\nRecent research has indicated that popularity bias frequently leads to a noticeable separation in the representation of item embeddings.\nAlthough methods based on contrastive learning aim to enhance overall uniformity by distancing negative samples, their current\nsampling methods might unintentionally worsen this separation. When negative samples follow the popularity distribution, which\nis dominated by popular items, prioritizing unpopular items as positive samples widens the gap between popular and unpopular\nitems in the representation space. Conversely, when negative samples follow a uniform distribution, focusing on popular items\nseparates them from most unpopular ones, thus worsening the representation gap. Existing studies use the same weights for positive\nand negative samples in the contrastive loss function, without considering differences in item popularity. However, in real-world\nrecommendation datasets, the impact of items varies due to dataset characteristics and interaction distributions. Neglecting this\naspect could lead to suboptimal results and exacerbate representation separation.\n\nWe propose to identify different influences by re-weighting different popularity items. To this end, we introduce re-weighting\ndifferent positive and negative samples to mitigate representation separation from a popularity-centric perspective. We incorporate\nthis approach into contrastive learning to better optimize the consistency of representations. Specifically, we aim to reduce the risk\nof pushing items with varying popularity further apart. For example, when using a popular item as a positive sample, our goal is\nto avoid pushing unpopular items too far away. Thus, we introduce two hyperparameters to control the weights when items are\nconsidered positive and negative samples.\n\nTo ensure balanced and equitable representations of items within our model, we first propose a dynamic strategy to categorize items\ninto popular and unpopular groups for each mini-batch. Instead of relying on a fixed global threshold, which often leads to the\noverrepresentation of popular items across various batches, we implement a hyperparameter x. This hyperparameter readjusts the\nclassification of items within the current batch. By adjusting the hyperparameter x, we maintain a balance between different item\npopularity levels. This enhances the model\u2019s ability to generalize across diverse item sets by accurately reflecting the popularity\ndistribution in the current training context. Specifically, we denote the set of items within each batch as IB. And then we divide IB\ninto a popular group Ipop and an unpopular group Iunpop based on their respective popularity levels, classifying the top x% of items\nas Ipop:\n\nIB = Ipop \u222a Iunpop, \u2200i \u2208 Ipop \u2227 j \u2208 Iunpop, p(i) > p(j),\n\n(2)\n\nwhere Ipop \u2208 IB and Iunpop \u2208 IB are disjoint, with Ipop consisting of the top x% of items in the batch. In this work, we dynamically\ndivided items into popular and unpopular groups within each mini-batch based on their popularity, assigning the top 50% as popular\nitems and the bottom 50% as unpopular items. This radio not only ensures equal representation of both groups in our contrastive\nlearning but also allows items to be classified adaptively based on the batch\u2019s current composition.\n\nAfter that, we use InfoNCE to optimize the uniformity of item representations. Unlike traditional CL-based methods, we calculate\nthe loss for different item groups. Specifically, we introduce the hyperparameter \u03b1 to control the positive sample weights between\npopular and unpopular items, adapting to varying item distributions in different datasets:\n\n2\n\n\fLCL\n\nitem = \u03b1 \u00d7 LCL\n\npop + (1 \u2212 \u03b1) \u00d7 LCL\n\nunpop,\n\n(3)\n\npop represents the contrastive loss when popular items are considered as positive samples, and LCL\n\nwhere LCL\nunpop represents the\ncontrastive loss when unpopular items are considered as positive samples. The value of \u03b1 ranges from 0 to 1, where \u03b1 = 0 means\nexclusive emphasis on the loss of unpopular items LCL\nunpop, and \u03b1 = 1 means exclusive emphasis on the loss of popular items\nLCL\npop. By adjusting \u03b1, we can effectively balance the impact of positive samples from both popular and unpopular items, allowing\nadaptability to varying item distributions in different datasets.\n\nFollowing this, we fine-tune the weighting of negative samples in the contrastive learning framework using the hyperparameter \u03b2.\nThis parameter controls how samples from different popularity groups contribute as negative samples. Specifically, we prioritize\nre-weighting items with popularity opposite to the positive samples, mitigating the risk of excessively pushing negative samples\naway and reducing representation separation. Simultaneously, this approach ensures the optimization of intra-group consistency. For\ninstance, when dealing with popular items as positive samples, we separately calculate the impact of popular and unpopular items\nas negative samples. The hyperparameter \u03b2 is then used to control the degree to which unpopular items are pushed away. This is\nformalized as follows:\n\n\u2032\nL\n\npop =\n\n(cid:88)\n\nlog\n\n(cid:80)\n\ni\u2208Ipop\n\nj\u2208Ipop\n\n\u2032\nexp(h\nihj/\u03c4 ) + \u03b2 (cid:80)\n\nihi/\u03c4 )\n\nexp(h\u2032\n\nj\u2208Iunpop\n\nexp(h\u2032\n\nihj/\u03c4 )\n\n,\n\nsimilarly, the contrastive loss for unpopular items is defined as:\n\n\u2032\nL\n\nunpop =\n\n(cid:88)\n\nlog\n\ni\u2208Iunpop\n\n(cid:80)\n\nj\u2208Iunpop\n\n\u2032\nihi/\u03c4 )\nexp(h\nihj/\u03c4 ) + \u03b2 (cid:80)\n\nexp(h\u2032\n\nexp(h\u2032\n\nihj/\u03c4 )\n\n,\n\nj\u2208Ipop\n\n(4)\n\n(5)\n\nwhere the parameter \u03b2 ranges from 0 to 1, controlling the negative sample weighting in the contrastive loss. When \u03b2 = 0, it means\nthat only intra-group uniformity optimization is performed. Conversely, when \u03b2 = 1, it means equal treatment of both popular and\nunpopular items in terms of their impact on positive samples. The setting of \u03b2 allows for a flexible adjustment between prioritizing\nintra-group uniformity and considering the impact of different popularity levels in the training. We prefer to push away items\nwithin the same group to optimize uniformity. This setup helps prevent over-optimizing the uniformity of different groups, thereby\nmitigating representation separation.\n\nThe final re-weighting contrastive objective is the weighted sum of the user objective and the item objective:\n\nLCL =\n\n1\n2\n\n\u00d7 (LCL\n\nitem + LCL\n\nuser).\n\n(6)\n\nIn this way, we not only achieved consistency in representation but also reduced the risk of further separating items with similar\ncharacteristics into different representation spaces, thereby alleviating the issue of representation separation caused by popularity\nbias.\n\n2.3 Model Optimization\n\nTo reduce popularity bias in collaborative filtering tasks, we employ a multi-task training strategy to jointly optimize the classic\nrecommendation loss (LREC), supervised alignment loss (LSA), and re-weighting contrast loss (LCL).\n\nL = LREC + \u03bb1LSA + \u03bb2LCL + \u03bb3||\u0398||2,\n\n(7)\n\nwhere \u0398 is the set of model parameters in LREC as we do not introduce additional parameters, \u03bb1 and \u03bb2 are hyperparameters that\ncontrol the strengths of the popularity-aware supervised alignment loss and the re-weighting contrastive learning loss respectively,\nand \u03bb3 is the L2 regularization coefficient. After completing the model training process, we use the dot product to predict unknown\npreferences for recommendations.",
  "experiments": "questions:\n\n\u2022 How does PAAC compare to existing debiasing methods?\n\u2022 How do different designed components play roles in our proposed PAAC?\n\n3\n\n\f\u2022 How does PAAC alleviate the popularity bias?\n\n\u2022 How do different hyper-parameters affect the PAAC recommendation performance?\n\n3.1 Experiments Settings\n\n3.1.1 Datasets\n\nIn our experiments, we use three widely public datasets: Amazon-book, Yelp2018, and Gowalla. We retained users and items with a\nminimum of 10 interactions.\n\n3.1.2 Baselines and Evaluation Metrics\n\nWe implement the state-of-the-art LightGCN to instantiate PAAC, aiming to investigate how it alleviates popularity bias. We\ncompare PAAC with several debiased baselines, including re-weighting-based models, decorrelation-based models, and contrastive\nlearning-based models.\n\nWe utilize three widely used metrics, namely Recall@K, HR@K, and NDCG@K, to evaluate the performance of Top-K recommen-\ndation. Recall@K and HR@K assess the number of target items retrieved in the recommendation results, emphasizing coverage. In\ncontrast, NDCG@K evaluates the positions of target items in the ranking list, with a focus on their positions in the list. We use\nthe full ranking strategy, considering all non-interacted items as candidate items to avoid selection bias during the test stage. We\nrepeated each experiment five times with different random seeds and reported the average scores.\n\n3.2 Overall Performance\n\nAs shown in Table 1, we compare our model with several baselines across three datasets. The best performance for each metric\nis highlighted in bold, while the second best is underlined. Our model consistently outperforms all compared methods across all\nmetrics in every dataset.\n\n\u2022 Our proposed model PAAC consistently outperforms all baselines and significantly mitigates the popularity bias. Specif-\nically, PAAC enhances LightGCN, achieving improvements of 282.65%, 180.79%, and 82.89% in NDCG@20 on the\nYelp2018, Gowalla, and Amazon-Book datasets, respectively. Compared to the strongest baselines, PAAC delivers better\nperformance. The most significant improvements are observed on Yelp2018, where our model achieves an 8.70% increase\nin Recall@20, a 10.81% increase in HR@20, and a 30.2% increase in NDCG@20. This improvement can be attributed\nto our use of popularity-aware supervised alignment to enhance the representation of less popular items and re-weighted\ncontrastive learning to address representation separation from a popularity-centric perspective.\n\n\u2022 The performance improvements of PAAC are smaller on sparser datasets. For example, on the Gowalla dataset, the\nimprovements in Recall@20, HR@20, and NDCG@20 are 3.18%, 5.85%, and 5.47%, respectively. This may be because,\nin sparser datasets like Gowalla, even popular items are not well-represented due to lower data density. Aligning unpopular\nitems with these poorly represented popular items can introduce noise into the model. Therefore, the benefits of using\nsupervisory signals for unpopular items may be reduced in very sparse environments, leading to smaller performance\nimprovements.\n\n\u2022 Regarding the baselines for mitigating popularity bias, the improvement of some is relatively limited compared to the\nbackbone model (LightGCN) and even performs worse in some cases. This may be because some are specifically designed\nfor traditional data-splitting scenarios, where the test set still follows a long-tail distribution, leading to poor generalization.\nSome mitigate popularity bias by excluding item popularity information. Others use invariant learning to remove popularity\ninformation at the representation level, generally performing better than the formers. This shows the importance of\naddressing popularity bias at the representation level. Some outperform the other baselines, emphasizing the necessary to\nimprove item representation consistency for mitigating popularity bias.\n\n\u2022 Different metrics across various datasets show varying improvements in model performance. This suggests that different\ndebiasing methods may need distinct optimization strategies for models. Additionally, we observe varying effects of PAAC\nacross different datasets. This difference could be due to the sparser nature of the Gowalla dataset. Conversely, our model\ncan directly provide supervisory signals for unpopular items and conduct intra-group optimization, consistently maintaining\noptimal performance across all metrics on the three datasets.\n\n3.3 Ablation Study\n\nTo better understand the effectiveness of each component in PAAC, we conduct ablation studies on three datasets. Table 2 presents a\ncomparison between PAAC and its variants on recommendation performance. Specifically, PAAC-w/o P refers to the variant where\nthe re-weighting contrastive loss of popular items is removed, focusing instead on optimizing the consistency of representations for\nunpopular items. Similarly, PAAC-w/o U denotes the removal of the re-weighting contrastive loss for unpopular items. PAAC-w/o\nA refers to the variant without the popularity-aware supervised alignment loss. It\u2019s worth noting that PAAC-w/o A differs from\n\n4\n\n\fTable 1: Performance comparison on three public datasets with K = 20. The best performance is indicated in bold, while the\nsecond-best performance is underlined. The superscripts * indicate p \u2264 0.05 for the paired t-test of PAAC vs. the best baseline (the\nrelative improvements are denoted as Imp.).\n\nModel\n\nMF\nLightGCN\nIPS\nMACR\n!\n\u03b1-Adjnorm\nInvCF\nAdap-\u03c4\nSimGCL\nPAAC\nImp.\n\nYelp2018\n\nGowalla\n\nAmazon-book\n\nRecall@20 HR@20 NDCG@20 Recall@20 HR@20 NDCG@20 Recall@20 HR@20 NDCG@20\n\n0.0050\n0.0048\n0.0104\n0.0402\n0.0053\n0.0444\n0.0450\n0.0449\n0.0494*\n+9.78 %\n\n0.0109\n0.0111\n0.0183\n0.0312\n0.0088\n0.0344\n0.0497\n0.0518\n0.0574*\n+10.81%\n\n0.0093\n0.0098\n0.0158\n0.0265\n0.0080\n0.0291\n0.0341\n0.0345\n0.0375*\n+8.70%\n\n0.0343\n0.0380\n0.0562\n0.0908\n0.0328\n0.1001\n0.1182\n0.1194\n0.1232*\n+3.18%\n\n0.0422\n0.0468\n0.0670\n0.1086\n0.0409\n0.1202\n0.1248\n0.1228\n0.1321*\n+5.85%\n\n0.0280\n0.0302\n0.0444\n0.0600\n0.0267\n0.0662\n0.0794\n0.0804\n0.0848*\n+5.47%\n\n0.0370\n0.0421\n0.0488\n0.0515\n0.0422\n0.0562\n0.0641\n0.0628\n0.0701*\n+9.36%\n\n0.0388\n0.0439\n0.0510\n0.0609\n0.0450\n0.0665\n0.0678\n0.0648\n0.0724*\n+6.78%\n\n0.0270\n0.0304\n0.0365\n0.0487\n0.0264\n0.0515\n0.0511\n0.0525\n0.0556*\n5.90%\n\nSimGCL in that we split the contrastive loss on the item side, LCL\nunpop. This approach\nallows us to separately address the consistency of popular and unpopular item representations, thereby providing a more detailed\nanalysis of the impact of each component on the overall performance.\n\nitem, into two distinct losses: LCL\n\npop and LCL\n\nFrom Table 2, we observe that PAAC-w/o A outperforms SimGCL in most cases. This validates that re-weighting the importance of\npopular and unpopular items can effectively improve the model\u2019s performance in alleviating popularity bias. It also demonstrates the\neffectiveness of using supervision signals from popular items to enhance the representations of unpopular items, providing more\nopportunities for future research on mitigating popularity bias. Moreover, compared with PAAC-w/o U, PAAC-w/o P results in much\nworse performance. This confirms the importance of re-weighting popular items in contrastive learning for mitigating popularity\nbias. Finally, PAAC consistently outperforms the three variants, demonstrating the effectiveness of combining supervised alignment\nand re-weighting contrastive learning. Based on the above analysis, we conclude that leveraging supervisory signals from popular\nitem representations can better optimize representations for unpopular items, and re-weighting contrastive learning allows the model\nto focus on more informative or critical samples, thereby improving overall performance. All the proposed modules significantly\ncontribute to alleviating popularity bias.\n\nTable 2: Ablation study of PAAC, highlighting the best-performing model on each dataset and metrics in bold. Specifically,\nPAAC-w/o P removes the re-weighting contrastive loss of popular items, PAAC-w/o U eliminates the re-weighting contrastive loss\nof unpopular items, and PAAC-w/o A omits the popularity-aware supervised alignment loss.\n\nModel\n\nYelp2018\n\nGowalla\n\nAmazon-book\n\nRecall@20 HR@20 NDCG@20 Recall@20 HR@20 NDCG@20 Recall@20 HR@20 NDCG@20\n\nSimGCL\n!\nPAAC-w/o P\nPAAC-w/o U\nPAAC-w/o A\nPAAC\n\n0.0449\n0.0443\n0.0462\n0.0466\n0.0494*\n\n0.0518\n0.0536\n0.0545\n0.0547\n0.0574*\n\n0.0345\n0.0340\n0.0358\n0.0360\n0.0375*\n\n0.1194\n0.1098\n0.1120\n0.1195\n0.1232*\n\n0.1228\n0.1191\n0.1179\n0.1260\n0.1321*\n\n0.0804\n0.0750\n0.0752\n0.0815\n0.0848*\n\n0.0628\n0.0616\n0.0594\n0.0687\n0.0701*\n\n0.0648\n0.0639\n0.0617\n0.0711\n0.0724*\n\n0.0525\n0.0458\n0.0464\n0.0536\n0.0556*\n\n3.4 Debias Ability\n\nTo further verify the effectiveness of PAAC in alleviating popularity bias, we conduct a comprehensive analysis focusing on the\nrecommendation performance across different popularity item groups. Specifically, 20% of the most popular items are labeled\n\u2019Popular\u2019, and the rest are labeled \u2019Unpopular\u2019. We compare the performance of PAAC with LightGCN, IPS, MACR, and SimGCL\nusing the NDCG@20 metric across different popularity groups. We use \u2206 to denote the accuracy gap between the two groups. We\ndraw the following conclusions:\n\n\u2022 Improving the performance of unpopular items is crucial for enhancing overall model performance. Specially, on the\nYelp2018 dataset, PAAC shows reduced accuracy in recommending popular items, with a notable decrease of 20.14%\ncompared to SimGCL. However, despite this decrease, the overall recommendation accuracy surpasses that of SimGCL\nby 11.94%, primarily due to a 6.81% improvement in recommending unpopular items. This improvement highlights the\nimportance of better recommendations for unpopular items and emphasizes their crucial role in enhancing overall model\nperformance.\n\n5\n\n\f\u2022 Our proposed PAAC significantly enhances the recommendation performance for unpopular items. Specifically, we observe\nan improvement of 8.94% and 7.30% in NDCG@20 relative to SimGCL on the Gowalla and Yelp2018 datasets, respectively.\nThis improvement is due to the popularity-aware alignment method, which uses supervisory signals from popular items to\nimprove the representations of unpopular items.\n\n\u2022 PAAC has successfully narrowed the accuracy gap between different item groups. Specifically, PAAC achieved the smallest\ngap, reducing the NDCG@20 accuracy gap by 34.18% and 87.50% on the Gowalla and Yelp2018 datasets, respectively.\nThis indicates that our method treats items from different groups fairly, effectively alleviating the impact of popularity\nbias. This success can be attributed to our re-weighted contrast module, which addresses representation separation from a\npopularity-centric perspective, resulting in more consistent recommendation results across different groups.\n\n3.5 Hyperparameter Sensitivities\n\nIn this section, we analyze the impact of hyperparameters in PAAC. Firstly, we investigate the influence of \u03bb1 and \u03bb2, which\nrespectively control the impact of the popularity-aware supervised alignment and re-weighting contrast loss. Additionally, in the\nre-weighting contrastive loss, we introduce two hyperparameters, \u03b1 and \u03b2, to control the re-weighting of different popularity items\nas positive and negative samples. Finally, we explore the impact of the grouping ratio x on the model\u2019s performance.\n\n3.5.1 Effect of \u03bb1 and \u03bb2\n\nAs formulated in Eq. (11), \u03bb1 controls the extent of providing additional supervisory signals for unpopular items, while \u03bb2 controls\nthe extent of optimizing representation consistency. Horizontally, with the increase in \u03bb2, the performance initially increases and\nthen decreases. This indicates that appropriate re-weighting contrastive loss effectively enhances the consistency of representation\ndistributions, mitigating popularity bias. However, overly strong contrastive loss may lead the model to neglect recommendation\naccuracy. Vertically, as \u03bb1 increases, the performance also initially increases and then decreases. This suggests that suitable\nalignment can provide beneficial supervisory signals for unpopular items, while too strong an alignment may introduce more noise\nfrom popular items to unpopular ones, thereby impacting recommendation performance.\n\n3.5.2 Effect of re-weighting coefficient \u03b1 and \u03b2\n\nTo mitigate representation separation due to imbalanced positive and negative sampling, we introduce two hyperparameters into the\ncontrastive loss. Specifically, \u03b1 controls the weight difference between positive samples from popular and unpopular items, while \u03b2\ncontrols the influence of different popularity items as negative samples.\n\nIn our experiments, while keeping other hyperparameters constant, we search \u03b1 and \u03b2 within the range {0, 0.2, 0.4, 0.6, 0.8, 1}. As\n\u03b1 and \u03b2 increase, performance initially improves and then declines. The optimal hyperparameters for the Yelp2018 and Gowalla\ndatasets are \u03b1 = 0.8, \u03b2 = 0.6 and \u03b1 = 0.2, \u03b2 = 0.2, respectively. This may be attributed to the characteristics of the datasets. The\nYelp2018 dataset, with a higher average interaction frequency per item, benefits more from a higher weight \u03b1 for popular items as\npositive samples. Conversely, the Gowalla dataset, being relatively sparse, prefers a smaller \u03b1. This indicates the importance of\nconsidering dataset characteristics when adjusting the contributions of popular and unpopular items to the model.\n\nNotably, \u03b1 and \u03b2 are not highly sensitive within the range [0, 1], performing well across a broad spectrum. Performance exceeds the\nbaseline regardless of \u03b2 values when other parameters are optimal. Additionally, \u03b1 values from [0.4, 1.0] on the Yelp2018 dataset\nand [0.2, 0.8] on the Gowalla dataset surpass the baseline, indicating less need for precise tuning. Thus, \u03b1 and \u03b2 achieve optimal\nperformance without meticulous adjustments, focusing on weight coefficients to maintain model efficacy.\n\n3.5.3 Effect of grouping ratio x\n\nTo investigate the impact of different grouping ratios on recommendation performance, we developed a flexible classification\nmethod for items within each mini-batch based on their popularity. Instead of adopting a fixed global threshold, which tends to\noverrepresent popular items in some mini-batches, our approach dynamically divides items in each mini-batch into popular and\nunpopular categories. Specifically, the top x% of items are classified as popular and the remaining (100 - x)% as unpopular, with x\nvarying. This strategy prevents the overrepresentation typical in fixed distribution models, which could skew the learning process\nand degrade performance. To quantify the effects of these varying ratios, we examined various division ratios for popular items,\nincluding 20%, 40%, 60%, and 80%, as shown in Table 3. The preliminary results indicate that both extremely low and high ratios\nnegatively affect model performance, thereby underscoring the superiority of our dynamic data partitioning approach. Moreover,\nwithin the 40%-60% range, our model\u2019s performance remained consistently robust, further validating the effectiveness of PAAC.\n\n6\n\n\fTable 3: Performance comparison across varying popular item ratios x on metrics.\n\nRatio\n\n!\n\n20%\n40%\n50%\n60%\n80%\n\nYelp2018\n\nGowalla\n\nRecall@20 HR@20 NDCG@20 Recall@20 HR@20 NDCG@20\n\n0.0467\n0.0505\n0.0494\n0.0492\n0.0467\n\n0.0555\n0.0581\n0.0574\n0.0569\n0.0545\n\n0.0361\n0.0378\n0.0375\n0.0370\n0.0350\n\n0.1232\n0.1239\n0.1232\n0.1225\n0.1176\n\n0.1319\n0.1325\n0.1321\n0.1314\n0.1270\n\n0.0845\n0.0848\n0.0848\n0.0843\n0.0818",
  "results": "",
  "conclusion": "engaged with by the same user exhibit common traits, and we utilized this insight to coordinate the representations of both popular\nand unpopular items via a popularity-conscious supervised alignment method. This strategy furnished additional supervisory data for\nless popular items. It is important to note that our concept of aligning and categorizing items according to user-specific preferences\nintroduces a fresh perspective on alignment. Moreover, we tackled the problem of representation separation seen in current CL-based\n\n7\n\n\fmodels by incorporating two hyperparameters to regulate the influence of items with varying popularity levels when considered\nas positive and negative samples. This method refined the uniformity of representations and successfully reduced separation. We\nvalidated our method, PAAC, on three publicly available datasets, demonstrating its effectiveness and underlying rationale.\n\nIn the future, we will explore deeper alignment and contrast adjustments tailored to specific tasks to further mitigate popularity\nbias. We aim to investigate the synergies between alignment and contrast and extend our approach to address other biases in\nrecommendation systems.\n\nAcknowledgments\n\nThis work was supported in part by grants from the National Key Research and Development Program of China, the National Natural\nScience Foundation of China, the Fundamental Research Funds for the Central Universities, and Quan Cheng Laboratory.\n\n8",
  "is_reference": true,
  "ref_category": "publishable",
  "is_publishable": 1,
  "venue": "KDD"
}
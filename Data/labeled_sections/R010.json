{
  "title": "Detecting Medication Usage in Parkinson\u2019s Disease Through\nMulti-modal Indoor Positioning: A Pilot Study in a Naturalistic\nEnvironment",
  "abstract": "impairment. The effectiveness of levodopa therapy, a common treatment for PD, can fluctuate, causing periods of\nimproved mobility (\"on\" state) and periods where symptoms re-emerge (\"off\" state). These fluctuations impact\ngait speed and increase in severity as the disease progresses. This paper proposes a transformer-based method that\nuses both Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices to enhance\nindoor localization accuracy. A secondary goal is to determine if indoor localization, particularly in-home gait\nspeed features (like the time to walk between rooms), can be used to identify motor fluctuations by detecting if a\nperson with PD is taking their levodopa medication or not. The method is evaluated using a real-world dataset\ncollected in a free-living setting, where movements are varied and unstructured. Twenty-four participants, living\nin pairs (one with PD and one control), resided in a sensor-equipped smart home for five days. The results show\nthat the proposed network surpasses other methods for indoor localization. The evaluation of the secondary goal\nreveals that accurate room-level localization, when converted into in-home gait speed features, can accurately\npredict whether a PD participant is taking their medication or not.",
  "introduction": "It manifests through various motor symptoms, including bradykinesia (slowness of movement), rigidity, and gait impairment. A\ncommon complication associated with levodopa, the primary medication for PD, is the emergence of motor fluctuations that are\nlinked to medication timing. Initially, patients experience a consistent and extended therapeutic effect when starting levodopa.\nHowever, as the disease advances, a significant portion of patients begin to experience \"wearing off\" of their medication before\nthe next scheduled dose, resulting in the reappearance of parkinsonian symptoms, such as slowed gait. These fluctuations in\nsymptoms negatively impact patients\u2019 quality of life and often necessitate adjustments to their medication regimen. The severity\nof motor symptoms can escalate to the point where they impede an individual\u2019s ability to walk and move within their own home.\nConsequently, individuals may be inclined to remain confined to a single room, and when they do move, they may require more time\nto transition between rooms. These observations could potentially be used to identify periods when PD patients are experiencing\nmotor fluctuations related to their medication being in an ON or OFF state, thereby providing valuable information to both clinicians\nand patients.\n\nA sensitive and accurate ecologically-validated biomarker for PD progression is currently unavailable, which has contributed to\nfailures in clinical trials for neuroprotective therapies in PD. Gait parameters are sensitive to disease progression in unmedicated\nearly-stage PD and show promise as markers of disease progression, making measuring gait parameters potentially useful in clinical\ntrials of disease-modifying interventions. Clinical evaluations of PD are typically conducted in artificial clinic or laboratory settings,\nwhich only capture a limited view of an individual\u2019s motor function. Continuous monitoring could capture symptom progression,\nincluding motor fluctuations, and sensitively quantify them over time.\n\nWhile PD symptoms, including gait and balance parameters, can be measured continuously at home using wearable devices\ncontaining inertial motor units (IMUs) or smartphones, this data does not show the context in which the measurements are taken.\nDetermining a person\u2019s location within a home (indoor localization) could provide valuable contextual information for interpreting\nPD symptoms. For instance, symptoms like freezing of gait and turning in gait vary depending on the environment, so knowing a\nperson\u2019s location could help predict such symptoms or interpret their severity. Additionally, understanding how much time someone\nspends alone or with others in a room is a step towards understanding their social participation, which impacts quality of life in\nPD. Localization could also provide valuable information in the measurement of other behaviors such as non-motor symptoms like\nurinary function (e.g., how many times someone visits the toilet room overnight).\n\n\fIoT-based platforms with sensors capturing various modalities of data, combined with machine learning, can be used for unobtrusive\nand continuous indoor localization in home environments. Many of these techniques utilize radio-frequency signals, specifically the\nReceived Signal Strength Indication (RSSI), emitted by wearables and measured at access points (AP) throughout a home. These\nsignals estimate the user\u2019s position based on perceived signal strength, creating radio-map features for each room. To improve\nlocalization accuracy, accelerometer data from wearable devices, along with RSSI, can be used to distinguish different activities\n(e.g., walking vs. standing). Since some activities are associated with specific rooms (e.g., stirring a pan on the stove is likely to\noccur in a kitchen), accelerometer data can enhance RSSI\u2019s ability to differentiate between adjacent rooms, an area where RSSI\nalone may be insufficient.\n\nThe heterogeneity of PD, where symptoms and their severity vary between patients, poses a challenge for generalizing accelerometer\ndata across different individuals. Severe symptoms, such as tremors, can introduce bias and accumulated errors in accelerometer data,\nparticularly when collected from wrist-worn devices, which are a common and well-accepted placement location. Naively combining\naccelerometer data with RSSI may degrade indoor localization performance due to varying tremor levels in the acceleration signal.\nThis work makes two primary contributions to address these challenges.\n\n(1) We detail the use of RSSI, augmented by accelerometer data, to achieve room-level localization. Our proposed network\nintelligently selects accelerometer features that can enhance RSSI performance in indoor localization. To rigorously assess our\nmethod, we utilize a free-living dataset (where individuals live without external intervention) developed by our group, encompassing\ndiverse and unstructured movements as expected in real-world scenarios. Evaluation on this dataset, including individuals with and\nwithout PD, demonstrates that our network outperforms other methods across all cross-validation categories.\n\n(2) We demonstrate how accurate room-level localization predictions can be transformed into in-home gait speed biomarkers (e.g.,\nnumber of room-to-room transitions, room-to-room transition duration). These biomarkers can effectively classify the OFF or ON\nmedication state of a PD patient from this pilot study data.",
  "related_work": "neurological conditions, primarily cognitive dysfunction, change over time. However, there is limited work assessing room use in\nthe home setting in people with Parkinson\u2019s.\n\nGait quantification using wearables or smartphones is an area where a significant amount of work has been done. Cameras can\nalso detect parkinsonian gait and some gait features, including step length and average walking speed. Time-of-flight devices,\nwhich measure distances between the subject and the camera, have been used to assess medication adherence through gait analysis.\nFrom free-living data, one approach to gait and room use evaluation in home settings is by emitting and detecting radio waves to\nnon-invasively track movement. Gait analysis using radio wave technology shows promise to track disease progression, severity, and\nmedication response. However, this approach cannot identify who is doing the movement and also suffers from technical issues\nwhen the radio waves are occluded by another object. Much of the work done so far using video to track PD symptoms has focused\non the performance of structured clinical rating scales during telemedicine consultations as opposed to naturalistic behavior, and\nthere have been some privacy concerns around the use of video data at home.\n\nRSSI data from wearable devices is a type of data with fewer privacy concerns; it can be measured continuously and unobtrusively\nover long periods to capture real-world function and behavior in a privacy-friendly way. In indoor localization, fingerprinting using\nRSSI is the typical technique used to estimate the wearable (user) location by using signal strength data representing a coarse and\nnoisy estimate of the distance from the wearable to the access point. RSSI signals are not stable; they fluctuate randomly due to\nshadowing, fading, and multi-path effects. However, many techniques have been proposed in recent years to tackle these fluctuations\nand indirectly improve localization accuracy. Some works utilize deep neural networks (DNN) to generate coarse positioning\nestimates from RSSI signals, which are then refined by a hidden Markov model (HMM) to produce a final location estimate. Other\nworks try to utilize a time series of RSSI data and exploit the temporal connections within each access point to estimate room-level\nposition. A CNN is used to build localization models to further leverage the temporal dependencies across time-series readings.\n\nIt has been suggested that we cannot rely on RSSI alone for indoor localization in home environments for PD subjects due to\nshadowing rooms with tight separation. Some researchers combine RSSI signals and inertial measurement unit (IMU) data to test\nthe viability of leveraging other sensors in aiding the positioning system to produce a more accurate location estimate. Classic\nmachine learning approaches such as Random Forest (RF), Artificial Neural Network (ANN), and k-Nearest Neighbor (k-NN) are\ntested, and the result shows that the RF outperforms other methods in tracking a person in indoor environments. Others combine\nsmartphone IMU sensor data and Wi-Fi-received signal strength indication (RSSI) measurements to estimate the exact location (in\nEuclidean position X, Y) of a person in indoor environments. The proposed sensor fusion framework uses location fingerprinting in\ncombination with a pedestrian dead reckoning (PDR) algorithm to reduce positioning errors.\n\nLooking at this multi-modality classification/regression problem from a time series perspective, there has been a lot of exploration\nin tackling a problem where each modality can be categorized as multivariate time series data. LSTM and attention layers are\noften used in parallel to directly transform raw multivariate time series data into a low-dimensional feature representation for each\nmodality. Later, various processes are done to further extract correlations across modalities through the use of various layers (e.g.,\nconcatenation, CNN layer, transformer, self-attention). Our work is inspired by prior research where we only utilize accelerometer\n\n2\n\n\fdata to enrich the RSSI, instead of utilizing all IMU sensors, in order to reduce battery consumption. In addition, unlike previous\nwork that stops at predicting room locations, we go a step further and use room-to-room transition behaviors as features for a binary\nclassifier predicting whether people with PD are taking their medications or withholding them.\n\n3 Cohort and Dataset\n\n**Dataset:** This dataset was collected using wristband wearable sensors, one on each wrist of all participants, containing tri-axial\naccelerometers and 10 Access Points (APs) placed throughout the residential home, each measuring the RSSI. The wearable devices\nwirelessly transmit data using the Bluetooth Low Energy (BLE) standard, which can be received by the 10 APs. Each AP records the\ntransmitted packets from the wearable sensor, which contains the accelerometer readings sampled at 30Hz, with each AP recording\nRSSI values sampled at 5 Hz.\n\nThe dataset contains 12 spousal/parent-child/friend-friend pairs (24 participants in total) living freely in a smart home for five days.\nEach pair consists of one person with PD and one healthy control volunteer (HC). This pairing was chosen to enable PD vs. HC\ncomparison, for safety reasons, and also to increase the naturalistic social behavior (particularly amongst the spousal pairs who\nalready lived together). From the 24 participants, five females and seven males have PD. The average age of the participants is 60.25\n(PD 61.25, Control 59.25), and the average time since PD diagnosis for the person with PD is 11.3 years (range 0.5-19).\n\nTo measure the accuracy of the machine learning models, wall-mounted cameras are installed on the ground floor of the house,\nwhich capture red-green-blue (RGB) and depth data 2-3 hours daily (during daylight hours at times when participants were at home).\nThe videos were then manually annotated to the nearest millisecond to provide localization labels. Multiple human labelers used\nsoftware called ELAN to watch up to 4 simultaneously-captured video files at a time. The resulting labeled data recorded the kitchen,\nhallway, dining room, living room, stairs, and porch. The duration of labeled data recorded by the cameras for PD and HC is 72.84\nand 75.31 hours, respectively, which provides a relatively balanced label set for our room-level classification. Finally, to evaluate\nthe ON/OFF medication state, participants with PD were asked to withhold their dopaminergic medications so that they were in\nthe practically-defined OFF medications state for a temporary period of several hours during the study. Withholding medications\nremoves their mitigation on symptoms, leading to mobility deterioration, which can include slowing of gait.\n\n**Data pre-processing for indoor localization:** The data from the two wearable sensors worn by each participant were combined at\neach time point, based on their modality, i.e., twenty RSSI values (corresponding to 10 APs for each of the two wearable sensors)\nand accelerometry traces in six spatial directions (corresponding to the three spatial directions (x, y, z) for each wearable) were\nrecorded at each time point. The accelerometer data is resampled to 5Hz to synchronize the data with RSSI values. With a 5-second\ntime window and a 5Hz sampling rate, each RSSI data sample has an input of size (25 x 20), and accelerometer data has an input of\nsize (25 x 6). Imputation for missing values, specifically for RSSI data, is applied by replacing the missing values with a value that is\nnot possible normally (i.e., -120dB). Missing values exist in RSSI data whenever the wearable is out of range of an AP. Finally, all\ntime-series measurements by the modalities are normalized.\n\n**Data pre-processing for medication state:** Our main focus is for our neural network to continuously produce room predictions,\nwhich are then transformed into in-home gait speed features, particularly for persons with PD. We hypothesize that during their\nOFF medication state, the deterioration in mobility of a person with PD is exhibited by how they transition between rooms. These\nfeatures include \u2019Room-to-room Transition Duration\u2019 and the \u2019Number of Transitions\u2019 between two rooms. \u2019Number of Transitions\u2019\nrepresents how active PD subjects are within a certain period of time, while \u2019Room-to-room Transition Duration\u2019 may provide\ninsight into how severe their disease is by the speed with which they navigate their home environment. With the layout of the house\nwhere participants stayed, the hallway is used as a hub connecting all other rooms labeled, and \u2019Room-to-room Transition\u2019 shows\nthe transition duration (in seconds) between two rooms connected by the hallway. The transition between (1) kitchen and living\nroom, (2) kitchen and dining room, and (3) dining room and living room are chosen as the features due to their commonality across\nall participants. For these features, we limit the transition time duration (i.e., the time spent in the hallway) to 60 seconds to exclude\ntransitions likely to be prolonged and thus may not be representative of the person\u2019s mobility.\n\nThese in-home gait speed features are produced by an indoor-localization model by feeding RSSI signals and accelerometer data\nfrom 12 PD participants from 6 a.m. to 10 p.m. daily, which are aggregated into 4-hour windows. From this, each PD participant\nwill have 20 data samples (four data samples for each of the five days), each of which contains six features (three for the mean of\nroom-to-room transition duration and three for the number of room-to-room transitions). There is only one 4-hour window during\nwhich the person with PD is OFF medications. These samples are then used to train a binary classifier determining whether a person\nwith PD is ON or OFF their medications.\n\nFor a baseline comparison to the in-home gait speed features, demographic features which include age, gender, years of PD, and\nMDS-UPDRS III score (the gold-standard clinical rating scale score used in clinical trials to measure motor disease severity in\nPD) are chosen. Two MDS-UPDRS III scores are assigned for each PD participant; one is assigned when a person with PD is ON\nmedications, and the other one is assigned when a person with PD is OFF medications. For each in-home gait speed feature data\nsample, there will be a corresponding demographic feature data sample that is used to train a different binary classifier to predict\nwhether a person with PD is ON or OFF medications.\n\n**Ethical approval:** Full approval from the NHS Wales Research Ethics Committee was granted on December 17, 2019, and\nHealth Research Authority and Health and Care Research Wales approval was confirmed on January 14, 2020; the research was\n\n3\n\n\fconducted in accord with the Helsinki Declaration of 1975; written informed consent was gained from all study participants. In\norder to protect participant privacy, supporting data is not shared openly. It will be made available to bona fide researchers subject to\na data access agreement.\n\n4 Methodologies and Framework\n\nWe introduce Multihead Dual Convolutional Self Attention (MDCSA), a deep neural network that utilizes dual modalities for indoor\nlocalization in home environments. The network addresses two challenges that arise from multimodality and time-series data:\n\n(1) Capturing multivariate features and filtering multimodal noises. RSSI signals, which are measured at multiple access points\nwithin a home received from wearable communication, have been widely used for indoor localization, typically using a fingerprinting\ntechnique that produces a ground truth radio map of a home. Naturally, the wearable also produces acceleration measurements which\ncan be used to identify typical activities performed in a specific room, and thus we can explore if accelerometer data will enrich\nthe RSSI signals, in particular to help distinguish adjacent rooms, which RSSI-only systems typically struggle with. If it will, how\ncan we incorporate these extra features (and modalities) into the existing features for accurate room predictions, particularly in the\ncontext of PD where the acceleration signal may be significantly impacted by the disease itself?\n\n(2) Modeling local and global temporal dynamics. The true correlations between inputs both intra-modality (i.e., RSSI signal among\naccess points) and inter-modality (i.e., RSSI signal against accelerometer fluctuation) are dynamic. These dynamics can affect one\nanother within a local context (e.g., cyclical patterns) or across long-term relationships. Can we capture local and global relationships\nacross different modalities?\n\nThe MDCSA architecture addresses the aforementioned challenges through a series of neural network layers, which are described in\nthe following sections.\n\n4.1 Modality Positional Embedding\n\nDue to different data dimensionality between RSSI and accelerometer, coupled with the missing temporal information, a linear\nlayer with a positional encoding is added to transform both RSSI and accelerometer data into their respective embeddings. Suppose\nT ] \u2208 RT \u00d7a within\nwe have a collection of RSSI signals xr = [xr\nt2, ..., xa\nT time units, where xr\nta] represents\naccelerometer data from a spatial directions at time t with t < T . Given feature vectors xt = [xr\nt ] with u \u2208 {r, a} representing\nRSSI or accelerometer data at time t, and t < T representing the time index, a positional embedding hu\nt for RSSI or accelerometer\ncan be obtained by:\n\ntr] represents RSSI signals from r access points, and xa\n\nT ] \u2208 RT \u00d7r and accelerometer data xa = [xa\n\n2, ..., xa\nt1, xa\n\n1, xa\nt = [xa\n\nt2, ..., xr\n\n2, ..., xr\n\nt = [xr\n\nt1, xr\n\nt , xa\n\n1, xr\n\nwhere Wu \u2208 Ru\u00d7d and bu \u2208 Rd are the weight and bias to learn, d is the embedding dimension, and \u03c4t \u2208 Rd is the corresponding\nposition encoding at time t.\n\nt = (Wuxu\nhu\n\nt + bu) + \u03c4t\n\n(1)\n\n4.2 Locality Enhancement with Self-Attention\n\nSince it is time-series data, the importance of an RSSI or accelerometer value at each point in time can be identified in relation to its\nsurrounding values - such as cyclical patterns, trends, or fluctuations. Utilizing historical context that can capture local patterns on\ntop of point-wise values, performance improvements in attention-based architectures can be achieved. One straightforward option is\nto utilize a recurrent neural network such as a long-short term memory (LSTM) approach. However, in LSTM layers, the local\ncontext is summarized based on the previous context and the current input. Two similar patterns separated by a long period of time\nmight have different contexts if they are processed by the LSTM layers. We utilize a combination of causal convolution layers and\nself-attention layers, which we name Dual Convolutional Self-Attention (DCSA). The DCSA takes in a primary input \u02c6x1 \u2208 RN \u00d7d\nand a secondary input \u02c6x2 \u2208 RN \u00d7d and yields:\n\nDCSA(\u02c6x1, \u02c6x2) = GRN (N orm(\u03d5(\u02c6x1) + \u02c6x1), N orm(\u03d5(\u02c6x2) + \u02c6x2))\n\nwith\n\n\u03d5(\u02c6x) = SA(\u03a6k(\u02c6x)WQ, \u03a6k(\u02c6x)WK, \u03a6k(\u02c6x)WV )\n\n(2)\n\n(3)\n\nwhere GRN (.) is the Gated Residual Network to integrate dual inputs into one integrated embedding, N orm(.) is a standard layer\nnormalization, SA(.) is a scaled dot-product self-attention, \u03a6k(.) is a 1D-convolutional layer with a kernel size {1, k} and a stride\nof 1, WK \u2208 Rd\u00d7d, WQ \u2208 Rd\u00d7d, WV \u2208 Rd\u00d7d are weights for keys, queries, and values of the self-attention layer, and d is the\nembedding dimension. Note that all weights for GRN are shared across each time step t.\n\n4\n\n\f4.3 Multihead Dual Convolutional Self-Attention\n\nOur approach employs a self-attention mechanism to capture global dependencies across time steps. It is embedded as part of the\nDCSA architecture. Inspired by utilizing multihead self-attention, we utilize our DCSA with various kernel lengths with the same\naim: allowing asymmetric long-term learning. The multihead DCSA takes in two inputs \u02c6x1, \u02c6x2 \u2208 RN \u00d7d and yields:\n\nwith\n\nM DCSAk1,...,kn (\u02c6x1, \u02c6x2) = \u039en(\u03d5k1,...,kn (\u02c6x1, \u02c6x2))\n\n\u03d5ki(\u02c6x1, \u02c6x2) = SA(\u03a6ki(\u02c6x1)WQ, \u03a6ki(\u02c6x2)WK, \u03a6ki(\u02c6x1, \u02c6x2)WV )\n\n(4)\n\n(5)\n\nwhere \u03a6ki(.) is a 1D-convolutional layer with a kernel size {1, ki} and a stride ki, WK \u2208 Rd\u00d7d, WQ \u2208 Rd\u00d7d, WV \u2208 Rd\u00d7d are\nweights for keys, queries, and values of the self-attention layer, and \u039en(.) concatenates the output of each DCSAki(.) in temporal\norder. For regularization, a normalization layer followed by a dropout layer is added after Equation 4.\nFollowing the modality positional embedding layer in subsection 4.1, the positional embeddings of RSSI hr = [hr\naccelerometer ha = [ha\n\n1, ..., hr\nT ], produced by Eq. 1, are then fed to an MDCSA layer with various kernel sizes [k1, ..., kn]:\n\n1, ..., ha\n\nT ] and\n\nto yield h = [h1, ..., hT ] with ht \u2208 Rd and t < T .\n\n4.4 Final Layer and Loss Calculation\n\nh = M DCSAk1,...,kn (hr, ha)\n\n(6)\n\nWe apply two different layers to produce two different outputs during training. The room-level predictions are produced via a single\nconditional random field (CRF) layer in combination with a linear layer applied to the output of Eq. 7 to produce the final predictions\nas:\n\n\u02c6yt = CRF (\u03d5(ht))\nq\u2032(ht) = Wpht + bp\n\n(7)\n\n(8)\n\nwhere Wp \u2208 Rd\u00d7m and bp \u2208 Rm are the weight and bias to learn, m is the number of room locations, and h = [h1, ..., hT ] \u2208 RT \u00d7d\nis the refined embedding produced by Eq. 7. Even though the transformer can take into account neighbor information before\ngenerating the refined embedding at time step t, its decision is independent; it does not take into account the actual decision made by\nother refined embeddings t. We use a CRF layer to cover just that, i.e., to maximize the probability of the refined embeddings of all\ntime steps, so it can better model cases where refined embeddings closest to one another must be compatible (i.e., minimizing the\npossibility for impossible room transitions). When finding the best sequence of room location \u02c6yt, the Viterbi Algorithm is used as a\nstandard for the CRF layer.\n\nFor the second layer, we choose a particular room as a reference and perform a binary classification at each time step t. The binary\nclassification is produced via a linear layer applied to the refined embedding ht as:\n\n\u02c6ft = Wf ht + bf\n\n(9)\n\nwhere Wf \u2208 Rd\u00d71 and bf \u2208 R are the weight and bias to learn, and \u02c6f = [ \u02c6f1, ..., \u02c6fT ] \u2208 RT is the target probabilities for the\nreferenced room within time window T . The reason to perform a binary classification against a particular room is because of our\ninterest in improving the accuracy in predicting that room. In our application, the room of our choice is the hallway, where it will be\nused as a hub connecting any other room.\n\n**Loss Functions:** During the training process, the MDCSA network produces two kinds of outputs. Emission outputs (outputs\nproduced by Equation 9 prior to prediction outputs) \u02c6e = [\u03d5(h1), ..., \u03d5(hT )] are trained to generate the likelihood estimate of room\npredictions, while the binary classification output \u02c6f = [ \u02c6f1, ..., \u02c6fT ] is used to train the probability estimate of a particular room. The\nfinal loss function can be formulated as a combination of both likelihood and binary cross-entropy loss functions described as:\n\nL(\u02c6e, y, \u02c6f , f ) = LLL(\u02c6e, y) +\n\nT\n(cid:88)\n\nt=1\n\nLBCE( \u02c6ft, ft)\n\nLLL(\u02c6e, y) =\n\nT\n(cid:88)\n\ni=0\n\nP (\u03d5(hi))qT\n\ni (yi|yi\u22121) \u2212\n\nT\n(cid:88)\n\ni=0\n\nP (\u03d5(hi))[qT\n\ni (yi|yi\u22121)]\n\n5\n\n(10)\n\n(11)\n\n\fLBCE( \u02c6f , f ) = \u2212\n\n1\nT\n\nT\n(cid:88)\n\nt=0\n\nft log( \u02c6ft) + (1 \u2212 ft) log(1 \u2212 \u02c6ft)\n\n(12)\n\nwhere LLL(.) represents the negative log-likelihood and LBCE(.) denotes the binary cross-entropy, y = [y1, ..., yT ] \u2208 RT is the\nactual room locations, and f = [f1, ..., fT ] \u2208 RT is the binary value whether at time t the room is the referenced room or not.\nP (yi|yi\u22121) denotes the conditional probability, and P (yt|yt\u22121) denotes the transition matrix cost of having transitioned from yt\u22121\nto yt.",
  "methodology": "",
  "experiments": "We compare our proposed network, MDCSA1,4,7 (MDCSA with 3 kernels of size 1, 4, and 7), with:\n\n- Random Forest (RF) as a baseline technique, which has been shown to work well for indoor localization. - A modified transformer\nencoder in combination with a CRF layer representing a model with the capability to capture global dependency and enforce\ndependencies in temporal aspects. - A state-of-the-art model for multimodal and multivariate time series with a transformer encoder\nto learn asymmetric correlations across modalities. - An alternative to the previous model, representing it with a GRN layer replacing\nthe context aggregation layer and a CRF layer added as the last layer. - MDCSA1,4,7 4APS, as an ablation study, with our proposed\nnetwork (i.e., MDCSA1,4,7) using 4 access points for the RSSI (instead of 10 access points) and accelerometer data (ACCL) as its\ninput features. - MDCSA1,4,7 RSSI, as an ablation study, with our proposed network using only RSSI, without ACCL, as its input\nfeatures. - MDCSA1,4,7 4APS RSSI, as an ablation study, with our proposed network using only 4 access points for the RSSI as its\ninput features.\n\nFor RF, all the time series features of RSSI and accelerometry are flattened and merged into one feature vector for room-level\nlocalization. For the modified transformer encoder, at each time step t, RSSI xr\nt features are combined via a\nlinear layer before they are processed by the networks. A grid search on the parameters of each network is performed to find the best\nparameter for each model. The parameters to tune are the embedding dimension d in 128, 256, the number of epochs in 200, 300,\nand the learning rate in 0.01, 0.0001. The dropout rate is set to 0.15, and a specific optimizer in combination with a Look-Ahead\nalgorithm is used for the training with early stopping using the validation performance. For the RF, we perform a cross-validated\nparameter search for the number of trees (200, 250), the minimum number of samples in a leaf node (1, 5), and whether a warm start\nis needed. The Gini impurity is used to measure splits.\n\nt and accelerometer xa\n\n**Evaluation Metrics:** We are interested in developing a system to monitor PD motor symptoms in home environments. For\nexample, we will consider if there is any significant difference in the performance of the system when it is trained with PD data\ncompared to being trained with healthy control (HC) data. We tailored our training procedure to test our hypothesis by performing\nvariations of cross-validation. Apart from training our models on all HC subjects (ALL-HC), we also perform four different kinds of\ncross-validation: 1) We train our models on one PD subject (LOO-PD), 2) We train our models on one HC subject (LOO-HC), 3) We\ntake one HC subject and use only roughly four minutes\u2019 worth of data to train our models (4m-HC), 4) We take one PD subject and\nuse only roughly four minutes\u2019 worth of data to train our models (4m-PD). For all of our experiments, we test our trained models on\nall PD subjects (excluding the one used as training data for LOO-PD and 4m-PD). For room-level localization accuracy, we use\nprecision and weighted F1-score, all averaged and standard deviated across the test folds.\n\nTo showcase the importance of in-home gait speed features in differentiating the medication state of a person with PD, we first\ncompare how accurate the \u2019Room-to-room Transition\u2019 duration produced by each network is to the ground truth (i.e., annotated\nlocation). We hypothesize that the more accurate the transition is compared to the ground truth, the better mobility features are for\nmedication state classification. For the medication state classification, we then compare two different groups of features with two\nsimple binary classifiers: 1) the baseline demographic features (see Section 3), and 2) the normalized in-home gait speed features.\nThe metric we use for ON/OFF medication state evaluation is the weighted F1-Score and AUROC, which are averaged and standard\ndeviated across the test folds.\n\n5.1 Experimental Results\n\n**Room-level Accuracy:** The first part of Table 1 compares the performance of the MDCSA network and other approaches for\nroom-level classification. For room-level classification, the MDCSA network outperforms other networks and RF with a minimum\nimprovement of 1.3% for the F1-score over the second-best network in each cross-validation type, with the exception of the ALL-HC\nvalidation. The improvement is more significant in the 4m-HC and 4m-PD validations, when the training data are limited, with an\naverage improvement of almost 9% for the F1-score over the alternative to the state-of-the-art model.\n\nThe LOO-HC and LOO-PD validations show that a model that has the ability to capture the temporal dynamics across time steps will\nperform better than a standard baseline technique such as a Random Forest. The modified transformer encoder and the state-of-the-art\nmodel perform better in those two validations due to their ability to capture asynchronous relations across modalities. However,\nwhen the training data becomes limited, as in 4m-HC and 4m-PD validations, having extra capabilities is necessary to further\nextract temporal information and correlations. Due to being a vanilla transformer requiring a considerable amount of training\ndata, the modified transformer encoder performs worst in these two validations. The state-of-the-art model performs quite well\n\n6\n\n\fdue to its ability to capture local context via LSTM for each modality. However, in general, its performance suffers in both the\nLOO-PD and 4m-PD validations as the accelerometer data (and modality) may be erratic due to PD and should be excluded at\ntimes from contributing to room classification. The MDCSA network has all the capabilities that the state-of-the-art model has,\nwith an improvement in suppressing the accelerometer modality when needed via the GRN layer embedded in DCSA. Suppressing\nthe noisy modality seems to have a strong impact on maintaining the performance of the network when the training data is limited.\nThis is validated by how the alternative to the state-of-the-art model (i.e., the state-of-the-art model with added GRN and CRF\nlayers) outperforms the standard state-of-the-art model by an average of 2.2% for the F1-score in the 4m-HC and 4m-PD validations.\nIt is further confirmed by MDCSA1,4,7 4APS against MDCSA1,4,7 4APS RSSI, with the latter model, which does not include\nthe accelerometer data, outperforming the former for the F1-score by an average of 1.6% in the last three cross-validations. It is\nworth pointing out that the MDCSA1,4,7 4APS RSSI model performed the best in the 4m-PD validation. However, the omission of\naccelerometer data affects the model\u2019s ability to differentiate rooms that are more likely to have active movement (i.e., hall) than the\nrooms that are not (i.e., living room). It can be seen from Table 2 that the MDCSA1,4,7 4APS RSSI model has low performance in\npredicting the hallway compared to the full model of MDCSA1,4,7. As a consequence, the MDCSA1,4,7 4APS RSSI model cannot\nproduce in-home gait speed features as\n\naccurately, as shown in Table 3.\n\n**Room-to-room Transition and Medication Accuracy:** We hypothesize that during their OFF medication state, the deterioration\nin mobility of a person with PD is exhibited by how they transition between rooms. To test this hypothesis, a Wilcoxon signed-rank\ntest was used on the annotated data from PD participants undertaking each of the three individual transitions between rooms whilst\nON (taking) and OFF (withholding) medications to assess whether the mean transition duration ON medications was statistically\nsignificantly shorter than the mean transition duration for the same transition OFF medications for all transitions studied (see Table\n4). From this result, we argue that the mean transition duration obtained by each model from Table 1 that is close to the ground truth\ncan capture what the ground truth captures. As mentioned in Section 3, this transition duration for each model is generated by the\nmodel continuously performing room-level localization, focusing on the time a person is predicted to spend in a hallway between\nrooms. We show, in Table 3, that the mean transition duration for all transitions studied produced by the MDCSA1,4,7 model is the\nclosest to the ground truth, improving over the second best by around 1.25 seconds across all hall transitions and validations.\n\nThe second part of Table 1 shows the performance of all our networks for medication state classification. The demographic\nfeatures can be used as a baseline for each type of validation. The MDCSA network, with the exception of the ALL-HC validation,\noutperforms any other network by a significant margin for the AUROC score. By using in-home gait speed features produced by\nthe MDCSA network, a minimum of 15% improvement over the baseline demographic features can be obtained, with the biggest\ngain obtained in the 4m-PD validation data. In the 4m-PD validation data, RF, TENER, and DTML could not manage to provide\nany prediction due to their inability to capture (partly) hall transitions. Furthermore, TENER has shown its inability to provide any\nmedication state prediction from the 4m-HC data validations. It can be validated by Table 3 when TENER failed to capture any\ntransitions between the dining room and living room across all periods that have ground truths. MDCSA networks can provide\nmedication state prediction and maintain their performance across all cross-validations thanks to the addition of Eq. 13 in the loss\nfunction.\n\n**Limitations and future research:** One limitation of this study is the relatively small sample size (which was planned as this is\nan exploratory pilot study). We believe our sample size is ample to show proof of concept. This is also the first such work with\nunobtrusive ground truth validation from embedded cameras. Future work should validate our approach further on a large cohort\nof people with PD and consider stratifying for sub-groups within PD (e.g., akinetic-rigid or tremor-dominant phenotypes), which\nwould also increase the generalizability of the results to the wider population. Future work in this matter could also include the\nconstruction of a semi-synthetic dataset based on collected data to facilitate a parallel and large-scale evaluation.\n\nThis smart home\u2019s layout and parameters remain constant for all the participants, and we acknowledge that the transfer of this deep\nlearning model to other varied home settings may introduce variations in localization accuracy. For future ecological validation and\nbased on our current results, we anticipate the need for pre-training (e.g., a brief walkaround which is labeled) for each home, and\nalso suggest that some small amount of ground-truth data will need to be collected (e.g., researcher prompting of study participants to\nundertake scripted activities such as moving from room to room) to fully validate the performance of our approach in other settings.",
  "results": "",
  "conclusion": "accelerometer data. The evaluation on our unique real-world free-living pilot dataset, which includes subjects with and without PD,\nshows that MDCSA achieves state-of-the-art accuracy for indoor localization. The availability of accelerometer data does indeed\nenrich the RSSI features, which, in turn, improves the accuracy of indoor localization.\n\nAccurate room localization using these data modalities has a wide range of potential applications within healthcare. This could\ninclude tracking of gait speed during rehabilitation from orthopedic surgery, monitoring wandering behavior in dementia, or\ntriggering an alert for a possible fall (and long lie on the floor) if someone is in one room for an unusual length of time. Furthermore,\naccurate room use and room-to-room transfer statistics could be used in occupational settings, e.g., to check factory worker location.\n\n7\n\n\fTable 1: Room-level and medication state accuracy of all models. Standard deviation is shown in (.), the best performer is bold,\nwhile the second best is italicized. Note that our proposed model is the one named MDCSA1,4,7\n\nTraining Model\n\nRoom-Level Localisation\n\nMedication State\n\nPrecision\n\nF1-Score\n\nF1-Score\n\nAUROC\n\nALL-HC\n\nLOO-HC\n\n!\n\nLOO-PD\n\n4m-HC\n\n4m-PD\n\nRF\nTENER\nDTML\nAlt DTML\nMDCSA1,4,7 4APS\nMDCSA1,4,7 RSSI\nMDCSA1,4,7 4APS RSSI\nMDCSA1,4,7\nDemographic Features\n\nRF\nTENER\nDTML\nAlt DTML\nMDCSA1,4,7 4APS\nMDCSA1,4,7 RSSI\nMDCSA1,4,7 4APS RSSI\nMDCSA1,4,7\nDemographic Features\n\nRF\nTENER\nDTML\nAlt DTML\nMDCSA1,4,7 4APS\nMDCSA1,4,7 RSSI\nMDCSA1,4,7 4APS RSSI\nMDCSA1,4,7\nDemographic Features\n\nRF\nTENER\nDTML\nAlt DTML\nMDCSA1,4,7 4APS\nMDCSA1,4,7 RSSI\nMDCSA1,4,7 4APS RSSI\nMDCSA1,4,7\nDemographic Features\n\nRF\nTENER\nDTML\nAlt DTML\nMDCSA1,4,7 4APS\nMDCSA1,4,7 RSSI\nMDCSA1,4,7 4APS RSSI\nMDCSA1,4,7\nDemographic Features\n\n95.00\n94.60\n94.80\n94.80\n92.22\n94.70\n93.30\n94.90\n\n89.67 (1.85)\n90.35 (1.87)\n90.51 (1.95)\n90.52 (2.17)\n88.01 (6.92)\n90.26 (2.43)\n88.55 (6.67)\n91.39 (2.13)\n\n86.89 (7.14)\n86.91 (6.76)\n87.13 (6.53)\n87.36 (6.30)\n86.44 (6.96)\n87.61 (6.64)\n87.20 (7.17)\n88.04 (6.94)\n\n74.27 (8.99)\n69.86 (18.68)\n77.10 (9.89)\n78.79 (3.95)\n81.42 (6.95)\n81.69 (6.85)\n82.80 (7.82)\n83.32 (6.65)\n\n71.00 (9.67)\n65.30 (23.25)\n70.35 (14.17)\n74.43 (9.59)\n81.02 (8.48)\n77.47 (12.54)\n83.01 (6.42)\n83.30 (6.73)\n\n95.20\n94.80\n94.90\n95.00\n92.22\n94.90\n93.10\n95.10\n\n88.95 (2.61)\n89.75 (2.24)\n89.82 (2.60)\n89.71 (2.83)\n88.08 (5.73)\n89.48 (3.47)\n88.75 (5.50)\n91.06 (2.62)\n\n84.71 (7.33)\n86.18 (6.01)\n86.31 (6.32)\n86.44 (6.63)\n85.93 (6.05)\n87.21 (5.44)\n87.00 (6.12)\n87.82 (6.01)\n\n69.87 (7.21)\n60.71 (24.94)\n70.12 (14.26)\n71.44 (9.82)\n78.65 (7.59)\n77.12 (8.46)\n79.37 (8.98)\n80.24 (6.85)\n\n65.89 (11.96)\n58.57 (27.19)\n64.00 (17.88)\n67.55 (14.50)\n76.85 (10.94)\n73.99 (13.00)\n79.77 (7.05)\n76.77 (13.19)\n\n56.67 (17.32)\n47.08 (16.35)\n50.33 (13.06)\n47.25 (5.50)\n53.47 (12.63)\n51.14 (11.95)\n64.52 (11.44)\n64.13 (6.05)\n49.74 (15.60)\n\n54.74 (11.46)\n51.76 (14.37)\n55.34 (13.67)\n49.56 (17.26)\n59.52 (20.62)\n58.84 (23.08)\n42.34 (13.11)\n55.50 (15.78)\n51.79 (15.40)\n\n43.28 (14.02)\n36.04 (9.99)\n43.98 (14.06)\n44.02 (16.89)\n47.26 (14.47)\n45.71 (17.85)\n41.33 (17.72)\n49.99 (13.18)\n43.89 (14.43)\n\n50.47 (12.63)\nN/A\n43.89 (11.60)\n47.49 (14.64)\n42.87 (17.34)\n49.95 (17.35)\n43.57 (23.87)\n55.43 (10.48)\n32.87 (13.81)\n\nN/A\nN/A\nN/A\nN/A\n49.97 (7.80)\n41.79 (16.82)\n41.18 (12.43)\n48.61 (12.03)\n36.69 (18.15)\n\n84.55 (12.06)\n67.74 (10.82)\n75.97 (9.12)\n75.63 (4.49)\n73.48 (6.18)\n68.33 (18.49)\n81.84 (6.30)\n80.95 (10.71)\n65.66 (18.54)\n\n69.24 (17.77)\n70.80 (9.78)\n73.77 (9.84)\n73.26 (10.65)\n74.35 (16.78)\n76.10 (10.84)\n72.58 (6.77)\n83.98 (13.45)\n68.33 (18.43)\n\n62.63 (20.63)\n60.03 (10.52)\n66.93 (11.07)\n69.70 (12.04)\n72.62 (11.16)\n67.76 (10.73)\n66.26 (12.11)\n81.08 (8.46)\n60.95 (25.16)\n\n59.55 (12.38)\nN/A\n64.67 (12.88)\n65.16 (12.56)\n67.09 (7.42)\n69.71 (11.55)\n65.46 (15.78)\n78.24 (6.67)\n53.68 (13.86)\n\nN/A\nN/A\nN/A\nN/A\n69.10 (7.64)\n67.37 (16.86)\n63.16 (11.06)\n76.39 (12.23)\n50.53 (15.60)\n\nIn naturalistic settings, in-home mobility can be measured through the use of indoor localization models. We have shown, using\nroom transition duration results, that our PD cohort takes longer on average to perform a room transition when they withhold\nmedications. With accurate in-home gait speed features, a classifier model can then differentiate accurately if a person with PD is in\nan ON or OFF medication state. Such changes show the promise of these localization outputs to detect the dopamine-related gait\nfluctuations in PD that impact patients\u2019 quality of life and are important in clinical decision-making. We have also demonstrated\nthat our indoor localization system provides precise in-home gait speed features in PD with a minimal average offset to the ground\n\n8\n\n\fTable 2: Hallway prediction on limited training data.\n\nTraining Model\n\nPrecision\n\nF1-Score\n\n4m-HC\n\n4m-PD\n\nMDCSA 4APS RSSI\nMDCSA 4APS\nMDCSA\n\nMDCSA 4APS RSSI\nMDCSA 4APS\nMDCSA\n\n62.32 (19.72)\n68.07 (23.22)\n71.25 (21.92)\n\n58.59 (23.60)\n62.36 (18.98)\n70.47 (14.10)\n\n58.99 (23.87)\n60.01 (26.24)\n68.95 (17.89)\n\n57.68 (24.27)\n57.76 (20.07)\n64.64 (21.38)\n\nTable 3: Room-to-room transition accuracy (in seconds) of all models compared to the ground truth. Standard deviation is shown in\n(.), the best performer is bold, while the second best is italicized. A model that fails to capture a transition between particular rooms\nwithin a period that has the ground truth is assigned \u2019N/A\u2019 score.\n\nData\n\nModels\n\nKitch-Livin\n\nKitch-Dinin\n\nDinin-Livin\n\nGround Truth\n\n18.71 (18.52)\n\n14.65 (6.03)\n\n10.64 (11.99)\n\nALL-HC\n\nLOO-HC\n\n!\n\nLOO-PD\n\n4m-HC\n\n4m-PD\n\nRF\nTENER\nAlt DTML\nMDCSA\n\n16.18 (12.08)\n15.58 (8.75)\n15.27 (7.51)\n17.70 (16.17)\n\n17.52 (16.97)\nRF\nTENER\n14.62 (16.37)\nAlt DTML 16.30 (17.78)\n17.70 (17.42)\nMDCSA\n\n14.49 (15.28)\nRF\nTENER\n13.42 (14.88)\nAlt DTML 16.98 (15.15)\n16.42 (14.04)\nMDCSA\n\n14.22 (18.03)\nRF\nTENER\n10.75 (15.67)\nAlt DTML 16.89 (18.07)\n18.15 (19.12)\nMDCSA\n\n11.52 (16.07)\nRF\nTENER\n8.75 (14.89)\nAlt DTML 14.75 (13.79)\n17.96 (19.17)\nMDCSA\n\n14.58 (10.22)\n16.30 (12.94)\n13.40 (6.43)\n14.94 (9.71)\n\n11.93 (10.08)\n9.58 (9.16)\n14.01 (8.08)\n14.34 (9.48)\n\n11.67 (11.68)\n10.87 (10.37)\n15.26 (8.85)\n14.48 (9.81)\n\n11.38 (15.46)\n8.59 (14.39)\n14.68 (13.57)\n15.32 (14.93)\n\n8.73 (12.90)\nN/A\n13.47 (17.66)\n14.74 (10.83)\n\n10.19 (9.46)\n12.01 (13.01)\n10.84 (10.81)\n10.76 (9.59)\n\n9.23 (13.69)\n7.21 (10.61)\n10.37 (12.44)\n11.07 (13.60)\n\n8.65 (13.06)\n6.95 (10.28)\n9.99 (13.03)\n10.77 (14.18)\n\n13.43 (18.87)\nN/A\n9.31 (15.70)\n11.89 (17.55)\n\nN/A\nN/A\nN/A\n10.16 (14.03)\n\ntruth. The network also outperforms other models in the production of in-home gait speed features, which is used to differentiate the\nmedication state of a person with PD.\n\nAcknowledgments\n\nWe are very grateful to the study participants for giving so much time and effort to this research. We acknowledge the local\nMovement Disorders Health Integration Team (Patient and Public Involvement Group) for their assistance at each study design step.\nThis work was supported by various grants and institutions.\n\nStatistical Significance Test\n\nIt could be argued that all the localization models compared in Table 1 might not be statistically different due to the fairly high\nstandard deviation across all types of cross-validations, which is caused by the relatively small number of participants. In order to\ncompare multiple models over cross-validation sets and show the statistical significance of our proposed model, we perform the\nFriedman test to first reject the null hypothesis. We then performed a pairwise statistical comparison: the Wilcoxon signed-rank test\nwith Holm\u2019s alpha correction.\n\n9\n\n\fTable 4: PD participant room transition duration with ON and OFF medications comparison using Wilcoxon signed rank tests.\n\nOFF transitions\n\nMean transition duration\n\nON transitions\n\nMean transition duration W\n\nz\n\nKitchen-Living OFF\nDining-Kitchen OFF\nDining-Living OFF\n\n17.2 sec\n12.9 sec\n10.4 sec\n\nKitchen-Living ON\nDining-Kitchen ON\nDining-Living ON\n\n14.0 sec\n9.2 sec\n9.0 sec\n\n75.0\n76.0\n64.0\n\n2.824\n2.903\n1.961\n\n10",
  "is_publishable": 1,
  "venue": "KDD"
}
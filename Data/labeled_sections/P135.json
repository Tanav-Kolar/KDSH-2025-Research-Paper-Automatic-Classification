{
  "title": "A Decentralized Local Stochastic Extragradient\nApproach for Variational Inequalities",
  "abstract": "This study examines distributed stochastic variational inequalities (VIs) within\nunbounded domains, where the problem data is heterogeneous, meaning it is non-\nidentically distributed and spread across numerous devices. We adopt a broad\nassumption regarding the computational network, which encompasses fully de-\ncentralized computations with dynamic networks and the centralized structures\ncommonly employed in Federated Learning. Additionally, we allow multiple local\nupdates on the workers to reduce how often they communicate. We adapt the\nstochastic extragradient method to this versatile framework, and conduct theoreti-\ncal analysis on its convergence rate, specifically in strongly-monotone, monotone,\nand non-monotone scenarios (given that a Minty solution is available). The rates\nwe provide demonstrate a clear relationship with various network properties like\nmixing time, the number of iterations, data heterogeneity, variance, the quantity\nof devices, and other typical parameters. As a particular application, our method\nand analysis can be used for distributed stochastic saddle-point problems (SPP),\nsuch as the training of Deep Generative Adversarial Networks (GANs), which is\nknown to be very difficult when using decentralized training. The experiments we\nperform for decentralized GANs training demonstrate the efficacy of our proposed\napproach.",
  "introduction": "In extensive machine learning (ML) situations, training data is often split among multiple devices\nlike data centers or mobile devices. Decentralized training methods can produce an ML model\nwith the same accuracy as if all data were on a single server. Moreover, decentralized training has\nadvantages over traditional centralized methods including data ownership, privacy, fault tolerance, and\nscalability. Federated Learning (FL) is a decentralized learning approach where the training process\nis managed by a single device or server that communicates with all the participating clients. However,\nin fully decentralized learning (FD) scenarios, devices only communicate with their neighbors via a\ncommunication network with an arbitrary structure. Therefore, decentralized algorithms are valuable\nwhen centralized communication is expensive, undesirable, or impossible.\n\nRecently, significant advances have been made in the creation, design, and understanding of decen-\ntralized training methods. In particular, aspects such as data heterogeneity, communication efficiency,\nwhich includes local updates or compression, and personalization have been explored. However,\nthese advancements have focused on training with single-criterion loss functions, which lead to\nminimization problems, and are not applicable to more general types of problems. For instance,\ntraining Generative Adversarial Networks (GANs) requires the simultaneous competing optimization\nof the generator and discriminator objectives, which translates to solving a non-convex-non-concave\nsaddle-point problem (SPP). This kind of problem structure makes GANs extremely challenging to\ntrain, even in the single-node setting, let alone when training over decentralized datasets.\n\nThis study centers around solving decentralized stochastic SPPs and, more broadly, decentralized\nstochastic Minty variational inequalities (MVIs). In a decentralized stochastic MVI, data is distributed\n\n.\n\n\facross M or more devices/nodes. Each device m has access to its own local stochastic oracle Fm(z, m)\nfor the local operator Fm(z) := EmDmFm(z, m). The data m in device m follows a distribution Dm,\nwhich can vary across devices. The devices are connected via a communication network, allowing\ntwo devices to exchange information only if their corresponding nodes are connected by an edge in\nthe network graph. The objective is to find cooperatively a point z* Rn that satisfies the inequality:\n\nM\n(cid:88)\n\nm=1\n\nE[Fm(z\u2217), z \u2212 z\u2217] \u2265 0\n\n(1)\n\nfor all z Rn.\n\nA specific instance of decentralized stochastic MVIs is the decentralized stochastic SPP with local\nobjectives fm(x, y) := EmDm[fm(x, y, m)]:\n\nmin\nx\u2208Rn\n\nmax\ny\u2208Rm\n\nM\n(cid:88)\n\nm=1\n\nfm(x, y)\n\n(2)\n\nThe connection to VI can be seen by setting z = (x, y) and the gradient field F(z) = (xf(x, y), -yf(x,\ny)). In cases where f(x,y) is convex-concave, the operator F(z) is monotone. However, in the context\nof GANs training, where x and y are parameters of the generator and discriminator, respectively, the\nlocal losses fm(x, y) are generally non-convex-non-concave in x, y, and monotonicity of F cannot be\nassumed.\n\nIn this study, we develop a new algorithm for addressing problems (1) and (2). Because gradient\ndescent-ascent for problem (2) can diverge even in simple convex-concave settings with a single\ndevice, we use extragradient updates and combine them with a gossip-type communication protocol\non arbitrary, possibly dynamic, network topologies. One challenge arising from communication\nconstraints is a \u201cnetwork error\u201d that stems from the inability of all devices to achieve exact consensus.\nTherefore, each device uses a local variable, with only approximate consensus among devices\nachieved through gossip steps. Our method avoids multiple gossip steps per iteration, leading to\nbetter practical performance on dynamic networks. It also allows multiple local updates between\ncommunication rounds to reduce communication overhead, making it suitable for communication-\nand privacy-restricted FL or fully decentralized scenarios.\n\nOur Contributions:\n\n1. We have created an algorithm that uses extragradient updates to tackle distributed stochas-\ntic MVIs, and consequently distributed stochastic SPPs, with heterogeneous data. This\nframework offers a flexible communication protocol that supports centralized settings like\nFederated Learning, fully decentralized configurations, local steps in both centralized and\ndecentralized setups, and dynamic network topologies.\n\n2. Using this general communication protocol, we have demonstrated the convergence of our\nalgorithm in three MVI settings, namely where the operator is strongly-monotone, monotone,\nor non-monotone (assuming a Minty condition is met). The rates of convergence depend\nexplicitly on several problem parameters, such as network characteristics, data heterogeneity,\ndata variance, number of devices, and other relevant factors. These theoretical results\ntranslate directly to the corresponding SPP settings (strongly-convex-strongly-concave,\nconvex-concave, and non-convex-non-concave under the Minty condition). All theoretical\nresults are valid when using heterogeneous data, and allow quantifying how factors like data\nheterogeneity, noise in the data, and network characteristics influence convergence rate. We\nhave also shown that for decentralized settings, our results are novel for time-varying graphs\nand the three different monotonicity settings.\n\n3. We have verified our theoretical results through numerical experiments and demonstrated the\neffectiveness of our strategy in practice. Specifically, we have trained a DCGAN architecture\non the CIFAR-10 dataset.\n\n2",
  "related_work": "Research on MVIs dates back to at least 1962, and has been continued in recent works. VIs are\nused in diverse applications: image denoising, game theory and optimal control, robust optimization,\nand non-smooth optimization using smooth reformulations. In ML, MVIs and SPPs arise in GANs\ntraining, reinforcement learning, and adversarial training.\n\nThe extragradient method (EGM) was first introduced and later expanded to include deterministic\nproblems and stochastic problems with bounded variance. However, if the stochastic noise is not\nuniformly bounded, EGM can diverge.\n\n3 Algorithm\n\nThis section details our proposed algorithm (Algorithm 1) based on two main concepts: (i) the extra-\ngradient step (as seen in classical methods for VIs), and (ii) gossip averaging (used in decentralized\noptimization and diffusion strategies in distributed learning). Instead of using gradient descent, as\nin similar algorithms, ours uses the extragradient method. It is designed for VIs and SPPs. It also\nincludes local steps between communication rounds, supports dynamic networks, and comes with\nnon-asymptotic theoretical convergence guarantees.\n\nEach step of Algorithm 1 has two phases. The local phase (lines 4\u20136) involves a step of the stochastic\nextragradient method at each node using only local data. Nodes make an extrapolation step \u201cto\nlook into the future\u201d and then update using the operator value at the \u201cfuture\u201d point. Next is the\ncommunication phase (line 7), during which nodes share local iterates with their neighbors Nm in the\ncommunication network graph for each iteration k. Averaging is done using weights w k m,i, which\nare matrix Wk elements called the mixing matrix.\n\nDefinition 2.1 (Mixing matrix). A matrix W [0; 1]M\u00d7M is a mixing matrix if it satisfies: 1) W is\nsymmetric, 2) W is doubly stochastic (W1 = 1, 1TW = 1T, where 1 is the vector of all ones), 3) W is\naligned with the network: wij 0 if and only if i = j or the edge (i, j) is in the communication network\ngraph.\n\nReasonable choices of mixing matrices include Wk = IM Lk /max(Lk), where Lk is the Laplacian\nmatrix of the network graph at step k and IM is the identity matrix, or by using local rules based on\nthe degrees of the neighboring nodes. Our setting offers great flexibility because the communication\ngraph\u2019s topology can change between iterations. The matrix Wk, which encodes the current network,\nalso changes. This is encoded in line 2, where Wk is generated using a rule Wk that can vary.\nExamples include the deterministic choice of a matrix sequence Wk or sampling from a dynamic\nprobability distribution on matrices. Local steps without communication can be encoded with a\ndiagonal matrix Wk.\n\n> 0, {Wk}k0 \u2013 rules or distributions for mixing matrix in iteration k.\n\nAlgorithm 1 Extra Step Time-Varying Gossip Method\nparameters: stepsize\ninitialize: z0 Z, m : z0 m = z0\n1: for k = 0, 1, 2, . . . do\n2: Sample matrix Wk from Wk\n3: for each node m do\n4: Generate independently mk+1/3\n5:\n6: Generate independently mk+2/3\n7:\n8:\nend for\n9: end for\n\nFm(zk m, mk+1/3 )\n\nzk+1/3 m = zk m\n\nWk m,i zk+1/3\n\nzk+1 =\nzk+1/3\n\nDm\n\nDm\n\nTo ensure consensus between nodes, the mixing properties of the matrix sequence Wk must satisfy\nthe following assumption:\n\nAssumption 2.2 (Expected Consensus Rate). There exists a constant p (0, 1] and an integer 1 such\nthat, after K iterations, for all matrices Z Rd\u00d7M and all integers l 0, . . . , K/ ,\n\n3\n\n\fEW\n\n(cid:2)||ZWl\u03c4 \u2212 \u00afZ||2\n\nF\n\n(cid:3) \u2264 (1 \u2212 p)||Z \u2212 \u00afZ||2\n\nF\n\n(3)\n\nwhere Wl = W(l+1)1 ...Wl, we use the matrix notation Z = [z1, ..., zM] with z = (1/M)m=1M zm, and\nthe expectation EW is over distributions of W and indices t l,...,(l+1) - 1.\n\nThis assumption guarantees that the consensus between nodes improves by a factor of 1-p after every\ngossip steps. Some matrices Wk can be the identity matrix (local steps only).\n\n4 Setting and Assumptions\n\nThis section outlines the assumptions used to analyze the proposed algorithm:\n\nAssumption 3.1 (Lipschitzness). For every m, the operator Fm(z) is Lipschitz with a constant L,\nmeaning that:\n\n||Fm(z1) \u2212 Fm(z2)|| \u2264 L||z1 \u2212 z2||, \u2200z1, z2\n\n(4)\n\nThis is a common assumption used when analyzing all the methods in Table 1.\n\nAssumption 3.2. We consider three scenarios for the operator F: (SM) Strong monotonicity, (M)\nMonotonicity, and (NM) Non-monotonicity under the Minty condition:\n\n(SM) Strong monotonicity. For some > 0 and for all z1, z2, we have:\n\n(F (z1) \u2212 F (z2), z1 \u2212 z2) \u2265 \u00b5||z1 \u2212 z2||2\n\n(M) Monotonicity. For all z1, z2, we have:\n\n(NM) Non-monotonicity (Minty). There exists z such that, for all z,\n\n(F (z1) \u2212 F (z2), z1 \u2212 z2) \u2265 0\n\n(F (z), z \u2212 z\u2217) \u2265 0\n\n(5)\n\n(6)\n\n(7)\n\nAssumptions (SM), (M), and (L) are widely used in the literature. Assumption (NM), often called\nMinty or Variational Stability, has recently been used as a non-monotonicity variant, particularly in\nGANs training.\n\nAssumption 3.3 (Bounded noise). Fm(z, ) is unbiased and has bounded variance. This means, for all\nz:\n\nE[Fm(z, \u03be)] = Fm(z), E[||Fm(z, \u03be) \u2212 Fm(z)||2] \u2264 \u03c32\n\n(8)\n\nThe final assumption pertains to the variability of local operators compared to their mean, which is\ncalled D-heterogeneity, and is commonly used when analyzing local-step algorithms.\n\nAssumption 3.4 (D-heterogeneity). The values of the local operator have bounded variability:\n\n||Fm(z) \u2212 \u00afF (z)|| \u2264 D\n\n(9)\n\n5 Main Results\n\nThis section presents convergence rates for our proposed method under different settings de-\nfined by Assumption 3.2. We introduce the notation z = (1/M)m=1M zk for the average iter-\nates and Z = (1/K)k=0K-1 z for the averaged sequence, i.e., ergodic average. We denote =\n(2/M + D2), whichistheconsensuserror.\n\nTheorem 4.1 (Main theorem). Let Assumptions 2.2 and 3.1-3.4 hold, and the sequence z generated\nby Algorithm 1 runs for K > 0 iterations. Then:\n\n\u2022 Strongly-monotone case: under Assumption 3.2 (SM) with = /L2, itholdsthat :E[||\u00afzK \u2212 z\u2217||2] \u2264\n\n(cid:0)1 \u2212 \u00b5\n\n2L\n\n(cid:1)K\n\n||z0 \u2212 z\u2217||2 + \u03b3L2\u2206\n\n\u00b5 (10)\n\n4\n\n\fMonotone case: under Assumption 3.2 (M), for any convex compact C with z0,z C and Q = maxz,z\u2019C\n||z - z\u2019|| < Qc, with = O(min1/(K0.5L), (1/L)(p/), itholdsthat :\n\nQ\n\u221a\nK\nUnder the assumption that for all k, ||zk||Qwith = O(min1/KL, p/), wehave :\n\n+ (L(cid:112)Qc\u2206 + \u2206)\n\nE[(F (\u00afzK), \u00afzK \u2212 z)] \u2264\n\nsup\nz\u2208C\n\nL2Q2\nc\nK\n\n(cid:115)\n\nE[(F (\u00afz), \u00afz \u2212 z)] \u2264 O(\n\nsup\nz\u2208C\n\nLQ2\nK\n\n) + O(\n\nL\u2206Q\n\u221a\nK\n\n)\n\n(11)\n\n(12)\n\nK1/4 (14)\n\n\u00b5 + LQ\n\nK + L2\u2206Q\n\nK1/4 (13)Under\n\nthe additional assumption that,\n\nNon-monotone case: under Assumption 3.2 (NM) and if ||z\u2217||Qwith = O(min1/KL, p/),||z \u2212\nz\u2217||2 \u2264 LQ2\nK + L2\u2206\nfor all k,\n||zk||Q, wehavethatE[||\u00afzK \u2212 z\u2217||2] \u2264 LQ2\nThe proof of the theorem can be found in the supplementary materials, where the dependence of\nrates on the stepsize before optimal selection are given. In contrast to other analyses, our analysis\naddresses the fact that problem (1) has no feasible bounded set, which is important for analysis in\nboth monotone and non-monotone settings. Furthermore, our algorithm includes a communication\nstep that introduces a bias in the oracle, which needs to be analyzed over unbounded feasible sets.\nWe overcome this by bounding the bias, and proving the boundedness in expectation of the sequence\nof iterates for both monotone and non-monotone cases. We also analyze stochastic extragradient\nmethod with biased oracles on unbounded domains which has not been done before. We achieve this\nunder a general Assumption 2.2, with time varying graphs and all three monotonicity settings.\n\nThe convergence rates explicitly depend on the network, characterized by mixing time and mixing\nfactor p, and on data heterogeneity D, which appear only as the quantity , the variance 2, Lipschitz\nconstant L, strong monotonicity parameter , and the number of nodes M. These results help us\ndetermine how data heterogeneity, noise, and network characteristics influence convergence. This\nopens meta-optimization opportunities to design networks and set parameters such as M, , and p to\nimprove convergence.\n\nThe convergence results presented in the theorem have a similar multi-term structure. The first term\nis from the deterministic case and mirrors existing methods for smooth VIs in a non-distributed\nsetting. The second term is stochastic and is also standard for the non-distributed setting. The leading\nstochastic term is proportional to 2/M, decreasing with the number of nodes. Other terms represent\na consensus error, due to imperfect communication between nodes. In all the cases this does not\nworsen the convergence, because dependence on K is no worse than the stochastic term.\n\nTheorem 4.1 is given for a fixed iteration budget K, and corresponding stepsizes that depend on K,\nwhich is standard in literature. We also offer a procedure that allows extending the result to all-time\nconvergence without a priori fixed K, by restarting the algorithm after K iterations, which are doubled\neach time.\n\nIn the strongly monotone case, our rate is slightly better than other results. The other methods\u2019\nstepsize is limited as p/(L2), slowing convergence. For decentralized settings, our rate is worse,\nprobably because Assumption 2.2 is more general, but our algorithm is more practical because it\navoids multiple gossip steps per iteration and works with time-varying topologies. In the monotone\ncase, we use the Gap function as a measure of suboptimality. And in the non-monotone setting we are\nable to obtain convergence up to a certain accuracy. It is important to note that we use assumptions\nabout iterates that we can obtain only when they are generated by the algorithm. We manage to obtain\ncorresponding results that can be used for establishing that the algorithm behaves nicely under certain\ninitial conditions. The experimental section will demonstrate these theoretical findings.",
  "methodology": "",
  "experiments": "Here we present two experiments to validate the performance of Algorithm 1. Section 5.1 verifies the\nobtained convergence guarantees on two examples, a strongly-monotone and a monotone bilinear\nproblem. Section 5.2 uses a non-monotone case with a GAN training application. Full details about\nthe experimental setup are available in the supplementary material.\n\n5\n\n\f6.1 Verifying Theoretical Convergence Rate\n\nThis experiment aims to determine whether Algorithm 1\u2019s actual performance matches our theoretical\nrate from Theorem 4.1.\n\nWe consider a distributed bilinear saddle point problem (SPP) with the objective functions:\n\nfm(x, y) = a\u2225x\u22252 + b\u27e8y, Cmx\u27e9,\n\nwhere x, y, Cm \u2208 Rn, and a, b are real numbers.\nThis setup satisfies the assumptions with constants:\n\n\u00b5 = a, L = a2 + b2, D = max\nm\n\n\u2225Cm\u2225.\n\nThe network uses M = 20 nodes with uniform averaging weights. The dimension is n = 5, b = 1,\nD \u2248 3, and \u03c4 = 1. The p value is approximately 0.288.\nTo obtain stochastic gradients, unbiased Gaussian noise with variance \u03c32 is added.\n\nConvergence Behaviour. The convergence of Algorithm 1 with a fixed stepsize in both the strongly-\nmonotone (a = 1) and monotone (a = 0) settings. In the strongly monotone setting we observe linear\nconvergence up to an error floor determined by the noise and problem parameters. The monotone\ncase converges more slowly, but is still linear up to a level. This is expected for bilinear problems. We\nsee that when a constant stepsize is used in stochastic optimization algorithms, convergence is usually\nlimited to a certain neighborhood, see Theorem 2 in a previous study. Theorem 4.1 also reflects this;\nconvergence with zero error requires a diminishing stepsize. In the supplementary material, we also\nvalidate with decreasing stepsize.\nWe verify the dependence on the heterogeneity parameter D and set the noise \u03c32 = 0. Based on\nthe theory, we expect that the error when \u03c3 = 0 scales as O(D2K \u22122). We conduct experiments by\nsetting b = 1 and a = 1, and measuring how many iterations are needed for\n(cid:13)\n(cid:13)\n(cid:13)\n(cid:13)\n(cid:13)\n\nzk \u2212 z\u2217\n\n1\nM\n\n(cid:13)\n(cid:13)\n(cid:13)\n(cid:13)\n(cid:13)\n\n< \u03f5,\n\n(cid:88)\n\nm\n\nwhile varying D. The step size is tuned for every experiment.\n\nThe number of iterations scale as K \u2248 \u03f5\u22124, confirming that the error depends on K as O(K \u22121/2).\nThe middle plot shows that iterations scale proportionally to D (D \u2248 K). Lastly, we see the number\nof iterations to reach \u03f5 = 0.01 while varying the graph parameter p, and observe D \u2248 p \u00b7 K. This\nmeans that experiments confirm the O\n\nterm in the convergence rate.\n\np DK 2(cid:17)\n(cid:16) 1\n\n6.2 Training GANs\n\nOur method allows for combining communication graph topologies and local steps during distributed\nlearning. This section explores our method on GANs training. In Section A.1, we discuss the\nrelevance of our theoretical results to GANs training.\n\nData and model. We use the CIFAR-10 dataset which includes 60,000 images across 10 classes. We\nincrease the dataset four times by adding transformations and noise, and simulate a distributed set\nup using 16 nodes on two GPUs with Ray. We create heterogeneity by splitting the dataset into 16\nsubsets where a major class makes up 20% of the data and the rest is split uniformly between all the\nother classes. We use the DCGAN architecture, conditioned by class labels, similar to a previous\npaper. We use Adam as the optimizer. We make one local Adam step and one gossip averaging step\nwith time-varying matrices Wk, similarly to Algorithm 1.\n\nSettings. We compare the following topologies, with respective matrices Wk:\n\n\u2022 Full. A full graph is used at the end of each epoch; otherwise, local steps are taken. This\n\nleads to 120 communication rounds per epoch.\n\n\u2022 Local. A full graph is used every five epochs; otherwise, local steps are taken. This means\n\n24 communication rounds per epoch on average.\n\n6\n\n\f\u2022 Clusters. At the end of each epoch, clique clusters of size 4 are formed randomly (4 cliques\n\nin total). This results in 24 communication rounds per epoch.\n\nThe first topology has a 5x larger communication budget.\n\nThe learning rate is 0.002 for both generator and discriminator. The rest of the parameters are in the\nsupplementary material.",
  "results": "The methods reach a similar convergence in terms of local epochs and produced similar images.\nThe Local and Cluster topologies perform much better in terms of communication, with the Cluster\ntopology slightly outperforming the Local.",
  "conclusion": "We have developed an effective algorithm to solve decentralized stochastic MVIs and SPPs, assuming\na highly flexible network topology and communication constraints. This method represents the first\ndecentralized extragradient approach that supports local steps for dynamic network topologies. We\ntheoretically demonstrated the convergence rate of the algorithm for SM, M, and NM cases. In\nnumerical experiments, we validated that the dependency on the data heterogeneity parameter D is\ntight in the SM case and impossible to improve in general. By training DCGAN in a decentralized\nmanner, we showed our method\u2019s effectiveness for practical DL tasks. Future work could extend\nthese algorithms to infinite-dimensional problems.\n\n7",
  "is_publishable": 1,
  "venue": NaN
}
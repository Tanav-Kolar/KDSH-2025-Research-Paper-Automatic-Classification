{
  "title": "A Reverse Hierarchy Model for Predicting Eye\nFixations",
  "abstract": "A number of psychological and physiological evidences suggest that early visual\nattention works in a coarse-to- fine way, which lays a basis for the reverse hierarchy\ntheory (RHT). This theory states that attention propagates from the top level of\nthe visual hierarchy that processes gist and abstract information of input, to the\nbottom level that processes local details. Inspired by the theory, we develop a\ncomputational model for saliency detection in images. First, the original image\nis downsampled to different scales to constitute a pyramid. Then, saliency on\neach layer is obtained by image super-resolution reconstruction from the layer\nabove, which is defined as unpredictability from this coarse-to-fine reconstruction.\nFinally, saliency on each layer of the pyramid is fused into stochastic fixations\nthrough a probabilistic model, where attention initiates from the top layer and\npropagates downward through the pyramid. Extensive experiments on two standard\neye-tracking datasets show that the proposed method can achieve competitive\nresults with state-of-the-art models.",
  "introduction": "Human vision system can selectively direct eyes to informative and salient parts of natural scenes.\nThis ability allows adaptive and efficient allocation of limited computational resources to important\nobjects. Though enjoying great potential in various applications of computer vision, predicting eye\nfixations, however, remains a challenging task. The underlying difficulty inherits from the ambiguous\nnotion of what attracts eye fixations, or what is salient. In fact, the theoretical investigation of visual\nsaliency has aroused enduring controversies. One possible explanation often adopted in the design of\nsaliency detection approaches is the Feature Integration Theory (FIT). According to FIT, attention\nserves as a mechanism to coherently combine features for the perception of objects. Therefore,\nstarting from , eye fixations are commonly predicted by directly conjoining saliency activations from\nmultiple channels, which can be global and local channels, multiple features and so on.\n\nAnatomical and physiological studies have shown that human visual system is organized hierarchically,\nwhich is believed to be advantageous in efficient processing of visual input. Computational studies\nhave shown that hierarchical models (e.g. HMAX, CDBN) are effective for object recognition. Most\nsaliency detection models, however, do not seriously take this into account. An obvious method\nto fill this gap is to develop hierarchical bottom-up models for saliency detection in the manner\nof HMAX, CDBN and the like. But there exists theoretical alternatives. The Reverse Hierarchy\nTheory (RHT) argues that parallel feedforward feature activation acts implicitly at first to construct a\ncoarse gist of the scene, while explicit perception incrementally incorporates fine details via feedback\ncontrol. This theory potentially has tremendous applications in computer vision including image\nsegmentation, object recognition and scene understanding, however, computational studies are scarce.\nIn this paper, we present an effective model based on RHT for saliency detection, which proves that\nRHT is helpful at least in this particular computer vision application. As for this application, a more\ndirect evidence for the proposed model refers to a psychophysical study which showed that fixations\nfrom low-resolution images could predict fixations on higher-resolution images.\n\n.\n\n\fOur main idea is to model the coarse-to-fine dynamics of visual perception. We take a simple strategy\nto construct a visual hierarchy by inputting images at different layers with different scales, obtained\nby downsampling the original image. The higher layers receive coarser input and lower layers receive\nfiner input. On each layer, saliency is defined as unpredictability in coarse-to-fine reconstruction\nthrough image super-resolution. The saliency on each layer is then fused into fixation estimate with a\nprobabilistic model that mimics reverse propagation of attention. Throughout the paper, we call the\nproposed model a reverse hierarchy model (RHM).\n\nThe coarse-to-fine dynamics, however, is not the only property of RHT. In fact, RHT is closely related\nto the biased competition theory of attention, which claims that attentional competition is biased\nby either stimulus-driven or task-dependent factors. Our model deals with fixation prediction in\nthe free viewing task, which can be regarded as an implementation of the stimulus-driven bias. In\naddition, the image pyramid is a very coarse approximation of the highly complex structure of the\nvisual hierarchy in the brain, which only utilizes the fact of increasing receptive field sizes along the\nhierarchy. Therefore, some closely related concepts to RHT, such as perceptual learning, would not\nbe discussed in the paper.",
  "related_work": "The majority of computational attention modeling studies follow the Feature Integration Theory.\nIn particular, the pioneering work by first explored the computational aspect of FIT by searching\nfor center-surround patterns across multiple feature channels and image scales. This method was\nfurther extended through integration of color contrast, symmetry, etc. Random Center Surround\nSaliency adopted a similar center-surround heuristic but with center size and region randomly sampled.\nintroduced a graph-based model that treated feature maps as fully connected nodes, while the nodes\ncommunicated according to their dissimilarity and distance in a Markovian way. Saliency was\nactivated as the equilibrium distribution.\n\nSeveral saliency models adopted a probabilistic approach and modeled the statistics of image features.\nand Baldi defined saliency as surprise that arised from the divergence of prior and posterior belief.\nSUN was a Bayesian framework using natural statistics, in which bottom-up saliency was defined as\nself-information. proposed an attention model based on information maximization of image patches.\ndefined the saliency by computing the Hotelling\u2019s T-squared statistics of each multi-scale feature\nchannel. considered saliency in a discriminative setting by defining the KL-divergence between\nfeatures and class labels.\n\nA special class of saliency detection schemes was frequency-domain methods. proposed a spectral\nresidual method, which defined saliency as irregularities in amplitude information. explored the phase\ninformation in the frequency domain with a Quaternion Fourier Transform. Recently, introduced a\nsimple image descriptor, based on which a competitive fast saliency detection algorithm was devised.\n\nDifferent from our proposal, the conventional practice in fusing saliency at different image scales and\nfeature channels was through linear combination. proposed a model that combined a global saliency\nmodel AIM and a local model through linear addition of normalized maps. Some models learned the\nlinear combination weights for feature channels. trained a linear SVM from human eye fixation data\nto optimally combine the activation of several low-, mid- and high-level features. With a similar idea,\nadopted a regression-based approach.\n\nOur model is characterized by a top-down flow of information. But it differs from most existing\nsaliency detection models that incorporate top-down components such as in two aspects. First, a\nbiased prior (e.g., context clues, object features, task-related factors) is often needed in those models,\nserving as the goal of top-down modulation, which is not necessary in our model. Second, hierarchical\nstructure of the visual cortex is not considered in those models, but plays a significant role in our\nmodel.\n\nNevertheless, there were a few preliminary studies trying to make use of the hierarchical structure for\nsaliency detection and attention modeling. The Selective Tuning Model was such a model. It was\na biologically plausible neural network that modeled visual attention as a forward winner-takes-all\nprocess among units in each visual layer. A recent study used hierarchical structure to combine\nmulti-scale saliency, with a hierarchical inference procedure that enforces the saliency of a region to\nbe consistent across different layers.\n\n2\n\n\f3 Saliency from Image Super-Resolution\n\nIn this section, a coarse-to-fine saliency model based on image super-resolution is presented. We\nconsider an image at two consecutive scales in an image pyramid: a coarse one Il and a fine one\nIh. Inspired by RHT, we define saliency as details in Ih that are unpredictable from Il. In the next\nsection, we discuss how to fuse saliency on each layer of the pyramid into fixation estimate.\n\n3.1 Saliency as Unpredictability\n\nPredicting Ih using the information of Il is closely related to image super-resolution, which has\nbeen extensively studied using techniques including Markov random field, example-based learning,\ncompressive sensing, etc. In patch-based representation of images, the problem is to predict a high-\nresolution H \u00d7 H patch xh \u2208 Ih from its low-resolution L \u00d7 L counterpart xl \u2208 Il. For convenience\nof notation, we also use xh and xl as H 2 and L2 dimensional vectors, which are computed by\nreshaping the corresponding patches. Then xl is obtained by blurring and downsampling xh:\n\nxl = GBxh,\n(1)\nwhere B denotes a H 2 \u00d7 H 2 blurring matrix (throughout the paper a Gaussian matrix is used) and G\nrepresents a L2 \u00d7 H 2 downsampling matrix. Let zh denote the reconstructed patch by some method\nA, which summarizes the best knowledge one can recover from the coarse perception of xl, via A.\nThe reconstruction error of zh from xh, naturally represents the fine-scale information that cannot be\nrecovered. Therefore, we define saliency S(xh|xl) as the Normalized Mean Square Error (NMSE):\n\nS(xh|zh) =\n\n||xh \u2212 zh||2\n||xh||2\n\n(2)\n\nThe mean squared error is normalized so that S(xh|xl) is robust to variations of the patch energy\n||xh||2.\n\n3.2 Coarse-to-Fine Reconstruction\n\nThe reconstruction from the coarse scale subject to the constraint (1) is actually not well-defined, since\ngiven a low-resolution patch xl, there exists an infinite number of possible high-resolution patches\nxh. To resolve this issue, the basic idea is to incorporate some prior knowledge, which inherits from\nthe properties of natural images. In what follows we discuss several possible reconstruction schemes\nwith increasingly sophisticated prior knowledge.\n\nLinear Reconstruction (LR). Consider a trivial case: the coarse patch xl = Bxh, is just the blurred\nversion and we do nothing but output zh = xl. Therefore, no prior is used in this case. Saliency can\nbe computed according to (2). As shown in Fig. 2, this method assigns more saliency to patches\ncontaining many high-frequency components like edges and textures.\n\nBicubic Interpolation (BI). If we reconstruct xh using bicubic interpolation, then we utilize a\nsmoothness prior in image interpolation. Although this approach concentrates less on edges than the\nlinear reconstruction, its prediction is still far from the ground truth. See Fig. 2.\n\nWith LR or BI, the saliency computed in (2) is the normalized l2-norm of the Laplacian pyramid. In\naddition, the two techniques can be used to implement the center-surround strategy adopted in some\nsaliency models, e.g. .\n\nCompressive Sensing (CS). We now consider a more sophisticated prior of image structure \u2013 sparsity.\nAccording to this prior, any patch xh of a high-resolution image can be sparsely approximated by a\nlinear combination of items in a dictionary Dh:\n\nxh \u2248 Dh\u03b1,\n(3)\nfor some sparse coefficients \u03b1 that satisfies ||\u03b1||0 \u2264 K for some small K. Assuming \u03b1 is sparse,\nthe theory of compressive sensing states that \u03b1 can be recovered from sufficient measurements\nxl = GBxh by solving the following optimization problem:\n\nmin ||\u03b1||0subjectto||Dl\u03b1 \u2212 xl|| < \u03f5,\n(4)\nwhere Dl = GBDh, denotes the blurred and downsampled dictionary Dh, and \u03f5 is the allowed error\ntolerance. This is hard to solve, and in practice the following relaxed problem is often solved:\n\nmin ||\u03b1||1subjectto||Dl\u03b1 \u2212 xl|| < \u03f5.\n\n(5)\n\n3\n\n\fThe coefficients \u03b1 are then used to reconstruct zh by\n\nzh = Dh\u03b1.\n(6)\nOnce we have obtained zh, saliency of the image patch can be computed using (2). Preliminary\nresults in Fig. 2 indicate that the saliency obtained by compressive sensing can largely differ from\nthat obtained by LR and BIL.\n\nThe dictionaries Dh and Dl are constructed as follows. For each scale of the image pyramid, we\nfirst uniformly sample raw patches {dj}n\nj=1 of size H \u00d7 H (n > H 2), and stack them into a high-\nresolution dictionary Dh = [d1, d2, ..., dn]. Then we apply the blurring matrix B and downsampling\nmatrix G to each dj, to obtain dj = GBdj. So Dl = [d1, d2, ..., dn] is the collection of corresponding\nlow-resolution patches. The use of overcomplete raw patches for Dh and Dl has been shown effective\nfor image super-resolution.\n\n3.3 Saliency Map\n\nA saliency map M is obtained by collecting patch saliency defined in (2) over the entire image. First,\ncalculate\n\nM [i, j] = S(xh[i, j]|xl[i, j]),\n(7)\nwhere xh[i, j] is the patch centered at pixel (i, j) in the image and xl[i, j] is its low-resolution version.\nThen M is blurred with a Gaussian filter and normalized to be between [0, 1] to yield the final saliency\nmap M . One should not confuse this Gaussian filter with B in Sections 3.1 and 3.2.\n\n4 Reverse Propagation of Saliency\n\nNow, we present a method to transform the saliency maps at different scales into stochastic eye\nfixations on the original image. Based on RHT, a reverse propagation model is presented, where\nattention initiates from top level and propagates downward through the hierarchy.\n\n4.1 Generating Fixations\n\nWe model attention as random variables A0, A1, ..., An on saliency maps M0, M1, ..., Mn, which are\nordered in a coarse-to-fine scale hierarchy. Specifically, let P r[Ak = (i, j)] denote the probability for\npixel (i, j) attracting a fixation. To define this probability, we need to consider factors that influence\nthe random variable Ak. First of all, the saliency map Mk is an important factor. Pixels with higher\nvalues should receive more fixations. Second, according to RHT, attention starts from M0, and then\ngradually propagates down along the hierarchy. Therefore, Ak should also depend on Ak\u22121, ..., A0.\nFor simplicity, we assume that only Ak\u22121 has an influence on Ak while Ak\u22122, ..., A0 do not.\n\nBased on these considerations, we define\n\nP r[Ak|Mk, Ak\u22121, ..., A0] = P r[Ak|Mk, Ak\u22121],\nfor k = 1, ..., n. A log-linear model is used for this conditional probability\n\n(8)\n\nP r[Ak = (i, j)|Mk, Ak\u22121] \u221d exp(\u03b7Mk[i, j] + \u03bbL(Ak, Ak\u22121)),\n(9)\nwhere L(Ak, Ak\u22121) is a spatial coherence term, \u03b7 and \u03bb are two constants. The spatial coherence\nterm restricts the fixated patches to be close in space. The motivation of introducing this term\ncomes from the fact that the visual system is more likely to amplify the response of neurons that is\ncoherent with initial perception. To compute the term, we first convert the coordinate Ak\u22121 into the\ncorresponding coordinate (u, v) in the saliency map just below it, i.e. Mk. Then compute\n\nL(Ak, Ak\u22121) = \u2212((i \u2212 u)2 + (j \u2212 v)2).\n(10)\nIn other words, the farther away a patch x is from Ak\u22121, the less likely it would be attended by Ak.\nTherefore, for predicting the fixation probability of any patch in the current layer, the model makes a\ntradeoff between the spatial coherence with previous attention and its current saliency value.\n\nIf we do not consider any prior on the top layer, P r[A0] depends on the saliency map only\n\nP r[A0 = (i, j)] \u221d exp(\u03b7M0[i, j]).\n(11)\nWe can then generate fixations via an ancestral sampling procedure from the probability model.\nSpecifically, we first sample fixation A0 on map M0 according to (11), and then for k = 1, 2, ...\nsample Ak on map Mk given Ak\u22121 on the coarser scale according to (9). Finally, we collect all\nsamples on the finest scale, and use them as prediction of the eye fixations.\n\n4\n\n\f4.2\n\nIncorporating Prior of Fixations\n\nThe proposed probabilistic model offers great flexibility for incorporating prior of fixations. This prior\ncan be useful in capturing, for example, the top-down guidance of visual saliency from recognition,\nor central bias in eye-tracking experiments. To achieve this, we extend the expression of P r[A0] as\nfollows:\n\nP r[A0 = (i, j)] \u221d exp(\u03b7M0[i, j] + \u03b8P [i, j]),\n\n(12)\n\nwhere P [i, j] encodes the prior information of pixel (i, j) on the first map M0 and \u03b8 is a weighting\nparameter.\nFor example, the central bias can be incorporated into the model by setting P [i, j] = \u2212[(i \u2212 cx)2 +\n(j \u2212 cy)2], where (cx, cy) denotes the map center.",
  "methodology": "",
  "experiments": "5.1 Experiment Settings\n\nDatasets. The performance of the proposed reverse hierarchy model (RHM) was evaluated on two\nhuman eye-tracking datasets. One was the TORONTO dataset. It contained 120 indoor and outdoor\ncolor images as well as fixation data from 20 subjects. The other was the MIT dataset, which\ncontained 1003 images collected from Flicker and LabelMe. The fixation data was obtained from 15\nsubjects.\n\nParameters. The raw image I in RGB representation was downsampled by factors of 27, 9, 3 to\nconstruct a coarse-to-fine image pyramid. The patch size for super-resolution was set as 9 \u00d7 9 on\neach layer. To construct corresponding coarse patches, we used Gaussian blurring filter B (\u03c3 = 3)\nand downsampling operator G with a factor of 3. A total of 1000 image patches were randomly\nsampled from all images at the current scale to construct the dictionary Dh, which is then blurred and\ndownsampled to build Dl.\n\nIn some experiments, we included a center bias in the model. This is achieved by switching \u03b8 from 0\nto 1 in (12).\n\nNote that the reverse propagation described in (8)-(11) is a stochastic sampling procedure and we\nneed to generate a large number of fixations to ensure unbiased sampling. We found that 20000 points\non each image were enough to achieve good performance, which was adopted in all experiments.\nThe stochastic points were then blurred with a Gaussian filter to yield the final saliency map. The\nstandard deviation of the Gaussian filter was fixed as 4 pixels on saliency maps, which was about 5\n\nEvaluation metric. Several metrics have been used to evaluate the performance of saliency models.\nWe adopted Area Under Curve (AUC), Normalized Scanpath Saliency (NSS) and Similarity (S).\nSpecifically, We used the AUC code from the GBVS toolbox, NSS code from and Similarity code\nfrom . Following , we first matched the histogram of the saliency map to that of the fixation map\nto equalize the amount of salient pixels in the map, and then used the matched saliency map for\nevaluation. Note that AUC was invariant to this histogram matching.\n\nModels for comparison. The proposed model was compared with several state-of-the-art models:\nItti Koch, Spectral Residual Methods (SR), Saliency based on Information Maximization (AIM),\nGraph Based Visual Saliency (GBVS), Image Signature (ImgSig), SUN framework and Adaptive\nWhitening Saliency (AWS). The implementation of these models were based on publicly available\ncodes/software. Among these models, GBVS, ImgSig and AWS usually performed better than the\nothers.\n\nInspired by the center bias, we included a Center model as a baseline, which was simply a Gaussian\nfunction with mean at the center of the image and standard deviation being 1/4 of the image width.\nThis simple model was also combined with other saliency detection models to account for the center\nbias, which could boost accuracy of fixation prediction. Following , this was achieved by multiplying\nthe center model with the saliency maps obtained by these models in a point-wise manner.\n\n5\n\n\f5.2 Results\n\nFirst, we compared different super-resolution techniques (LR, BI and CS) for eye fixation prediction.\nFig. 5 shows the results of RHM with the three techniques. The CS method significantly outperformed\nLR and BI. Therefore, sparsity as a prior offers great advantage in discovering salient fine details. We\nthen focused on RHM with CS in subsequent experiments.\n\nFig. 4 shows some qualitative comparison of the proposed model against existing models. Table 5\nshows quantitative results under three metrics. As we can see, no single model could dominate others\nunder all three metrics. However, in most cases (including both \u201cwith\u201d and \u201cwithout center\u201d settings),\nthe RHM outperformed the current state-of-the-art models. This demonstrated the reverse hierarchy\ntheory as a promising way to predict human eye fixations.\n\n5.3 Contributions of Individual Components\n\nThe RHM consists of two components: coarse-to-fine reconstruction (especially compressive sensing)\nand reverse propagation. Although the two components integrated together showed promising results,\nthe contribution of each component to the performance is unclear. This is discussed as follows.\n\nCompressive sensing. To identify the role of compressive sensing, we substituted it with other saliency\nmodels. Specifically, we replaced the saliency maps obtained from coarse-to-fine reconstruction\nby the saliency maps obtained by existing models. The models designed to work on a single scale,\nincluding SR, AIM, SUN, were applied to images of different scales to obtain multiple saliency maps.\nFor multi-scale models such as Itti Koch, we use their intermediate single-scale results.\n\nNotice that blurring with a Gaussian filter is a necessary step in our model to obtain a smooth saliency\nmap from stochastic fixations. Previous results have shown that blurring improved the performance\nof saliency models. For the sake of fairness, we also tested the models with the same amount of\nblurring (the sigma of Gaussian) used in RHM. Fig. 6 shows the results on the TORONTO dataset.\n\nThe reverse propagation procedure improved the AUC of these models. However, their performance\nis still behind RHM. Therefore, compressive sensing is a critical component in the RHM.\n\nReverse propagation. To investigate the effect of reverse propagation, we substituted it with linear\ncombination of saliency maps, which is widely adopted in literature. Table 2 shows the results. The\nlinear combination produced an AUC between the best and worst that a single saliency map could\nachieve. However, RHM outperformed the best single-map performance. Therefore, through reverse\npropagation, RHM could integrate complementary information in each map for better prediction.\n\n6 Conclusion and Future Work\n\nIn this paper, we present a novel reverse hierarchy model for predicting eye fixations based on a\npsychological theory, reverse hierarch theory (RHT). Saliency is defined as unpredictability from\ncoarse-to-fine image reconstruction, which is achieved by image super-resolution. Then a stochastic\nfixation model is presented, which propagates saliency from from the top layer to the bottom layer to\ngenerate 01xation esti- mate. Experiments on two benchmark eye-tracking datasets demonstrate the\neffectiveness of the model.\n\nThis work could be extended in several ways. First, it is worth exploring whether there exist better\nsuper- resolution techniques than compressive sensing for the pro- posed framework. Second, it\nis worth exploring if the ideas presented in the paper can be applied to a hierarchical struc- ture\nconsisting of different level of features, which play a signi01cant role in the top-down modulation as\nsuggested by RHT. Finally, in view of the similar hierarchical structure used in this study for saliency\ndetection and other studies for object recognition, it would be interesting to devise a uni01ed model\nfor both tasks.\n\n6",
  "results": "",
  "conclusion": "",
  "is_publishable": 1,
  "venue": NaN
}
{
  "title": "Acquiring the Ability to Recommend Interventions for Tuberculosis\nTreatment Through the Utilization of Digital Adherence Information",
  "abstract": "Digital Adherence Technologies (DATs) are becoming progressively favored as a means of confirming patients\u2019\nadherence to various medications. This paper examines the information gathered from a city that utilizes 99DOTS,\na telephone-based DAT implemented for tuberculosis (TB) treatment in India, where approximately 3 million\nindividuals are diagnosed with the disease annually. The dataset encompasses approximately 17,000 patients\nand 2.1 million dosage records. This research establishes the basis for deriving insights from this real-world\ndata, encompassing a methodology to circumvent the influence of unrecorded interventions in the training\ndata employed for machine learning. Subsequently, a deep learning model is developed, its interpretability is\nillustrated, and it is demonstrated how it can be modified and trained under diverse clinical conditions to more\neffectively target and enhance patient treatment. In the context of real-time risk prediction, the model could be\nemployed to proactively intervene with 21% more patients and prevent 76% more missed doses compared to\nthe current heuristic benchmarks. Regarding outcome prediction, the model exhibits 40% improvement over\nbaseline approaches, enabling cities to allocate more resources to clinics with a higher proportion of patients\nsusceptible to treatment failure. Lastly, a case study is presented that illustrates how the model can be trained in an\nend-to-end, decision-focused learning framework to realize a 15% enhancement in solution quality in a sample\ndecision problem encountered by healthcare professionals.",
  "introduction": "The World Health Organization (WHO) has identified tuberculosis (TB) as one of the leading ten causes of mortality globally, despite\nit being a curable and preventable disease in the majority of instances. The widespread occurrence of TB is partially attributable\nto inadequate adherence to medication, which leads to an elevated probability of mortality, reinfection, and the development of\ndrug-resistant strains of TB. To address the issue of non-adherence, the WHO advocates for directly observed treatment (DOT),\nwherein a healthcare professional directly observes and validates a patient\u2019s daily intake of the necessary medication. Nevertheless,\nthe necessity for patients to commute to the DOT facility imposes a financial strain and potentially introduces social stigma because\nof the public apprehension surrounding the disease. These obstacles make it challenging to eradicate TB, as they contribute to\npatients being lost to follow-up. Consequently, digital adherence technologies (DATs), which offer patients adaptable methods to\ndemonstrate adherence, have experienced a surge in popularity on a global scale.\n\nDATs empower patients to be \"observed\" consuming their medication electronically through various means, such as two-way\ntext messaging, video recording, electronic pill containers, or toll-free phone calls. Healthcare professionals can subsequently\nmonitor patient adherence in real-time using a dashboard. Besides enhancing patient adaptability and confidentiality, the dashboard\nempowers healthcare personnel to categorize patients and allocate their constrained resources towards those at the highest risk.\nInitial research indicates that DATs have the potential to enhance adherence in various disease contexts, thereby stimulating their\nutilization and assessment for the management of TB adherence. The WHO has even issued a manual for the effective incorporation\nof this technology in TB patient care.\n\nIn this paper, the focus is on investigating how the extensive longitudinal data generated by DATs can be utilized to assist health\nworkers in better triaging TB patients and providing interventions to enhance the overall adherence of their patient group. The data\nunder analysis originates from Mumbai, India, and is the result of a collaboration with the City TB Office of Mumbai. They have\nput into practice a DAT that enables patients to verify their adherence by making daily toll-free calls. The DAT system was set\nup with technical assistance from the healthcare technology company Everwell and is recognized as 99DOTS. Everwell provides\nsupport for the implementation of 99DOTS across India, where there were an estimated 2.7 million cases of TB in 2017. In Mumbai,\npatients registered in 99DOTS currently receive interventions based on the following broad guidelines. If they have not taken their\nmedication by the afternoon, they (and their health worker) get a text message reminder. If the patient still does not take their\nmedication after some time, the worker will call the patient directly. Lastly, if a patient does not respond to these interventions after\na certain number of days, they may be personally visited by a health worker. It is important to note that a significant number of these\npatients reside in communities with limited resources, where each health worker is responsible for managing dozens to hundreds\n\n\fof patients, far exceeding their capacity for daily visits. Therefore, models that can pinpoint patients at risk of missing doses and\nprioritize interventions by health workers are of the utmost importance.\n\nAt first, the challenge of determining whom to target for an intervention seems to be a straightforward supervised machine learning\ntask. Provided with information regarding a patient\u2019s medication adherence as indicated by their calls to the 99DOTS system, it is\npossible to train a machine learning model to forecast whether they will miss medication doses in the future. Nevertheless, such a\nmodel disregards the simultaneous interventions carried out by health workers during the data collection period and may result in\nerroneous prioritization choices, even when it exhibits high accuracy. As an illustration, it might be observed that missed doses are\nsucceeded by a phase of medication adherence. This observation does not imply that individuals who miss doses are more inclined\nto take medication, but rather suggests that an intervention by a health worker likely occurred, after which the patient resumed their\nmedication.\n\nTherefore, to prescribe interventions, it\u2019s necessary to separate the impact of manual interventions from other underlying elements\nthat contribute to missed doses. However, because this data was gathered through a wide-ranging implementation involving actual\npatients, it incorporates the impacts of interventions executed by healthcare personnel. An added difficulty is that healthcare workers\nseldom document their interventions within the 99DOTS system, making it hard to gauge their consequences. Although there is a\nsubstantial body of research on assessing heterogeneous treatment effects, conventional methods consistently necessitate awareness\nof which patients underwent an intervention. It should be noted that such omissions will be prevalent as nations enthusiastically\nimplement DAT systems with the aim of aiding low-income areas. To facilitate the provision of enhanced care, it is imperative that\nwe can glean insights from this complex yet abundant data.\n\nHence, a general strategy is introduced for acquiring knowledge from adherence data with unrecorded interventions, grounded in\ndomain expertise regarding the intervention heuristics used by healthcare workers. A proxy is created for interventions evident in\nthe historical 99DOTS data, and a model is devised to aid in prioritizing intervention targets for healthcare workers across various\nclinical scenarios.",
  "related_work": "",
  "methodology": "The TB treatment system functions under severe resource constraints; for instance, a single health worker might be in charge of\nover 100 patients. Therefore, it is essential that workers can precisely evaluate patient risk and prioritize interventions appropriately.\nAlthough machine learning can be employed to carry out such risk assessment with encouraging precision, it necessitates careful\nconsideration of how intervention resources were distributed in the current data.\n\nA significant obstacle arises from the fact that users of the 99DOTS platform typically do not document interventions. Health\nworkers might send texts, make calls, or conduct personal visits to patients in an effort to boost adherence, but these interventions are\nnot systematically recorded in the data. Although far from perfect, these gaps are unavoidable as countries with varying reporting\nstandards adopt DATs for TB treatment. Considering the wealth of data produced by DATs and their potential to affect human\nlives, the importance of learning lessons in this demanding setting where unobserved interventions take place is emphasized. This\nchallenge is subsequently addressed by developing a screening procedure that recognizes patients who were probable candidates for\nspecific interventions.\n\nThe aim is to utilize the accessible data to create an approximation for when an intervention likely took place, enabling the training\nof models on data points unaffected by interventions. The initial step involves differentiating between various categories of health\nworker interventions. Specifically, a house visit is regarded as a \"resource-limited\" intervention, given that workers are unable to visit\nall their patients promptly. Typically, this represents a last resort for health workers when patients are unresponsive to alternative\nmethods. On the other hand, calls and texts are viewed as \"non-resource-limited\" interventions, as they could feasibly be conducted\non a large patient population at minimal expense.\n\nTo develop the proxy, a search was conducted for health worker guidelines concerning house visits. The 2005 guide by India\u2019s\nRevised National Tuberculosis Control Program (RNTCP) mandated that workers perform a house visit after a single missed dose.\nHowever, more recent guidelines are considerably more ambiguous on this matter. Both the latest guide by the WHO and the\nRNTCP leave house visits to the health worker\u2019s discretion. Nevertheless, through discussions in Mumbai, it was discerned that\nhealth workers give precedence to non-adherent patients for resource-limited interventions like house visits. Consequently, the proxy\nwas formulated based on the adherence dashboard accessible to health workers.\n\nThe 99DOTS dashboard provides a daily \"Attention Required\" status for each patient. Initially, if a patient has a record in the Patient\nLog, signifying that a provider made a note about the patient within the preceding 7 days, their status is automatically adjusted to\n\"MEDIUM\" attention. However, this guideline impacts fewer than 1% of the labels. The remaining 99% of labels are determined as\nfollows: if a patient misses 0 or 1 doses in the past 7 days, their attention level is changed to \"MEDIUM.\" If they miss 4 or more, it\nis changed to \"HIGH.\" Patients with 2-3 missed doses maintain their attention level from the day before. As a conservative proxy, it\nwas assumed that only \"HIGH\" attention patients were candidates for resource-limited interventions, considering that the attention\nlevel serves as a health worker\u2019s primary overview of recent patient adherence. This \"Attention Required\" system for screening\nresource-limited interventions is applicable to any daily adherence context; one only needs to ascertain the threshold for a change to\nHIGH attention.\n\n2\n\n\fEmploying this screening system, sequences of days can be identified during which a patient was a candidate for a resource-limited\nintervention, and subsequently, the use of signal from those days in the training task can be avoided.",
  "experiments": "The objective was to create a model that mirrors the daily routine of a health worker, which involves analyzing their patients\u2019 recent\ncall records to gauge adherence risk and subsequently planning various types of interventions. Enhanced prediction capabilities\nenable workers to engage with a greater number of patients proactively, prior to their missing crucial doses.\n\nThe process began with the entire group of 16,975 patients and proceeded to create training samples from each patient in the\nfollowing manner. All consecutive sequences of 14 days of call data were considered, ensuring that the initial 7 days of each\nsequence did not overlap. The first 7 days of each patient\u2019s treatment, as well as the final day, were omitted to prevent any bias that\nmight arise from interactions with health workers during the initiation or conclusion of treatment. Two filtering steps were then\nimplemented. Initially, samples were excluded where the patient had in excess of 2 doses manually recorded by a provider during the\ninput sequence, as these patients likely had contact with their provider outside of the 99DOTS system. Secondly, samples in which\nthe patient did not miss any doses in the input sequence were removed. Although these samples constituted the majority of the data,\nthey included almost no positive (HIGH risk) labels, which distorted the training process. Moreover, positive predictions for patients\nwho missed 0 doses are improbable to be beneficial; no resource-limited intervention can be implemented so extensively that patients\nwith flawless recent adherence are targeted. The aforementioned steps yielded 16,015 samples, of which 2,437 were positive.\n\nEach sample comprised a time-series of call data along with static characteristics. The time series encompassed two sequences of 7\nin length for every sample. The initial sequence was a binary representation of call data, where 1 signified a call or manual dose\nand 0 indicated a miss. The subsequent sequence represented a cumulative count of all doses missed up to that specific day, taking\ninto account the patient\u2019s entire history within the program. The static features incorporated four demographic attributes from the\nPatient Table: weight-band, age-band, gender, and treatment center ID. Supplementary features were derived from the patient Call\nLogs and captured a patient\u2019s behavior beyond mere adherence. For instance, did the patient call at a consistent time each morning\nor at irregular intervals throughout the day? This was captured by calculating the mean and variance of the call minute and hour.\nAdditional features encompassed the number of calls, number of manual doses, and the mean, maximum, and variance of calls per\nday, in addition to days per call. Analogous features were also incorporated, which exclusively utilized unique calls per day (i.e.,\ncalls to distinct phone numbers) or disregarded manual doses. This procedure resulted in 29 descriptive features.\n\nInitially, standard models were tested that utilize solely the static features: linear regression, a random forest (with 100 trees and a\nmaximum depth of 5), and a support vector machine. The random forest exhibited the best performance, so the others are omitted for\nthe sake of clarity. To make use of the time series data, a deep network was also constructed, designated as LEAP (Lstm rEal-time\nAdherence Predictor), which accepts both the time series and static features as input. LEAP comprises two input layers: 1) an LSTM\nwith 64 hidden units for the time series input, and 2) a dense layer with 100 units for the static feature input. The outputs of these\ntwo layers were concatenated and fed forward into another dense layer with 16 units, followed by a single sigmoid activation unit. A\nbatch size of 128 was employed, and training was conducted for 20 epochs.\n\nTo assess the models, all data was randomized, and 25% was set aside as the test set. A 4-fold grid search was employed to ascertain\nthe optimal model parameters. To address class imbalance, SMOTE was utilized to oversample the training set, implemented using\nthe Python library imblearn. Features were also normalized as percentiles using SKLearn, which was empirically found to be\neffective. The benchmark for comparison was the method employed by the current 99DOTS platform to evaluate risk, namely, doses\nmissed by the patient in the preceding week (lw-Misses).",
  "results": "The models were compared against the baseline. The random forest slightly surpasses the baseline, and LEAP distinctly outperforms\nboth. Nevertheless, to gauge the efficacy of the methods relative to the baseline, a comparison is made regarding how each method\ncould be applied to strategize house-visit interventions. Given that this constitutes a highly constrained resource, the most stringent\nbaseline threshold was established to contemplate patients for this intervention, specifically, 3 missed calls. Maintaining the FPR of\nthis baseline method, it is demonstrated how many more patients in the test set would be reached weekly by the proposed method\n(owing to its enhanced TPR), alongside the enhancement in the quantity of missed doses detected. To ascertain the number of missed\ndoses caught, only missed doses that transpired before the patient\u2019s transition to HIGH risk are counted. The model identifies 21.6%\nmore patients and captures 76.5% more missed doses, signifying substantially more accurate targeting than the baseline.\n\nIt is shown that the model also surpasses the baseline as both the true positive rate (TPR) and FPR escalate, underscoring the model\u2019s\nsuperior discriminatory capability. This proves advantageous for interventions not constrained by resources, like calls or texts. It\nis important to remember that the screening procedure is not pertinent to this category of intervention; therefore, the predictions\ncan solely advocate for supplementary interventions. It is crucial that additional interventions are meticulously aimed, as repeated\nengagement with a specific patient diminishes the effectiveness of each subsequent interaction over time. This emphasizes the\nsignificance of the enhanced precision provided by the model, as merely inundating the entire population with calls and texts is\nprobable to be ineffective.\n\n3\n\n\fThe model has the capability to prevent a greater number of missed doses compared to existing approaches. Nonetheless, these\nadvancements cannot be realized unless health workers on the ground administer interventions in accordance with the predictions.\nConsequently, interpretability emerges as a crucial determinant of the model\u2019s utility, as health workers must comprehend the\nrationale behind the model\u2019s predictions to trust it and incorporate its logic with their own professional expertise.\n\nThe superior predictive performance was attained with LEAP, a black-box network, as opposed to an inherently interpretable model\nsuch as linear regression. As a result, it is demonstrated how a visualization instrument can assist users in extracting insights\nregarding the model\u2019s reasoning. The SHapley Additive exPlanations (SHAP) python library was employed, which produces\nvisualizations to elucidate machine learning models. It is illustrated how static features affect the model\u2019s prediction, where red\nfeatures drive predictions toward 1 (HIGH) and blue toward 0 (MEDIUM). It is important to recall that features are scaled as\npercentiles. In the blue region, it is observed that this patient makes an above-average number of calls each week, pushing the\nprediction toward 0. Conversely, in the red region, it is noted that this patient has a very low average but a high variability in time\nbetween calls. These features capture that this patient missed two days of calls, then made three calls on one day in an attempt to\n\"back log\" their previous missed calls. The model learned that this is a high-risk behavior.\n\nFour distinct samples are presented as input to the LSTM layer of the model. On the left, the binary input sequence is depicted as\ncolored pixels, where black represents a call and yellow signifies a missed call. On the right, SHAP values corresponding to each\nday of adherence data are displayed, and grey denotes the commencement of the call sequence. It is observed that the model has\ndiscerned that calls made later in the week carry more weight than those made earlier. In Sample 1, the bottom two pixels (the most\nrecent calls) have blue SHAP values, while the other pixels have SHAP values close to 0. In Sample 3, a single missed call at the\nbeginning of the week, combined with a call made at the end of the week, result in essentially canceling SHAP values. Sample 4\nalso has one missed call, but on the last day of the week, resulting in a net positive SHAP value.\n\nThis visualization method offers intuitive insights into the principles acquired by the model. In a real-world application, healthcare\nprofessionals could produce these visualizations for any given sample on-the-fly to support their decision-making procedure.",
  "conclusion": "A framework is introduced for acquiring the ability to generate intervention recommendations from data produced by DAT systems\nused in TB care. A comprehensive strategy is formulated for learning from medical adherence data that includes unrecorded\ninterventions, and this strategy is utilized to construct a model for forecasting risk in various contexts. In the real-time adherence\nscenario, it is demonstrated that the model would empower health workers to more precisely direct interventions to high-risk patients\nat an earlier stage, identifying 21% more patients and preventing 76% more missed doses than the existing heuristic benchmark.\nSubsequently, the model is trained for outcome prediction, illustrating how adherence data can more accurately detect patients\nat risk of unfavorable treatment outcomes. Insights are then derived that could assist health workers in accurately identifying\nLCFO patients using a straightforward rule after a mere 7 days of treatment. Finally, it is demonstrated that adapting the LEAP\nmodel for a particular intervention through decision-focused learning can enhance performance by an additional 15%. The learning\nmethodologies presented here are versatile and could be applied to analyze data generated by DATs for any medication schedule.\nGiven the increasing adoption of DAT systems for TB, HIV, diabetes, heart disease, and other medications, this work aims to\nestablish the groundwork for enhanced patient outcomes in healthcare settings worldwide.\n\n6 Outcome Prediction\n\nThe subsequent phase involves an investigation into how adherence data can be employed to forecast the ultimate treatment outcome.\nConventional studies on TB treatment typically model outcomes solely in relation to patient covariates, such as demographic\ncharacteristics. By utilizing daily real-time adherence data furnished by DATs, an exploration is conducted into how employing\nthe initial k days of a patient\u2019s adherence facilitates more precise, individualized outcome predictions. It is important to note\nthat intervention effects are still discernible in this configuration. Nevertheless, the screening procedure will not be applicable,\nas predictions are made over a span of several months, during which practically all patients would have had recurring in-person\ninteractions with healthcare providers.\n\nThe prediction task is formalized in the following manner: given the first k days of adherence data, predict the final binary treatment\noutcome. \"Cured\" and \"Treatment Complete\" were regarded as favorable outcomes, while \"Died,\" \"Lost to follow-up,\" and\n\"Treatment Failure\" were considered unfavorable. Solely patients who were assigned an outcome from these classifications are\nincorporated. Furthermore, given that patients with the outcome \"Died\" or \"Lost to follow-up\" exit the program prior to the full 6\nmonths of treatment, those who were present for less than k + 1 days were excluded. Lastly, patients who had in excess of half their\nfirst k days marked as manual doses were omitted. This was inclined to enhance prediction performance, which is conjectured to be\nassociated with the observation that practices for reporting manual doses varied by health center, rendering the \"significance\" of a\nmanual dose ambiguous across samples with respect to outcome. The final dataset comprised 4167 samples, with 433 unfavorable\ncases.\n\nThrough discussions in Mumbai, it was learned that health workers often build a sense of a patient\u2019s risk of an unfavorable outcome\nwithin their first month of treatment. To model this process, k=35 was set for the prediction task, capturing the first month of each\npatient\u2019s adherence after enrollment in 99DOTS. (Note that this is not a general rule for health workers, but simply served as a\n\n4\n\n\fmotivation for the choice of k in this task.) Both the static features and the sequence inputs were the same as calculated for the\nweekly prediction task, but now taken over the initial 35 days. Two versions of the health worker baseline were included: missed\ndoses in the last week (lw-Misses) and total missed doses in 35 days (t-Misses).\n\nThe same models, grid search design, training process, and evaluation procedure as before were used. For the Random Forest, 150\ntrees were used with no maximum depth. For LEAP, 64 hidden units were used for the LSTM input layer, 48 units for the dense\nlayer input, and 4 units in the penultimate dense layer.\n\nEven the rudimentary baseline of tallying the calls made in the preceding 7 days before the 35-day threshold is somewhat predictive\nof the outcome, implying that the daily data provided by DATs is valuable in assessing which patients will fail TB treatment. The\nML models exhibit even greater predictive capability, with LEAP leading in performance, closely followed by the random forest.\nIt is emphasized how LEAP\u2019s predictive ability could aid officials in minimizing the expenses required to meet medical outcome\ntargets for their city. For instance, suppose Mumbai initiates a new program to capture 80% of unfavorable outcomes (true positives)\nby recruiting additional health staff. Across the 17,000 patients in Mumbai, where 10% have unsuccessful outcomes as in the test\nset, an 80% capture rate necessitates rescuing 1360 patients. Employing either baseline, attaining the 80% TPR necessitates an FPR\nof 70%, which translates to hiring extra staff to support 10710 total patients in this hypothetical scenario. However, utilizing LEAP\nonly results in an FPR of 42%, corresponding to 6426 total patients. It is important to remember that in Mumbai, the typical health\nworker attends to approximately 25 patients. With a yearly starting salary of |216,864, the model would result in |37M in saved costs\nannually.\n\n7 Detecting Low-Call Favorable Outcome Patients\n\nAn additional significant hurdle within the 99DOTS system is that certain patients consistently take their doses as directed but opt not\nto call. Consequently, according to the dashboard, they appear to be missing doses and would be categorized as HIGH risk by both\n99DOTS and LEAP. However, in actuality, they should be classified as MEDIUM risk. In fact, almost 15% of patients who had an\noutcome assigned as in section 3 called on fewer than 25% of the days during their treatment, yet experienced a favorable outcome.\n\nThese patients are referred to as low-call favorable outcome (LCFO). The aim is to learn to recognize these LCFO patients to avoid\nincorrectly classifying them as HIGH risk, despite their lack of calls. Additionally, there is a desire to identify these patients early in\ntheir treatment so they can be reassigned to an adherence monitoring method that is more appropriate for them.\n\nThis is framed as a binary prediction task as follows: given the first k days of adherence data, predict whether the patient will both\ncall on less than 25% of days from day k + 1 onward and have a favorable outcome. Only patients who were assigned an outcome as\nin Section 3 and who had at least k + 7 days of adherence data were included. To detect LCFO status as early as possible, k was set\nto 7. Thus, the final dataset contained 7265 patients, of which 1124 were positive. Note that this population was larger than that of\nthe outcome prediction task because 1) patients were required to be in the program for less time and 2) patients were not removed\nfor having too many manual doses since this was found to correlate with being LCFO.\n\nBoth the static features and the sequence inputs were the same as calculated for the outcome prediction task, but this time taken over\nthe initial 7 days. The health worker baseline of missed doses in the last week (lw-Misses) was included, along with a random forest\ntrained only on demographic or \"0-day\" data (RF 0-day), a simple baseline that counts the number of manual doses in the last week\n(lw-Manual), a random forest trained on all non-sequence features over the initial 7 days (RF), and LEAP trained on all features and\nsequences.\n\nThe same models, grid search design, training process, and evaluation procedure as the previous two formulations were used. For RF\n0-day, 300 trees were used with a maximum depth of 10. For RF, 200 trees were used with a maximum depth of 10. For LEAP, 200\nhidden units were used for the LSTM input layer, 1000 units for the dense layer input, and 16 units in the penultimate dense layer.\n\nInterestingly, for this task, the lw-Misses baseline has almost no predictive power. Conversely, the performance of the lw-Manual\nheuristic is notable, which simply counts the number of manual doses marked in the first 7 days for each patient. This simple\nheuristic has almost equivalent predictive power to the machine learning models. This is a valuable insight for health workers,\nsuggesting that if the worker is already manually marking doses for a patient early in their treatment, the patient is likely to continue\nto be disengaged with the system in the long term and should be considered for different adherence technology. The RF 0-day model\nhas decent predictive power, though closer inspection reveals that most of this power is encoded in the treatment center ID \u2013 that is,\nLCFO patients tend to be concentrated at certain treatment centers. This insight merits closer inspection by supervisors about why\npatients in certain regions tend to be disengaged with 99DOTS but still consuming pills. The RF and LEAP models both perform\nslightly better than the lw-Manual baseline but similarly to each other, suggesting that the adherence sequence structure does not\nencode additional information for this prediction task. These insights could improve processes by 1) helping to identify hotspot\nregions of LCFO patients, after which supervisors might investigate the underlying reason and adjust treatment accordingly at those\ncenters and 2) the lw-Manual baseline, after only 7 days of dosage data, could give health workers a simple rule for identifying\nLCFO patients that should switch to different adherence technology.\n\n5\n\n\f8 Decision Focused Learning\n\nThis section delves into a case study illustrating how the LEAP model can be specialized to furnish decision support for a specific\nintervention. The end-to-end differentiability of the model is utilized to supplant the earlier loss function (binary cross-entropy)\nwith a performance metric customized to the objective and limitations of a particular decision problem. To realize this end-to-end\ntraining, recent developments in decision-focused learning are employed, which incorporates an optimization model within the\nmachine learning training loop.\n\nThe focus is on a particular optimization problem that simulates the allocation of health workers to intervene with patients who are\nat risk in the near future. This proactive intervention is facilitated by the real-time risk predictions and exemplifies how the system\ncan empower preemptive, focused action by providers. Nonetheless, it is underscored that the system can be readily adapted to\naccommodate other intervention problems. Such adaptability is one of the advantages of the technical approach, which permits the\nML model to automatically adjust to the problem delineated by a domain expert.\n\nThe optimization problem models a health worker who orchestrates a sequence of interventions throughout a week. The health\nworker is accountable for a patient population across various locations and may visit one location daily. Location identifiers are\nemployed at the TB Unit level, as this is the most detailed identifier shared by the majority of patients in the dataset. Visiting a\nlocation enables the health worker to intervene with any of the patients at that location. The optimization problem involves choosing\na set of locations to visit that maximizes the number of patients who receive an intervention on or before the first day they would\nhave missed a dose. This quantity is referred to as the number of successful interventions, which is selected as the objective for two\nrationales. Firstly, it gauges the degree to which the health worker can proactively engage with patients before adherence declines.\nSecondly, this objective exclusively counts patients who commence the week at MEDIUM attention and receive an intervention\nbefore they could have transitioned to HIGH, aligning with the earlier discussion on circumventing unobserved interventions in the\ndata. This extends the earlier intervention proxy to manage day-by-day rewards.\n\nThe optimization problem can be formalized as a linear program. There is a set of locations i = 1, . . . , L and patients j = 1, . . . , N ,\nwhere patient j has location \u2113j. Over the days of the week t = 1, . . . , 7, the objective coefficient cjt is 1 if an intervention on day t\nwith patient j is successful and 0 otherwise. The decision variable is xit, which takes the value 1 if the health worker visits location\ni on day t and 0 otherwise. With this notation, the final LP is as follows:\n\nsubject to:\n\nmax\n\n7\n(cid:88)\n\nN\n(cid:88)\n\nt=1\n\nj=1\n\ncjtx\u2113j ,t\n\n7\n(cid:88)\n\nt=1\n\nxit \u2264 1 \u2200i,\n\nxit \u2208 {0, 1}.\n\nHere, the second constraint prevents the objective from double-counting multiple visits to a location. It is noted that the feasible\nregion of the LP can be demonstrated to be equivalent to a bipartite matching polytope, implying that the optimal solution is always\nintegral.\n\nThe machine learning task involves predicting the values of cjt, which are unknown at the start of the week. Three models are\ncompared. Firstly, the lw-Misses baseline is extended to this setting by thresholding the number of doses patient j missed in the last\nweek, setting cjt = 0 for all t if this value falls below the threshold \u03c4 and cjt = 1 otherwise. \u03c4 = 1 was used as it performed best.\nSecondly, the LEAP system was trained directly on the true cjt as a binary prediction task using cross-entropy loss. Thirdly, LEAP\nwas trained to predict cjt using performance on the above optimization problem as the loss function (training via the differentiable\nsurrogate). This model is referred to as LEAP-Decision.\n\nInstances of the decision problem were created by randomly dividing patients into groups of 100, simulating a health worker under\nsevere resource limitations (as they would benefit most from such a system). All patients were included, even those with no missed\ndoses in the last week, since the overall resource allocation problem over locations must still account for them.\n\nLEAP and LEAP-Decision both outperform lw-Misses, as anticipated. LEAP-Decision enhances the number of successful\ninterventions by roughly 15% compared to LEAP, showcasing the merit of customizing the learned model to a given planning\nproblem. LEAP-Decision actually has a lower AUC than either LEAP or lw-Misses, suggesting that conventional measures of\nmachine learning accuracy are not an ideal proxy for utility in decision-making. To investigate what specifically distinguishes the\npredictions made by LEAP-Decision, scatter plots of the predicted utility at each location according to LEAP and LEAP-Decision\nversus the true values are presented. Visually, LEAP-Decision appears better able to distinguish the high-utility outliers which are\nmost important to making good decisions. Quantitatively, LEAP-Decision\u2019s predictions have worse correlation with the ground truth\noverall (0.463, versus 0.519 for LEAP), but better correlation on locations where the true utility is strictly more than 1 (0.504 versus\n0.409). Hence, decision-focused training incentivizes the model to focus on making accurate predictions specifically for locations\nthat are likely to be good candidates for an intervention. This demonstrates the benefit of the flexible machine learning modeling\napproach, which can use custom-defined loss functions to automatically adapt to particular decision problems.\n\n6\n\n\fTable 1: Data Summary. *Doses per patient was calculated only on patients enrolled at least 6 months before Sept 2018.\n\nMetric\n\nTotal doses recorded\n\u2013By patient call\n\u2013Manual (entered by health worker)\n\nRegistered phones\nPatients\nHealth centers\nDoses recorded per patient*\n\n\u2013Quartiles\n\u2013Min/Mean/Max\n\nActive patients per center per month\n\n\u2013Quartiles\n\u2013Min/Mean/Max\n\nCount\n\n2,169,976\n1,459,908\n710,068\n38,000\n16,975\n252\n\n57/149/188\n1/136/1409\n\n7/18/35\n1/25/226\n\nTable 2: LEAP vs. Baseline - Missed Doses Caught\n\nMethod\n\nTrue Positives Doses Caught\n\nBaseline\nLEAP\nImprovement\n\n204\n248\n21.6%\n\n204\n360\n76.5%\n\nTable 3: LEAP vs. Baseline: Additional Interventions\n\nTPR Baseline FPR LEAP FPR Improvement\n\n75% 50%\n80% 63%\n90% 82%\n\n35%\n41%\n61%\n\n30%\n35%\n26%\n\n7",
  "is_publishable": 1,
  "venue": NaN
}
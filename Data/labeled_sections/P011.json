{
  "title": "Controlling False Discovery Rates in Detecting Heterogeneous\nTreatment Effects for Online Experiments",
  "abstract": "Online controlled experiments, commonly referred to as A/B testing, are widely used in many Internet companies\nfor data-driven decision-making regarding feature modifications and product releases. However, a significant\nchallenge remains in methodically evaluating how each code or feature change affects millions of users who\nexhibit considerable heterogeneity across various dimensions such as countries, ages, and devices. The Average\nTreatment Effect (ATE) framework, which is the foundation of the A/B testing approach used by many companies,\nis unable to identify the heterogeneity of treatment effects on users with varying characteristics. This paper\nintroduces statistical techniques designed to systematically and precisely pinpoint the Heterogeneous Treatment\nEffect (HTE) within any specific user cohort, like mobile device type or country. Additionally, these methods help\ndetermine which user factors, such as age or gender, contribute to the variability in treatment effects observed\nduring an A/B test. Through the application of these methods to both simulated and real-world experimental\ndata, we demonstrate their robust performance in maintaining a controlled, low False Discovery Rate (FDR).\nSimultaneously, they offer valuable insights into the heterogeneity of identified user groups. We have implemented\na toolkit based on these methods and utilized it to assess the HTE across numerous A/B tests at Snap.",
  "introduction": "Controlled experiments, also known as A/B testing, have become a standard method for assessing and enhancing new product\nconcepts across internet companies. Numerous IT companies, possessing extensive and large-scale data, have developed internal\nA/B testing platforms to address their intricate experimentation requirements. At Snap, the utilization of A/B testing has substantially\nincreased in the last two years. The in-house platform currently manages hundreds of concurrent experiments at any moment. Each\nexperiment automatically generates results for hundreds to thousands of varied online metrics.\n\nAs experimentation gains popularity, there is an increasing demand for experimenters to understand not only the overall impact\non metrics in an A/B test but also the reasons behind metric changes and the specific user segments driving these changes. Such\ninsights into user heterogeneity can assist experimenters in devising strategies to enhance the product. For instance, in a recent\nexperiment, we observed that a decline in a metric was primarily influenced by users with the highest number of snap views. This\nobservation led us to concentrate on understanding the engineering and design aspects when a user has a large number of snap stacks\nto load. Consequently, we were able to pinpoint a significant performance problem that was causing the metric to drop. Indeed, we\nhave encountered numerous instances where users react differently to the same experimental treatment.\n\nFurthermore, the abundance of data presents a significant risk of false discoveries, often due to a statistical phenomenon referred to\nas \"multiple testing\". Given the hundreds of thousands of user characteristics available to internet companies, user groups can be\nformed in millions of different ways. If a \"naive\" approach is taken, simply calculating and comparing the estimated effect based on\nusers within groups, it is easy to find groups with treatment effects that significantly deviate from the average, regardless of whether\nactual heterogeneity exists.\n\nThe objective of our work is to bridge this gap by offering rigorous statistical methods and a toolkit capable of detecting Heterogeneous\nTreatment Effects (HTE) while addressing the potential issue of multiple testing by controlling the false positive rate (FDR). This\ntoolkit has been deployed and is in use at Snap. In this paper, we explore the rationale for using FDR and contrast two statistical\nmethods that manage FDR, using both simulated results and actual experimental data. Based on the methods selected, we will\ndiscuss solutions to two questions that experimenters and practitioners are keen to understand regarding HTE:\n\n\u2022 How to systematically identify which subgroups of users (e.g., countries) exhibit treatment effects significantly different\n\nfrom the Average Treatment Effect in an A/B test.\n\n\u2022 How to rigorously determine which factors (e.g., age, gender) contribute to the heterogeneity of the treatment effect in an\n\nA/B test.\n\nOur contributions in this paper are summarized as follows:\n\n\f\u2022 We frame the HTE detection problem as an FDR control issue and elaborate on why controlling FDR is crucial in large-scale\n\nHTE detection in practical applications.\n\n\u2022 We employ two methods capable of controlling FDR in our HTE detection process and provide insightful comparisons of\n\nthese methods using both simulation and real-world empirical data.\n\n\u2022 We discuss two significant lessons learned, concerning (1) the distinction between heterogeneity in the population and\nheterogeneity in treatment effects, and (2) the scalability of the algorithms. These insights are intended to help practitioners\navoid similar pitfalls.",
  "related_work": "",
  "methodology": "2.1 Average Treatment Effect vs. Heterogeneous Treatment Effect\n\nIn an A/B test, users are randomly divided into a treatment group and a control group, and the metrics of interest are observed\nfor all users. The Rubin Causal Model is frequently employed in A/B testing as a statistical framework for causal inference. Let\nYi(Ti) represent the potential outcome for the i-th user, where Ti = 1 if the i-th user is in the treatment group and Ti = 0 if the i-th\nuser is in the control group. Consequently, \u03c4i = Yi(1) \u2212 Yi(0) denotes the causal effect of the treatment for the i-th unit, and the\naverage causal effect across all users, \u00af\u03c4 , is defined as the Average Treatment Effect (ATE). It is important to note that the ATE is\nnot directly observable since Yi(0) and Yi(1) cannot be known simultaneously. This is recognized as the \"fundamental problem of\ncausal inference\". However, the estimator Yi|Ti = 1 \u2212 Yi|Ti = 0 is unbiased for the ATE when two specific assumptions are met\nand is commonly used to estimate the ATE in A/B testing.\n\nAssumption 1. Stable Unit Treatment Value Assumption (SUTVA):\n\n\u2022 There is only one version of treatment and control, meaning there is only one version of T = 1 and T = 0.\n\u2022 The treatment applied to one user does not affect the outcome of another user (no interference).\n\nAssumption 2. Unconfoundedness: Ti is independent of (Yi(0), Yi(1)) given Xi, where Xi is a set of pre-treatment variables for the\ni-th user, such as age, gender, country, etc.\n\nHowever, analysis based solely on ATE is sometimes insufficient for obtaining precise and meaningful insights. As mentioned earlier,\nwe have observed numerous cases where a single feature change can impact different users differently. The estimation of ATE is\nnot an effective measure for a heterogeneous population, as it may exaggerate the treatment effect for one sub-population while\nunderestimating it for another. To investigate heterogeneous treatment effects, it is necessary to consider the conditional average\ntreatment effect, defined as: \u03c4 (x) = E[Yi(1) \u2212 Yi(0)|Xi = x], where Xi represents a set of pre-treatment variables for the i-th user.\n\nAccurately estimating the conditional average treatment effect \u03c4 (x) for all values of x is highly beneficial for detecting heterogeneous\ntreatment effects because \u03c4 (x) provides the conditional average treatment effect for the subpopulation defined by the covariates x.\nFor instance, if the covariate is \u2019country\u2019, the covariate space can be partitioned into countries, and \u03c4 (x) represents the conditional\naverage treatment effect for users in country x. If \u03c4 (x) is statistically different from the average treatment effect \u00af\u03c4 , then country x is\nconsidered heterogeneous.\n\nThere is a growing need for rigorous analysis based on heterogeneous treatment effects (HTE), which motivates us to develop a\nrobust statistical approach for HTE detection.\n\n2.2 Naive Approaches and their Caveats\n\nIn this section, we outline some prevalent practices used by practitioners that could result in the spurious discovery of HTE. Suppose\nwe have users from various countries and wish to identify which countries exhibit treatment effects different from the ATE for a\nparticular metric. A straightforward approach to detect heterogeneous countries involves first conducting a two-sample t-test on the\nobservations from each country to obtain a two-sided p-value for each country, and then selecting countries with a p-value less than\n0.05 as the result. We will refer to this method as the \"naive approach\".\n\nThis naive approach is simple and may appear intuitive to non-statisticians. However, it is susceptible to the multiple testing problem.\nWe demonstrate this issue with a basic simulation:\n\n\u2022 Step 1: Assess treatment effects for all users in 30 randomly generated subgroups from a standard Gaussian distribution,\n\nensuring the true ATE is zero.\n\n\u2022 Step 2: Implement the naive approach and identify subgroups with p-values below 0.05 as heterogeneous.\n\nIn this simulation, 3 out of 30 subgroups are identified as having heterogeneous treatment effects, despite the ATE estimator being 0,\nindicating no actual heterogeneity among the subgroups.\n\nThe Bonferroni correction method can be employed to address the multiple testing problem by controlling the family-wise error rate\n(FWER). The FWER is the probability of rejecting at least one true hypothesis. Nevertheless, the Bonferroni method is known to be\n\n2\n\n\fhighly conservative, resulting in a high rate of false negatives and low statistical power, defined as P(reject H0 | H1), where H0 is\nthe null hypothesis and H1 is the alternative hypothesis.\n\n2.3 False Discovery Rate Controlled HTE Detection\n\nDue to the limitations of the methods discussed in the previous section, we introduce methods for HTE detection that address\nthe multiple testing problem while maintaining sufficient statistical power. To manage the multiple testing issue and reduce\nconservativeness, Benjamini and Hochberg introduced the concept of the false discovery rate (FDR), which is defined as follows:\n\nDefinition 3.1. False Discovery Rate: Let Q be the proportion of false positives among all detected (rejections of the null hypothesis).\nThen F DR = E[Q].\n\nTo control the FDR, it is necessary to manage the expected proportion of discoveries that are false. Additionally, methods that control\nthe FDR are generally much less conservative than the Bonferroni method. Therefore, in our proposed HTE detection approach, we\ncan control the FDR and ensure adequate power simultaneously.\n\n2.4 Detection for Heterogeneous Subgroups\n\nWhen conducting an A/B testing experiment, it is often important to identify which subgroups of users exhibit treatment effects\ndifferent from the ATE. For example, at Snap, with users from over 200 countries, we are interested in determining which countries\nhave higher or lower treatment effects compared to the average for the metric of interest.\n\nIn this process, it is crucial to minimize the number of false discoveries in our results. To achieve this, we utilize the Benjamini-\nHochberg (BH) procedure to control the FDR. The BH procedure is known to control the FDR if the test statistics are independent or\nsatisfy the positive regression dependence on a subset property. It is one of the most widely used FDR control methods due to its\nsimplicity. For instance, suppose we have p-values from m independent hypothesis tests H1, ..., Hm ranked in ascending order:\np(1), ..., p(m), and we aim to control the FDR at level q. The BH procedure identifies the largest k such that p(k) \u2264 k\nm q and rejects\nthe null hypothesis for all H(i) where i \u2264 k. By doing so, it theoretically ensures that the FDR is controlled below q.\nTo detect heterogeneous subgroups, it is necessary to estimate the conditional average treatment effects defined in equation (3) for\nthe subgroups. Although individual treatment effect values are not available due to the fundamental problem of causal inference, we\ncan construct a transformed outcome (TO) for each user as an alternative measure of individual treatment effect. Let Y obs\nbe the\nobserved outcome for the i-th unit. Additionally, let p be the assignment probability, which, in practice, is the traffic percentage\nassigned to the treatment group in an A/B test. The transformed outcome for the i-th unit, Y \u2217\n\ni , is then defined as:\n\ni\n\ni \u00d7 (Ti\u2212p)\np(1\u2212p) .\n\ni = Y obs\nY \u2217\nA beneficial property of the TO is that, under the unconfoundedness assumption, the conditional expectation E[Y \u2217\nthe conditional average treatment effect \u03c4 (x).\n\ni |Xi = x] equals\n\nWe propose the following method, which combines the BH method and Transformed Outcome, to detect heterogeneous subgroups.\nSuppose we have n users from p subgroups, and we want to identify subgroups with heterogeneous treatment effects that differ from\nthe average treatment effect with a controlled FDR. We propose the following procedure, which we call the HTE-BH method:\n\n\u2022 Step 1: Create an n \u00d7 p design matrix X such that Xi,j = 1 if the i-th user belongs to the j-th subgroup.\n\u2022 Step 2: Compute the transformed outcomes Y \u2217 for all users based on the formula in Equation (5), and then subtract the\n\nestimated ATE, \u00afY (1) \u2212 \u00afY (0), from all transformed outcomes. Let Y be the vector of the resulting outcomes.\n\n\u2022 Step 3: Perform a linear regression using Y as the response and X as the design matrix, and obtain the p-values for the\n\ncoefficient estimates corresponding to all subgroups.\n\n\u2022 Step 4: Apply the BH procedure to the p-values to finalize the list of selected heterogeneous subgroups.\n\nThe design matrix X created in Step 1 is orthogonal in this scenario, so the p-values derived from the linear regression are independent.\nConsequently, the BH procedure can control the FDR at a pre-specified level q. In Step 2, we subtract the estimated ATE from the\ntransformed outcomes to detect subgroups with treatment effects different from the ATE. For simplicity, we treat the estimated\nATE as a parameter. Although this overlooks the fact that the estimated ATE is a random variable, it has practical relevance as\npractitioners are typically interested in observing which subgroups are statistically different from the observed average treatment\neffect across all users in an experiment. Note that obtaining p-values in the manner described in Step 3 is equivalent to obtaining\np-values from running independent t-tests for all subgroups.\n\n2.5 Detection for Heterogeneous Factors\n\nIn addition to detecting heterogeneous subgroups, identifying the factors that contribute to the heterogeneity of treatment effects is\nanother crucial task in practice. At Snap, we have anonymously constructed hundreds of user properties, including demographic\ninformation such as age and gender, as well as user engagement levels, such as how users interact with snaps, stories, or discover.\n\n3\n\n\fOften, when presented with subtle experimental results, we are unsure which of these factors to investigate further. By pinpointing\nthe factors contributing to the heterogeneity in treatment effects, we can more effectively delve into the relevant factors and derive\ninsights. The HTE-BH method is straightforward and easy to implement for detecting heterogeneous subgroups but is not suitable\nfor detecting heterogeneous factors because, in this case, we cannot construct an orthogonal design matrix in Step 1 of the HTE-BH\nmethod. Therefore, we propose using the \u2019Knockoff\u2019 method to control the FDR for heterogeneous factors.\n\nThe \u2019Knockoff\u2019 is a recently proposed FDR control method. Suppose the response of interest, y, follows the classical linear model:\ny = X\u03b2 + \u03f5, where y \u2208 Rn is a vector of y, X \u2208 Rn\u00d7p is any fixed design matrix, \u03b2 is a vector of unknown coefficients, and\n\u03f5 \u223c N (0, \u03c32I) is Gaussian error. Note that n is the number of observations and p is the number of variables. For the Knockoff\nmethod, we assume that n \u2265 2p, which is reasonable in practice because we are likely to have more observations than variables in\nmost A/B tests.\nLet \u03a3 = X T X after normalizing X. The \u2019Knockoff\u2019 procedure can be summarized in three steps:\n\n\u2022 Step 1: Construct a \u2019knockoff\u2019 matrix \u02dcX of X such that \u02dcX satisfies: \u02dcX T \u02dcX = X T X = \u03a3, X T \u02dcX = \u03a3 \u2212 diags, where s is\n\na non-negative vector that we will construct.\n\n\u2022 Step 2: Compute a statistic Wj for each pair (Xj, \u02dcXj) such that a large positive value of Wj provides evidence against the\n\nnull hypothesis that the j-th variable is not included in the true model.\n\n\u2022 Step 3: Calculate a data-dependent threshold T such that the FDR of the knockoff selection set \u02c6S := {j : Wj \u2265 T } is less\n\nthan or equal to the pre-specified level q.\n\nIn our proposal, we use the equi-correlated method to obtain the non-negative vector s used in Step 1 to construct the knockoff\nmatrix \u02dcX. The equi-correlated method suggests using sj = min{2\u03bbmin(\u03a3), 1} for all j, where \u03bbmin is the smallest eigenvalue of\n\u03a3. After obtaining this s, we construct \u02dcX using the formula: \u02dcX = X(I \u2212 \u03a3\u22121diags) + \u02dcU C, where \u02dcU is an n \u00d7 p orthonormal\nmatrix satisfying \u02dcU T X = 0, and C is a Cholesky decomposition satisfying C T C = 2diags \u2212 diags\u03a3\u22121diags.\nThere are numerous options available for computing the statistics Wj\u2019s in Step 2. We choose to use Lasso to compute the statistics\nWj\u2019s. Let X \u2217 = [X \u02dcX] \u2208 Rn\u00d72p be the augmented design matrix. Recall the Lasso problem: minimize\u03b2||y \u2212 X \u2217\u03b2||2\n2 + \u03bb||\u03b2||1.\nDefine Zj = sup{\u03bb : \u03b2j(\u03bb) \u0338= 0}, which is the largest tuning parameter \u03bb that first allows the j-th variable to enter the\nmodel. Note that (Zj, Zj+p) is a pair corresponding to the j-th original variable and its knockoff. We then calculate Wj as:\nWj = (Zj \u2212 Zj+p) \u00d7 sign(Zj \u2212 Zj+p), for j = 1, ..., p.\nLet W be the set {|W1|, ..., |Wp|} \\ {0}. In Step 3, it is proposed to use the threshold: T = min{t \u2208 W : 1+#{j:Wj \u2264\u2212t}\n\n#{j:Wj \u2265t} \u2264 q}.\n\nTheorem 2 claims that the knockoff selection set \u02c6S := {j : Wj \u2265 T } is theoretically guaranteed to have an FDR less than q.\nWe propose the following procedure to detect the variables that contribute to the heterogeneity in treatment effects while controlling\nthe FDR. We call this the HTE-Knockoff method:\n\n\u2022 Step 1: Construct a design matrix X based on the set of pre-treatment variables.\n\u2022 Step 2: Calculate the transformed outcomes Y \u2217 for all users based on the formula in Equation (5), and then subtract the\n\nestimated ATE, \u00afY (1) \u2212 \u00afY (0), from all transformed outcomes. Let Y be the vector of the resulting outcomes.\n\n\u2022 Step 3: Create a knockoff matrix \u02dcX of X.\n\u2022 Step 4: Run a Lasso regression using Y as the response and X \u2217 = [X \u02dcX] as the design matrix.\n\u2022 Step 5: Follow the procedure of the Knockoff method to obtain the knockoff selection set of heterogeneous variables.\n\nNote that our proposed HTE-Knockoff method can also detect heterogeneous subgroups because it works for any full-rank design\nmatrix, regardless of orthogonality. Additionally, the HTE-Knockoff method is applicable when Xi is a set of variables including\nboth categorical and continuous variables, but we need to be careful in constructing the design matrix when there are more than one\ncategorical variables in Xi.",
  "experiments": "",
  "results": "We apply the HTE-BH and HTE-Knockoff methods to two real experimental datasets. In the first experiment, both methods yield\nnearly identical selections for heterogeneous subgroups. If we were to use the naive approach, it would select many more subgroups,\nclearly indicating numerous false positives. The HTE results reveal drastically different effects in English-speaking countries versus\nnon-English-speaking countries. Retrospectively, we understood that the new layout in the experiment favored non-English content\nwhile suppressing high-quality content in English.\n\nIn the second experiment, the HTE-BH method selects one subgroup as heterogeneous, whereas the HTE-Knockoff method selects\nnone. This likely represents a scenario where the true treatment effects are too small to be detected, causing the HTE-Knockoff\n\n4\n\n\fmethod to be more conservative than the HTE-BH method to avoid making any false positives. This observation aligns with the\nsimulation results.",
  "conclusion": "In this paper, we propose the HTE-BH method for detecting heterogeneous subgroups with treatment effects different from the\naverage, and the HTE-Knockoff method for identifying factors contributing to the heterogeneity in treatment effects. While the\nHTE-BH method is easier to implement, the HTE-Knockoff method has a broader application as it can also be used to detect\nheterogeneous factors. Our proposed methods demonstrate good detection power while addressing the multiple testing problem by\ncontrolling the FDR level.\n\nDespite their wide application scenarios, our current methods have some limitations and could be improved in future research. The\nfirst limitation is the assumption that the true model is a linear regression model with Gaussian error; the theoretical properties\nof the original Knockoff method are based on this assumption. Although we show that the Knockoff method can still perform\nwell in controlling FDR in some non-Gaussian error cases, there is no theoretical proof for such robustness. Additionally, the\ntrue relationship between the treatment effect and the variables may not always be linear, making the use of linear regression\ninappropriate. Recently, a model-free knockoff method has been proposed, which, under certain conditions, can work on any kind of\nnon-linear model. This idea could be useful if we aim to extend the HTE-Knockoff procedure to a more generalized setting in future\nwork.\n\nAnother unresolved issue is scalability. We attempted to use the transformed design matrix to conduct HTE detection on multiple\nexperiments, but this resulted in increased computational complexity. This problem warrants further investigation because most\ncompanies have a large number of A/B test results available, and it is not feasible to apply the HTE detection method to each\nexperiment individually.\n\n5",
  "is_publishable": 1,
  "venue": NaN
}